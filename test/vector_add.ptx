//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-32267302
// Cuda compilation tools, release 12.0, V12.0.140
// Based on NVVM 7.0.1
//

.version 8.0
.target sm_52
.address_size 64

	// .globl	_Z10vector_addPfS_S_i

.visible .entry _Z10vector_addPfS_S_i(
	.param .u64 _Z10vector_addPfS_S_i_param_0,
	.param .u64 _Z10vector_addPfS_S_i_param_1,
	.param .u64 _Z10vector_addPfS_S_i_param_2,
	.param .u32 _Z10vector_addPfS_S_i_param_3
)
{
	.reg .pred 	%p<6>;
	.reg .f32 	%f<16>;
	.reg .b32 	%r<18>;
	.reg .b64 	%rd<29>;


	ld.param.u64 	%rd19, [_Z10vector_addPfS_S_i_param_0];
	ld.param.u64 	%rd20, [_Z10vector_addPfS_S_i_param_1];
	ld.param.u64 	%rd21, [_Z10vector_addPfS_S_i_param_2];
	ld.param.u32 	%r10, [_Z10vector_addPfS_S_i_param_3];
	cvta.to.global.u64 	%rd1, %rd19;
	cvta.to.global.u64 	%rd2, %rd21;
	cvta.to.global.u64 	%rd3, %rd20;
	setp.lt.s32 	%p1, %r10, 1;
	@%p1 bra 	$L__BB0_7;

	add.s32 	%r12, %r10, -1;
	and.b32  	%r17, %r10, 3;
	setp.lt.u32 	%p2, %r12, 3;
	mov.u32 	%r16, 0;
	@%p2 bra 	$L__BB0_4;

	sub.s32 	%r15, %r10, %r17;
	mov.u64 	%rd23, %rd1;
	mov.u64 	%rd24, %rd2;
	mov.u64 	%rd25, %rd3;

$L__BB0_3:
	ld.global.f32 	%f1, [%rd24];
	ld.global.f32 	%f2, [%rd25];
	add.f32 	%f3, %f2, %f1;
	st.global.f32 	[%rd23], %f3;
	ld.global.f32 	%f4, [%rd24+4];
	ld.global.f32 	%f5, [%rd25+4];
	add.f32 	%f6, %f5, %f4;
	st.global.f32 	[%rd23+4], %f6;
	ld.global.f32 	%f7, [%rd24+8];
	ld.global.f32 	%f8, [%rd25+8];
	add.f32 	%f9, %f8, %f7;
	st.global.f32 	[%rd23+8], %f9;
	ld.global.f32 	%f10, [%rd24+12];
	ld.global.f32 	%f11, [%rd25+12];
	add.f32 	%f12, %f11, %f10;
	st.global.f32 	[%rd23+12], %f12;
	add.s32 	%r16, %r16, 4;
	add.s64 	%rd25, %rd25, 16;
	add.s64 	%rd24, %rd24, 16;
	add.s64 	%rd23, %rd23, 16;
	add.s32 	%r15, %r15, -4;
	setp.ne.s32 	%p3, %r15, 0;
	@%p3 bra 	$L__BB0_3;

$L__BB0_4:
	setp.eq.s32 	%p4, %r17, 0;
	@%p4 bra 	$L__BB0_7;

	mul.wide.s32 	%rd22, %r16, 4;
	add.s64 	%rd28, %rd1, %rd22;
	add.s64 	%rd27, %rd2, %rd22;
	add.s64 	%rd26, %rd3, %rd22;

$L__BB0_6:
	.pragma "nounroll";
	ld.global.f32 	%f13, [%rd27];
	ld.global.f32 	%f14, [%rd26];
	add.f32 	%f15, %f14, %f13;
	st.global.f32 	[%rd28], %f15;
	add.s64 	%rd28, %rd28, 4;
	add.s64 	%rd27, %rd27, 4;
	add.s64 	%rd26, %rd26, 4;
	add.s32 	%r17, %r17, -1;
	setp.ne.s32 	%p5, %r17, 0;
	@%p5 bra 	$L__BB0_6;

$L__BB0_7:
	ret;

}

