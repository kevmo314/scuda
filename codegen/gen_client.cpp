#include <cublas_v2.h>
#include <cuda.h>
#include <cuda_runtime_api.h>
#include <cudnn.h>
#include <nvml.h>

#include <cstring>
#include <string>
#include <unordered_map>

#include "gen_api.h"

#include "manual_client.h"

#include "rpc.h"

extern int rpc_size();
extern conn_t *rpc_client_get_connection(unsigned int index);
int is_unified_pointer(conn_t *conn, void *arg);
int maybe_copy_unified_arg(conn_t *conn, void *arg, enum cudaMemcpyKind kind);
extern void rpc_close(conn_t *conn);

nvmlReturn_t nvmlInit_v2() {
  conn_t *conn = rpc_client_get_connection(0);
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlInit_v2) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlInitWithFlags(unsigned int flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlInitWithFlags) < 0 ||
      rpc_write(conn, &flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlShutdown() {
  conn_t *conn = rpc_client_get_connection(0);
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlShutdown) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  rpc_close(conn);
  return return_value;
}

nvmlReturn_t nvmlSystemGetDriverVersion(char *version, unsigned int length) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&length, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)version, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(length) &&
                  is_unified_pointer(conn, (void *)version);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&version[i],
                               cudaMemcpyHostToDevice) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlSystemGetDriverVersion) < 0 ||
      rpc_write(conn, &length, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, version, length * sizeof(char)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&length, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)version, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(length) &&
                  is_unified_pointer(conn, (void *)version);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&version[i],
                               cudaMemcpyDeviceToHost) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlSystemGetNVMLVersion(char *version, unsigned int length) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&length, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)version, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(length) &&
                  is_unified_pointer(conn, (void *)version);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&version[i],
                               cudaMemcpyHostToDevice) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlSystemGetNVMLVersion) < 0 ||
      rpc_write(conn, &length, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, version, length * sizeof(char)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&length, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)version, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(length) &&
                  is_unified_pointer(conn, (void *)version);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&version[i],
                               cudaMemcpyDeviceToHost) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlSystemGetCudaDriverVersion(int *cudaDriverVersion) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)cudaDriverVersion,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlSystemGetCudaDriverVersion) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, cudaDriverVersion, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)cudaDriverVersion,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlSystemGetCudaDriverVersion_v2(int *cudaDriverVersion) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)cudaDriverVersion,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlSystemGetCudaDriverVersion_v2) <
          0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, cudaDriverVersion, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)cudaDriverVersion,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlSystemGetProcessName(unsigned int pid, char *name,
                                      unsigned int length) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&pid, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&length, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)name, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0;
       i < static_cast<int>(length) && is_unified_pointer(conn, (void *)name);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&name[i], cudaMemcpyHostToDevice) <
        0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlSystemGetProcessName) < 0 ||
      rpc_write(conn, &pid, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &length, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, name, length * sizeof(char)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&pid, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&length, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)name, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0;
       i < static_cast<int>(length) && is_unified_pointer(conn, (void *)name);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&name[i], cudaMemcpyDeviceToHost) <
        0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlUnitGetCount(unsigned int *unitCount) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)unitCount, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlUnitGetCount) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, unitCount, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)unitCount, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlUnitGetHandleByIndex(unsigned int index, nvmlUnit_t *unit) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&index, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)unit, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlUnitGetHandleByIndex) < 0 ||
      rpc_write(conn, &index, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, unit, sizeof(nvmlUnit_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&index, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)unit, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlUnitGetUnitInfo(nvmlUnit_t unit, nvmlUnitInfo_t *info) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&unit, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)info, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlUnitGetUnitInfo) < 0 ||
      rpc_write(conn, &unit, sizeof(nvmlUnit_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, info, sizeof(nvmlUnitInfo_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&unit, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)info, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlUnitGetLedState(nvmlUnit_t unit, nvmlLedState_t *state) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&unit, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)state, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlUnitGetLedState) < 0 ||
      rpc_write(conn, &unit, sizeof(nvmlUnit_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, state, sizeof(nvmlLedState_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&unit, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)state, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlUnitGetPsuInfo(nvmlUnit_t unit, nvmlPSUInfo_t *psu) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&unit, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)psu, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlUnitGetPsuInfo) < 0 ||
      rpc_write(conn, &unit, sizeof(nvmlUnit_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, psu, sizeof(nvmlPSUInfo_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&unit, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)psu, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlUnitGetTemperature(nvmlUnit_t unit, unsigned int type,
                                    unsigned int *temp) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&unit, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&type, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)temp, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlUnitGetTemperature) < 0 ||
      rpc_write(conn, &unit, sizeof(nvmlUnit_t)) < 0 ||
      rpc_write(conn, &type, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, temp, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&unit, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&type, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)temp, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlUnitGetFanSpeedInfo(nvmlUnit_t unit,
                                     nvmlUnitFanSpeeds_t *fanSpeeds) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&unit, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)fanSpeeds, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlUnitGetFanSpeedInfo) < 0 ||
      rpc_write(conn, &unit, sizeof(nvmlUnit_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, fanSpeeds, sizeof(nvmlUnitFanSpeeds_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&unit, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)fanSpeeds, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlUnitGetDevices(nvmlUnit_t unit, unsigned int *deviceCount,
                                nvmlDevice_t *devices) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&unit, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)deviceCount,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)devices, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*deviceCount) &&
                  is_unified_pointer(conn, (void *)devices);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&devices[i],
                               cudaMemcpyHostToDevice) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlUnitGetDevices) < 0 ||
      rpc_write(conn, &unit, sizeof(nvmlUnit_t)) < 0 ||
      rpc_write(conn, deviceCount, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, deviceCount, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, devices, *deviceCount * sizeof(nvmlDevice_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&unit, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)deviceCount,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)devices, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*deviceCount) &&
                  is_unified_pointer(conn, (void *)devices);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&devices[i],
                               cudaMemcpyDeviceToHost) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlSystemGetHicVersion(unsigned int *hwbcCount,
                                     nvmlHwbcEntry_t *hwbcEntries) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)hwbcCount, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)hwbcEntries,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*hwbcCount) &&
                  is_unified_pointer(conn, (void *)hwbcEntries);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&hwbcEntries[i],
                               cudaMemcpyHostToDevice) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlSystemGetHicVersion) < 0 ||
      rpc_write(conn, hwbcCount, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, hwbcCount, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, hwbcEntries, *hwbcCount * sizeof(nvmlHwbcEntry_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)hwbcCount, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)hwbcEntries,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*hwbcCount) &&
                  is_unified_pointer(conn, (void *)hwbcEntries);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&hwbcEntries[i],
                               cudaMemcpyDeviceToHost) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetCount_v2(unsigned int *deviceCount) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)deviceCount,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetCount_v2) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, deviceCount, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)deviceCount,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetAttributes_v2(nvmlDevice_t device,
                                        nvmlDeviceAttributes_t *attributes) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)attributes, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetAttributes_v2) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, attributes, sizeof(nvmlDeviceAttributes_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)attributes, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetHandleByIndex_v2(unsigned int index,
                                           nvmlDevice_t *device) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&index, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetHandleByIndex_v2) < 0 ||
      rpc_write(conn, &index, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&index, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetHandleBySerial(const char *serial,
                                         nvmlDevice_t *device) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)serial, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  std::size_t serial_len = std::strlen(serial) + 1;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetHandleBySerial) < 0 ||
      rpc_write(conn, &serial_len, sizeof(std::size_t)) < 0 ||
      rpc_write(conn, serial, serial_len) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)serial, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetHandleByUUID(const char *uuid, nvmlDevice_t *device) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)uuid, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  std::size_t uuid_len = std::strlen(uuid) + 1;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetHandleByUUID) < 0 ||
      rpc_write(conn, &uuid_len, sizeof(std::size_t)) < 0 ||
      rpc_write(conn, uuid, uuid_len) < 0 || rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)uuid, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetHandleByPciBusId_v2(const char *pciBusId,
                                              nvmlDevice_t *device) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pciBusId, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  std::size_t pciBusId_len = std::strlen(pciBusId) + 1;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetHandleByPciBusId_v2) < 0 ||
      rpc_write(conn, &pciBusId_len, sizeof(std::size_t)) < 0 ||
      rpc_write(conn, pciBusId, pciBusId_len) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pciBusId, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetName(nvmlDevice_t device, char *name,
                               unsigned int length) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&length, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)name, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0;
       i < static_cast<int>(length) && is_unified_pointer(conn, (void *)name);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&name[i], cudaMemcpyHostToDevice) <
        0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetName) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &length, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, name, length * sizeof(char)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&length, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)name, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0;
       i < static_cast<int>(length) && is_unified_pointer(conn, (void *)name);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&name[i], cudaMemcpyDeviceToHost) <
        0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetBrand(nvmlDevice_t device, nvmlBrandType_t *type) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)type, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetBrand) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, type, sizeof(nvmlBrandType_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)type, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetIndex(nvmlDevice_t device, unsigned int *index) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)index, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetIndex) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, index, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)index, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetSerial(nvmlDevice_t device, char *serial,
                                 unsigned int length) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&length, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)serial, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0;
       i < static_cast<int>(length) && is_unified_pointer(conn, (void *)serial);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&serial[i],
                               cudaMemcpyHostToDevice) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetSerial) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &length, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, serial, length * sizeof(char)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&length, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)serial, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0;
       i < static_cast<int>(length) && is_unified_pointer(conn, (void *)serial);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&serial[i],
                               cudaMemcpyDeviceToHost) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetMemoryAffinity(nvmlDevice_t device,
                                         unsigned int nodeSetSize,
                                         unsigned long *nodeSet,
                                         nvmlAffinityScope_t scope) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&nodeSetSize,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)nodeSet, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(nodeSetSize) &&
                  is_unified_pointer(conn, (void *)nodeSet);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&nodeSet[i],
                               cudaMemcpyHostToDevice) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&scope, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetMemoryAffinity) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &nodeSetSize, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &scope, sizeof(nvmlAffinityScope_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, nodeSet, nodeSetSize * sizeof(unsigned long)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&nodeSetSize,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)nodeSet, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(nodeSetSize) &&
                  is_unified_pointer(conn, (void *)nodeSet);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&nodeSet[i],
                               cudaMemcpyDeviceToHost) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&scope, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetCpuAffinityWithinScope(nvmlDevice_t device,
                                                 unsigned int cpuSetSize,
                                                 unsigned long *cpuSet,
                                                 nvmlAffinityScope_t scope) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&cpuSetSize,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)cpuSet, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(cpuSetSize) &&
                  is_unified_pointer(conn, (void *)cpuSet);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&cpuSet[i],
                               cudaMemcpyHostToDevice) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&scope, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetCpuAffinityWithinScope) <
          0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &cpuSetSize, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &scope, sizeof(nvmlAffinityScope_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, cpuSet, cpuSetSize * sizeof(unsigned long)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&cpuSetSize,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)cpuSet, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(cpuSetSize) &&
                  is_unified_pointer(conn, (void *)cpuSet);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&cpuSet[i],
                               cudaMemcpyDeviceToHost) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&scope, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetCpuAffinity(nvmlDevice_t device,
                                      unsigned int cpuSetSize,
                                      unsigned long *cpuSet) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&cpuSetSize,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)cpuSet, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(cpuSetSize) &&
                  is_unified_pointer(conn, (void *)cpuSet);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&cpuSet[i],
                               cudaMemcpyHostToDevice) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetCpuAffinity) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &cpuSetSize, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, cpuSet, cpuSetSize * sizeof(unsigned long)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&cpuSetSize,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)cpuSet, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(cpuSetSize) &&
                  is_unified_pointer(conn, (void *)cpuSet);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&cpuSet[i],
                               cudaMemcpyDeviceToHost) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceSetCpuAffinity(nvmlDevice_t device) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceSetCpuAffinity) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceClearCpuAffinity(nvmlDevice_t device) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceClearCpuAffinity) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t
nvmlDeviceGetTopologyCommonAncestor(nvmlDevice_t device1, nvmlDevice_t device2,
                                    nvmlGpuTopologyLevel_t *pathInfo) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device1, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device2, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pathInfo, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetTopologyCommonAncestor) <
          0 ||
      rpc_write(conn, &device1, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &device2, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pathInfo, sizeof(nvmlGpuTopologyLevel_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device1, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device2, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pathInfo, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetTopologyNearestGpus(nvmlDevice_t device,
                                              nvmlGpuTopologyLevel_t level,
                                              unsigned int *count,
                                              nvmlDevice_t *deviceArray) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&level, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)count, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)deviceArray,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*count) &&
                  is_unified_pointer(conn, (void *)deviceArray);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&deviceArray[i],
                               cudaMemcpyHostToDevice) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetTopologyNearestGpus) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &level, sizeof(nvmlGpuTopologyLevel_t)) < 0 ||
      rpc_write(conn, count, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, count, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, deviceArray, *count * sizeof(nvmlDevice_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&level, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)count, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)deviceArray,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*count) &&
                  is_unified_pointer(conn, (void *)deviceArray);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&deviceArray[i],
                               cudaMemcpyDeviceToHost) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlSystemGetTopologyGpuSet(unsigned int cpuNumber,
                                         unsigned int *count,
                                         nvmlDevice_t *deviceArray) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&cpuNumber, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)count, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)deviceArray,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*count) &&
                  is_unified_pointer(conn, (void *)deviceArray);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&deviceArray[i],
                               cudaMemcpyHostToDevice) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlSystemGetTopologyGpuSet) < 0 ||
      rpc_write(conn, &cpuNumber, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, count, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, count, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, deviceArray, *count * sizeof(nvmlDevice_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&cpuNumber, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)count, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)deviceArray,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*count) &&
                  is_unified_pointer(conn, (void *)deviceArray);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&deviceArray[i],
                               cudaMemcpyDeviceToHost) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetP2PStatus(nvmlDevice_t device1, nvmlDevice_t device2,
                                    nvmlGpuP2PCapsIndex_t p2pIndex,
                                    nvmlGpuP2PStatus_t *p2pStatus) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device1, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device2, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&p2pIndex, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)p2pStatus, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetP2PStatus) < 0 ||
      rpc_write(conn, &device1, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &device2, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &p2pIndex, sizeof(nvmlGpuP2PCapsIndex_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, p2pStatus, sizeof(nvmlGpuP2PStatus_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device1, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device2, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&p2pIndex, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)p2pStatus, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetUUID(nvmlDevice_t device, char *uuid,
                               unsigned int length) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&length, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)uuid, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0;
       i < static_cast<int>(length) && is_unified_pointer(conn, (void *)uuid);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&uuid[i], cudaMemcpyHostToDevice) <
        0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetUUID) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &length, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, uuid, length * sizeof(char)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&length, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)uuid, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0;
       i < static_cast<int>(length) && is_unified_pointer(conn, (void *)uuid);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&uuid[i], cudaMemcpyDeviceToHost) <
        0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlVgpuInstanceGetMdevUUID(nvmlVgpuInstance_t vgpuInstance,
                                         char *mdevUuid, unsigned int size) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&vgpuInstance,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&size, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)mdevUuid, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0;
       i < static_cast<int>(size) && is_unified_pointer(conn, (void *)mdevUuid);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&mdevUuid[i],
                               cudaMemcpyHostToDevice) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlVgpuInstanceGetMdevUUID) < 0 ||
      rpc_write(conn, &vgpuInstance, sizeof(nvmlVgpuInstance_t)) < 0 ||
      rpc_write(conn, &size, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, mdevUuid, size * sizeof(char)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&vgpuInstance,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&size, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)mdevUuid, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0;
       i < static_cast<int>(size) && is_unified_pointer(conn, (void *)mdevUuid);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&mdevUuid[i],
                               cudaMemcpyDeviceToHost) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetMinorNumber(nvmlDevice_t device,
                                      unsigned int *minorNumber) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)minorNumber,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetMinorNumber) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, minorNumber, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)minorNumber,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetBoardPartNumber(nvmlDevice_t device, char *partNumber,
                                          unsigned int length) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&length, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)partNumber, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(length) &&
                  is_unified_pointer(conn, (void *)partNumber);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&partNumber[i],
                               cudaMemcpyHostToDevice) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetBoardPartNumber) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &length, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, partNumber, length * sizeof(char)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&length, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)partNumber, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(length) &&
                  is_unified_pointer(conn, (void *)partNumber);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&partNumber[i],
                               cudaMemcpyDeviceToHost) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetInforomVersion(nvmlDevice_t device,
                                         nvmlInforomObject_t object,
                                         char *version, unsigned int length) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&object, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&length, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)version, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(length) &&
                  is_unified_pointer(conn, (void *)version);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&version[i],
                               cudaMemcpyHostToDevice) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetInforomVersion) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &object, sizeof(nvmlInforomObject_t)) < 0 ||
      rpc_write(conn, &length, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, version, length * sizeof(char)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&object, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&length, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)version, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(length) &&
                  is_unified_pointer(conn, (void *)version);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&version[i],
                               cudaMemcpyDeviceToHost) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetInforomImageVersion(nvmlDevice_t device,
                                              char *version,
                                              unsigned int length) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&length, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)version, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(length) &&
                  is_unified_pointer(conn, (void *)version);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&version[i],
                               cudaMemcpyHostToDevice) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetInforomImageVersion) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &length, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, version, length * sizeof(char)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&length, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)version, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(length) &&
                  is_unified_pointer(conn, (void *)version);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&version[i],
                               cudaMemcpyDeviceToHost) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetInforomConfigurationChecksum(nvmlDevice_t device,
                                                       unsigned int *checksum) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)checksum, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(
          conn, RPC_nvmlDeviceGetInforomConfigurationChecksum) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, checksum, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)checksum, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceValidateInforom(nvmlDevice_t device) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceValidateInforom) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetDisplayMode(nvmlDevice_t device,
                                      nvmlEnableState_t *display) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)display, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetDisplayMode) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, display, sizeof(nvmlEnableState_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)display, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetDisplayActive(nvmlDevice_t device,
                                        nvmlEnableState_t *isActive) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)isActive, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetDisplayActive) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, isActive, sizeof(nvmlEnableState_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)isActive, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetPersistenceMode(nvmlDevice_t device,
                                          nvmlEnableState_t *mode) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)mode, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetPersistenceMode) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, mode, sizeof(nvmlEnableState_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)mode, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetPciInfo_v3(nvmlDevice_t device, nvmlPciInfo_t *pci) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pci, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetPciInfo_v3) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pci, sizeof(nvmlPciInfo_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pci, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetMaxPcieLinkGeneration(nvmlDevice_t device,
                                                unsigned int *maxLinkGen) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)maxLinkGen, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetMaxPcieLinkGeneration) <
          0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, maxLinkGen, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)maxLinkGen, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t
nvmlDeviceGetGpuMaxPcieLinkGeneration(nvmlDevice_t device,
                                      unsigned int *maxLinkGenDevice) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)maxLinkGenDevice,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetGpuMaxPcieLinkGeneration) <
          0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, maxLinkGenDevice, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)maxLinkGenDevice,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetMaxPcieLinkWidth(nvmlDevice_t device,
                                           unsigned int *maxLinkWidth) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)maxLinkWidth,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetMaxPcieLinkWidth) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, maxLinkWidth, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)maxLinkWidth,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetCurrPcieLinkGeneration(nvmlDevice_t device,
                                                 unsigned int *currLinkGen) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)currLinkGen,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetCurrPcieLinkGeneration) <
          0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, currLinkGen, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)currLinkGen,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetCurrPcieLinkWidth(nvmlDevice_t device,
                                            unsigned int *currLinkWidth) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)currLinkWidth,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetCurrPcieLinkWidth) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, currLinkWidth, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)currLinkWidth,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetPcieThroughput(nvmlDevice_t device,
                                         nvmlPcieUtilCounter_t counter,
                                         unsigned int *value) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&counter, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)value, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetPcieThroughput) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &counter, sizeof(nvmlPcieUtilCounter_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, value, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&counter, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)value, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetPcieReplayCounter(nvmlDevice_t device,
                                            unsigned int *value) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)value, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetPcieReplayCounter) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, value, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)value, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetClockInfo(nvmlDevice_t device, nvmlClockType_t type,
                                    unsigned int *clock) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&type, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)clock, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetClockInfo) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &type, sizeof(nvmlClockType_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, clock, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&type, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)clock, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetMaxClockInfo(nvmlDevice_t device,
                                       nvmlClockType_t type,
                                       unsigned int *clock) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&type, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)clock, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetMaxClockInfo) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &type, sizeof(nvmlClockType_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, clock, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&type, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)clock, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetApplicationsClock(nvmlDevice_t device,
                                            nvmlClockType_t clockType,
                                            unsigned int *clockMHz) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&clockType, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)clockMHz, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetApplicationsClock) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &clockType, sizeof(nvmlClockType_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, clockMHz, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&clockType, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)clockMHz, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetDefaultApplicationsClock(nvmlDevice_t device,
                                                   nvmlClockType_t clockType,
                                                   unsigned int *clockMHz) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&clockType, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)clockMHz, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetDefaultApplicationsClock) <
          0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &clockType, sizeof(nvmlClockType_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, clockMHz, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&clockType, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)clockMHz, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceResetApplicationsClocks(nvmlDevice_t device) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceResetApplicationsClocks) <
          0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetClock(nvmlDevice_t device, nvmlClockType_t clockType,
                                nvmlClockId_t clockId, unsigned int *clockMHz) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&clockType, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&clockId, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)clockMHz, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetClock) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &clockType, sizeof(nvmlClockType_t)) < 0 ||
      rpc_write(conn, &clockId, sizeof(nvmlClockId_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, clockMHz, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&clockType, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&clockId, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)clockMHz, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetMaxCustomerBoostClock(nvmlDevice_t device,
                                                nvmlClockType_t clockType,
                                                unsigned int *clockMHz) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&clockType, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)clockMHz, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetMaxCustomerBoostClock) <
          0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &clockType, sizeof(nvmlClockType_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, clockMHz, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&clockType, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)clockMHz, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetSupportedMemoryClocks(nvmlDevice_t device,
                                                unsigned int *count,
                                                unsigned int *clocksMHz) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)count, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)clocksMHz, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*count) &&
                  is_unified_pointer(conn, (void *)clocksMHz);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&clocksMHz[i],
                               cudaMemcpyHostToDevice) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetSupportedMemoryClocks) <
          0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, count, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, count, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, clocksMHz, *count * sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)count, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)clocksMHz, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*count) &&
                  is_unified_pointer(conn, (void *)clocksMHz);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&clocksMHz[i],
                               cudaMemcpyDeviceToHost) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetSupportedGraphicsClocks(nvmlDevice_t device,
                                                  unsigned int memoryClockMHz,
                                                  unsigned int *count,
                                                  unsigned int *clocksMHz) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&memoryClockMHz,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)count, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)clocksMHz, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*count) &&
                  is_unified_pointer(conn, (void *)clocksMHz);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&clocksMHz[i],
                               cudaMemcpyHostToDevice) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetSupportedGraphicsClocks) <
          0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &memoryClockMHz, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, count, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, count, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, clocksMHz, *count * sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&memoryClockMHz,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)count, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)clocksMHz, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*count) &&
                  is_unified_pointer(conn, (void *)clocksMHz);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&clocksMHz[i],
                               cudaMemcpyDeviceToHost) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t
nvmlDeviceGetAutoBoostedClocksEnabled(nvmlDevice_t device,
                                      nvmlEnableState_t *isEnabled,
                                      nvmlEnableState_t *defaultIsEnabled) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)isEnabled, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)defaultIsEnabled,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetAutoBoostedClocksEnabled) <
          0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, isEnabled, sizeof(nvmlEnableState_t)) < 0 ||
      rpc_read(conn, defaultIsEnabled, sizeof(nvmlEnableState_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)isEnabled, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)defaultIsEnabled,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceSetAutoBoostedClocksEnabled(nvmlDevice_t device,
                                                   nvmlEnableState_t enabled) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&enabled, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceSetAutoBoostedClocksEnabled) <
          0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &enabled, sizeof(nvmlEnableState_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&enabled, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceSetDefaultAutoBoostedClocksEnabled(
    nvmlDevice_t device, nvmlEnableState_t enabled, unsigned int flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&enabled, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(
          conn, RPC_nvmlDeviceSetDefaultAutoBoostedClocksEnabled) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &enabled, sizeof(nvmlEnableState_t)) < 0 ||
      rpc_write(conn, &flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&enabled, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetFanSpeed(nvmlDevice_t device, unsigned int *speed) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)speed, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetFanSpeed) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, speed, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)speed, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetFanSpeed_v2(nvmlDevice_t device, unsigned int fan,
                                      unsigned int *speed) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&fan, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)speed, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetFanSpeed_v2) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &fan, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, speed, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&fan, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)speed, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetTargetFanSpeed(nvmlDevice_t device, unsigned int fan,
                                         unsigned int *targetSpeed) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&fan, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)targetSpeed,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetTargetFanSpeed) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &fan, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, targetSpeed, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&fan, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)targetSpeed,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceSetDefaultFanSpeed_v2(nvmlDevice_t device,
                                             unsigned int fan) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&fan, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceSetDefaultFanSpeed_v2) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &fan, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&fan, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetMinMaxFanSpeed(nvmlDevice_t device,
                                         unsigned int *minSpeed,
                                         unsigned int *maxSpeed) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)minSpeed, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)maxSpeed, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetMinMaxFanSpeed) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, minSpeed, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, maxSpeed, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)minSpeed, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)maxSpeed, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetFanControlPolicy_v2(nvmlDevice_t device,
                                              unsigned int fan,
                                              nvmlFanControlPolicy_t *policy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&fan, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)policy, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetFanControlPolicy_v2) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &fan, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, policy, sizeof(nvmlFanControlPolicy_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&fan, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)policy, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceSetFanControlPolicy(nvmlDevice_t device,
                                           unsigned int fan,
                                           nvmlFanControlPolicy_t policy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&fan, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&policy, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceSetFanControlPolicy) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &fan, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &policy, sizeof(nvmlFanControlPolicy_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&fan, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&policy, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetNumFans(nvmlDevice_t device, unsigned int *numFans) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)numFans, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetNumFans) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, numFans, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)numFans, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetTemperature(nvmlDevice_t device,
                                      nvmlTemperatureSensors_t sensorType,
                                      unsigned int *temp) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&sensorType,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)temp, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetTemperature) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &sensorType, sizeof(nvmlTemperatureSensors_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, temp, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&sensorType,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)temp, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t
nvmlDeviceGetTemperatureThreshold(nvmlDevice_t device,
                                  nvmlTemperatureThresholds_t thresholdType,
                                  unsigned int *temp) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&thresholdType,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)temp, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetTemperatureThreshold) <
          0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &thresholdType, sizeof(nvmlTemperatureThresholds_t)) <
          0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, temp, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&thresholdType,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)temp, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceSetTemperatureThreshold(
    nvmlDevice_t device, nvmlTemperatureThresholds_t thresholdType, int *temp) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&thresholdType,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)temp, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceSetTemperatureThreshold) <
          0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &thresholdType, sizeof(nvmlTemperatureThresholds_t)) <
          0 ||
      rpc_write(conn, temp, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, temp, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&thresholdType,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)temp, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t
nvmlDeviceGetThermalSettings(nvmlDevice_t device, unsigned int sensorIndex,
                             nvmlGpuThermalSettings_t *pThermalSettings) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&sensorIndex,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pThermalSettings,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetThermalSettings) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &sensorIndex, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pThermalSettings, sizeof(nvmlGpuThermalSettings_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&sensorIndex,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pThermalSettings,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetPerformanceState(nvmlDevice_t device,
                                           nvmlPstates_t *pState) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pState, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetPerformanceState) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pState, sizeof(nvmlPstates_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pState, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetCurrentClocksThrottleReasons(
    nvmlDevice_t device, unsigned long long *clocksThrottleReasons) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)clocksThrottleReasons,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(
          conn, RPC_nvmlDeviceGetCurrentClocksThrottleReasons) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, clocksThrottleReasons, sizeof(unsigned long long)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)clocksThrottleReasons,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetSupportedClocksThrottleReasons(
    nvmlDevice_t device, unsigned long long *supportedClocksThrottleReasons) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)supportedClocksThrottleReasons,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(
          conn, RPC_nvmlDeviceGetSupportedClocksThrottleReasons) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, supportedClocksThrottleReasons,
               sizeof(unsigned long long)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)supportedClocksThrottleReasons,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetPowerState(nvmlDevice_t device,
                                     nvmlPstates_t *pState) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pState, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetPowerState) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pState, sizeof(nvmlPstates_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pState, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetPowerManagementMode(nvmlDevice_t device,
                                              nvmlEnableState_t *mode) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)mode, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetPowerManagementMode) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, mode, sizeof(nvmlEnableState_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)mode, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetPowerManagementLimit(nvmlDevice_t device,
                                               unsigned int *limit) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)limit, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetPowerManagementLimit) <
          0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, limit, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)limit, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetPowerManagementLimitConstraints(
    nvmlDevice_t device, unsigned int *minLimit, unsigned int *maxLimit) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)minLimit, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)maxLimit, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(
          conn, RPC_nvmlDeviceGetPowerManagementLimitConstraints) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, minLimit, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, maxLimit, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)minLimit, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)maxLimit, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t
nvmlDeviceGetPowerManagementDefaultLimit(nvmlDevice_t device,
                                         unsigned int *defaultLimit) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)defaultLimit,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(
          conn, RPC_nvmlDeviceGetPowerManagementDefaultLimit) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, defaultLimit, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)defaultLimit,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetPowerUsage(nvmlDevice_t device, unsigned int *power) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)power, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetPowerUsage) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, power, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)power, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetTotalEnergyConsumption(nvmlDevice_t device,
                                                 unsigned long long *energy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)energy, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetTotalEnergyConsumption) <
          0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, energy, sizeof(unsigned long long)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)energy, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetEnforcedPowerLimit(nvmlDevice_t device,
                                             unsigned int *limit) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)limit, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetEnforcedPowerLimit) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, limit, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)limit, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetGpuOperationMode(nvmlDevice_t device,
                                           nvmlGpuOperationMode_t *current,
                                           nvmlGpuOperationMode_t *pending) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)current, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pending, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetGpuOperationMode) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, current, sizeof(nvmlGpuOperationMode_t)) < 0 ||
      rpc_read(conn, pending, sizeof(nvmlGpuOperationMode_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)current, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pending, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetMemoryInfo(nvmlDevice_t device,
                                     nvmlMemory_t *memory) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)memory, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetMemoryInfo) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, memory, sizeof(nvmlMemory_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)memory, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetMemoryInfo_v2(nvmlDevice_t device,
                                        nvmlMemory_v2_t *memory) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)memory, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetMemoryInfo_v2) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, memory, sizeof(nvmlMemory_v2_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)memory, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetComputeMode(nvmlDevice_t device,
                                      nvmlComputeMode_t *mode) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)mode, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetComputeMode) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, mode, sizeof(nvmlComputeMode_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)mode, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetCudaComputeCapability(nvmlDevice_t device, int *major,
                                                int *minor) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)major, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)minor, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetCudaComputeCapability) <
          0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, major, sizeof(int)) < 0 ||
      rpc_read(conn, minor, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)major, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)minor, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetEccMode(nvmlDevice_t device,
                                  nvmlEnableState_t *current,
                                  nvmlEnableState_t *pending) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)current, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pending, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetEccMode) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, current, sizeof(nvmlEnableState_t)) < 0 ||
      rpc_read(conn, pending, sizeof(nvmlEnableState_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)current, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pending, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetDefaultEccMode(nvmlDevice_t device,
                                         nvmlEnableState_t *defaultMode) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)defaultMode,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetDefaultEccMode) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, defaultMode, sizeof(nvmlEnableState_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)defaultMode,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetBoardId(nvmlDevice_t device, unsigned int *boardId) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)boardId, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetBoardId) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, boardId, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)boardId, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetMultiGpuBoard(nvmlDevice_t device,
                                        unsigned int *multiGpuBool) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)multiGpuBool,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetMultiGpuBoard) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, multiGpuBool, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)multiGpuBool,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetTotalEccErrors(nvmlDevice_t device,
                                         nvmlMemoryErrorType_t errorType,
                                         nvmlEccCounterType_t counterType,
                                         unsigned long long *eccCounts) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&errorType, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&counterType,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)eccCounts, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetTotalEccErrors) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &errorType, sizeof(nvmlMemoryErrorType_t)) < 0 ||
      rpc_write(conn, &counterType, sizeof(nvmlEccCounterType_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, eccCounts, sizeof(unsigned long long)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&errorType, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&counterType,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)eccCounts, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetDetailedEccErrors(nvmlDevice_t device,
                                            nvmlMemoryErrorType_t errorType,
                                            nvmlEccCounterType_t counterType,
                                            nvmlEccErrorCounts_t *eccCounts) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&errorType, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&counterType,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)eccCounts, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetDetailedEccErrors) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &errorType, sizeof(nvmlMemoryErrorType_t)) < 0 ||
      rpc_write(conn, &counterType, sizeof(nvmlEccCounterType_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, eccCounts, sizeof(nvmlEccErrorCounts_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&errorType, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&counterType,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)eccCounts, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetMemoryErrorCounter(nvmlDevice_t device,
                                             nvmlMemoryErrorType_t errorType,
                                             nvmlEccCounterType_t counterType,
                                             nvmlMemoryLocation_t locationType,
                                             unsigned long long *count) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&errorType, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&counterType,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&locationType,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)count, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetMemoryErrorCounter) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &errorType, sizeof(nvmlMemoryErrorType_t)) < 0 ||
      rpc_write(conn, &counterType, sizeof(nvmlEccCounterType_t)) < 0 ||
      rpc_write(conn, &locationType, sizeof(nvmlMemoryLocation_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, count, sizeof(unsigned long long)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&errorType, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&counterType,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&locationType,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)count, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetUtilizationRates(nvmlDevice_t device,
                                           nvmlUtilization_t *utilization) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)utilization,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetUtilizationRates) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, utilization, sizeof(nvmlUtilization_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)utilization,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetEncoderUtilization(nvmlDevice_t device,
                                             unsigned int *utilization,
                                             unsigned int *samplingPeriodUs) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)utilization,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)samplingPeriodUs,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetEncoderUtilization) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, utilization, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, samplingPeriodUs, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)utilization,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)samplingPeriodUs,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetEncoderCapacity(nvmlDevice_t device,
                                          nvmlEncoderType_t encoderQueryType,
                                          unsigned int *encoderCapacity) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&encoderQueryType,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)encoderCapacity,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetEncoderCapacity) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &encoderQueryType, sizeof(nvmlEncoderType_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, encoderCapacity, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&encoderQueryType,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)encoderCapacity,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetEncoderStats(nvmlDevice_t device,
                                       unsigned int *sessionCount,
                                       unsigned int *averageFps,
                                       unsigned int *averageLatency) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)sessionCount,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)averageFps, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)averageLatency,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetEncoderStats) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, sessionCount, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, averageFps, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, averageLatency, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)sessionCount,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)averageFps, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)averageLatency,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t
nvmlDeviceGetEncoderSessions(nvmlDevice_t device, unsigned int *sessionCount,
                             nvmlEncoderSessionInfo_t *sessionInfos) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)sessionCount,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)sessionInfos,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*sessionCount) &&
                  is_unified_pointer(conn, (void *)sessionInfos);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&sessionInfos[i],
                               cudaMemcpyHostToDevice) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetEncoderSessions) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, sessionCount, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, sessionCount, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, sessionInfos,
               *sessionCount * sizeof(nvmlEncoderSessionInfo_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)sessionCount,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)sessionInfos,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*sessionCount) &&
                  is_unified_pointer(conn, (void *)sessionInfos);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&sessionInfos[i],
                               cudaMemcpyDeviceToHost) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetDecoderUtilization(nvmlDevice_t device,
                                             unsigned int *utilization,
                                             unsigned int *samplingPeriodUs) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)utilization,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)samplingPeriodUs,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetDecoderUtilization) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, utilization, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, samplingPeriodUs, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)utilization,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)samplingPeriodUs,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetFBCStats(nvmlDevice_t device,
                                   nvmlFBCStats_t *fbcStats) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)fbcStats, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetFBCStats) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, fbcStats, sizeof(nvmlFBCStats_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)fbcStats, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetFBCSessions(nvmlDevice_t device,
                                      unsigned int *sessionCount,
                                      nvmlFBCSessionInfo_t *sessionInfo) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)sessionCount,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)sessionInfo,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*sessionCount) &&
                  is_unified_pointer(conn, (void *)sessionInfo);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&sessionInfo[i],
                               cudaMemcpyHostToDevice) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetFBCSessions) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, sessionCount, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, sessionCount, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, sessionInfo,
               *sessionCount * sizeof(nvmlFBCSessionInfo_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)sessionCount,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)sessionInfo,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*sessionCount) &&
                  is_unified_pointer(conn, (void *)sessionInfo);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&sessionInfo[i],
                               cudaMemcpyDeviceToHost) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetVbiosVersion(nvmlDevice_t device, char *version,
                                       unsigned int length) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&length, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)version, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(length) &&
                  is_unified_pointer(conn, (void *)version);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&version[i],
                               cudaMemcpyHostToDevice) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetVbiosVersion) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &length, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, version, length * sizeof(char)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&length, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)version, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(length) &&
                  is_unified_pointer(conn, (void *)version);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&version[i],
                               cudaMemcpyDeviceToHost) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t
nvmlDeviceGetBridgeChipInfo(nvmlDevice_t device,
                            nvmlBridgeChipHierarchy_t *bridgeHierarchy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)bridgeHierarchy,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetBridgeChipInfo) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, bridgeHierarchy, sizeof(nvmlBridgeChipHierarchy_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)bridgeHierarchy,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetComputeRunningProcesses_v3(nvmlDevice_t device,
                                                     unsigned int *infoCount,
                                                     nvmlProcessInfo_t *infos) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)infoCount, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)infos, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*infoCount) &&
                  is_unified_pointer(conn, (void *)infos);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&infos[i],
                               cudaMemcpyHostToDevice) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(
          conn, RPC_nvmlDeviceGetComputeRunningProcesses_v3) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, infoCount, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, infoCount, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, infos, *infoCount * sizeof(nvmlProcessInfo_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)infoCount, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)infos, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*infoCount) &&
                  is_unified_pointer(conn, (void *)infos);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&infos[i],
                               cudaMemcpyDeviceToHost) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetGraphicsRunningProcesses_v3(
    nvmlDevice_t device, unsigned int *infoCount, nvmlProcessInfo_t *infos) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)infoCount, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)infos, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*infoCount) &&
                  is_unified_pointer(conn, (void *)infos);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&infos[i],
                               cudaMemcpyHostToDevice) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(
          conn, RPC_nvmlDeviceGetGraphicsRunningProcesses_v3) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, infoCount, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, infoCount, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, infos, *infoCount * sizeof(nvmlProcessInfo_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)infoCount, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)infos, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*infoCount) &&
                  is_unified_pointer(conn, (void *)infos);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&infos[i],
                               cudaMemcpyDeviceToHost) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetMPSComputeRunningProcesses_v3(
    nvmlDevice_t device, unsigned int *infoCount, nvmlProcessInfo_t *infos) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)infoCount, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)infos, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*infoCount) &&
                  is_unified_pointer(conn, (void *)infos);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&infos[i],
                               cudaMemcpyHostToDevice) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(
          conn, RPC_nvmlDeviceGetMPSComputeRunningProcesses_v3) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, infoCount, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, infoCount, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, infos, *infoCount * sizeof(nvmlProcessInfo_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)infoCount, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)infos, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*infoCount) &&
                  is_unified_pointer(conn, (void *)infos);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&infos[i],
                               cudaMemcpyDeviceToHost) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceOnSameBoard(nvmlDevice_t device1, nvmlDevice_t device2,
                                   int *onSameBoard) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device1, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device2, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)onSameBoard,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceOnSameBoard) < 0 ||
      rpc_write(conn, &device1, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &device2, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, onSameBoard, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device1, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device2, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)onSameBoard,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetAPIRestriction(nvmlDevice_t device,
                                         nvmlRestrictedAPI_t apiType,
                                         nvmlEnableState_t *isRestricted) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&apiType, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)isRestricted,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetAPIRestriction) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &apiType, sizeof(nvmlRestrictedAPI_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, isRestricted, sizeof(nvmlEnableState_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&apiType, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)isRestricted,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetSamples(nvmlDevice_t device, nvmlSamplingType_t type,
                                  unsigned long long lastSeenTimeStamp,
                                  nvmlValueType_t *sampleValType,
                                  unsigned int *sampleCount,
                                  nvmlSample_t *samples) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&type, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&lastSeenTimeStamp,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)sampleValType,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)sampleCount,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)samples, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*sampleCount) &&
                  is_unified_pointer(conn, (void *)samples);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&samples[i],
                               cudaMemcpyHostToDevice) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetSamples) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &type, sizeof(nvmlSamplingType_t)) < 0 ||
      rpc_write(conn, &lastSeenTimeStamp, sizeof(unsigned long long)) < 0 ||
      rpc_write(conn, sampleCount, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, sampleValType, sizeof(nvmlValueType_t)) < 0 ||
      rpc_read(conn, sampleCount, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, samples, *sampleCount * sizeof(nvmlSample_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&type, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&lastSeenTimeStamp,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)sampleValType,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)sampleCount,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)samples, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*sampleCount) &&
                  is_unified_pointer(conn, (void *)samples);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&samples[i],
                               cudaMemcpyDeviceToHost) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetBAR1MemoryInfo(nvmlDevice_t device,
                                         nvmlBAR1Memory_t *bar1Memory) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)bar1Memory, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetBAR1MemoryInfo) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, bar1Memory, sizeof(nvmlBAR1Memory_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)bar1Memory, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetViolationStatus(nvmlDevice_t device,
                                          nvmlPerfPolicyType_t perfPolicyType,
                                          nvmlViolationTime_t *violTime) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&perfPolicyType,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)violTime, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetViolationStatus) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &perfPolicyType, sizeof(nvmlPerfPolicyType_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, violTime, sizeof(nvmlViolationTime_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&perfPolicyType,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)violTime, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetIrqNum(nvmlDevice_t device, unsigned int *irqNum) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)irqNum, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetIrqNum) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, irqNum, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)irqNum, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetNumGpuCores(nvmlDevice_t device,
                                      unsigned int *numCores) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)numCores, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetNumGpuCores) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, numCores, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)numCores, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetPowerSource(nvmlDevice_t device,
                                      nvmlPowerSource_t *powerSource) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)powerSource,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetPowerSource) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, powerSource, sizeof(nvmlPowerSource_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)powerSource,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetMemoryBusWidth(nvmlDevice_t device,
                                         unsigned int *busWidth) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)busWidth, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetMemoryBusWidth) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, busWidth, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)busWidth, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetPcieLinkMaxSpeed(nvmlDevice_t device,
                                           unsigned int *maxSpeed) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)maxSpeed, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetPcieLinkMaxSpeed) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, maxSpeed, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)maxSpeed, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetPcieSpeed(nvmlDevice_t device,
                                    unsigned int *pcieSpeed) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pcieSpeed, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetPcieSpeed) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pcieSpeed, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pcieSpeed, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t
nvmlDeviceGetAdaptiveClockInfoStatus(nvmlDevice_t device,
                                     unsigned int *adaptiveClockStatus) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)adaptiveClockStatus,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetAdaptiveClockInfoStatus) <
          0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, adaptiveClockStatus, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)adaptiveClockStatus,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetAccountingMode(nvmlDevice_t device,
                                         nvmlEnableState_t *mode) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)mode, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetAccountingMode) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, mode, sizeof(nvmlEnableState_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)mode, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetAccountingStats(nvmlDevice_t device, unsigned int pid,
                                          nvmlAccountingStats_t *stats) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&pid, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)stats, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetAccountingStats) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &pid, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, stats, sizeof(nvmlAccountingStats_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&pid, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)stats, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetAccountingPids(nvmlDevice_t device,
                                         unsigned int *count,
                                         unsigned int *pids) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)count, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pids, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0;
       i < static_cast<int>(*count) && is_unified_pointer(conn, (void *)pids);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&pids[i], cudaMemcpyHostToDevice) <
        0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetAccountingPids) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, count, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, count, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, pids, *count * sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)count, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pids, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0;
       i < static_cast<int>(*count) && is_unified_pointer(conn, (void *)pids);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&pids[i], cudaMemcpyDeviceToHost) <
        0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetAccountingBufferSize(nvmlDevice_t device,
                                               unsigned int *bufferSize) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)bufferSize, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetAccountingBufferSize) <
          0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, bufferSize, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)bufferSize, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetRetiredPages(nvmlDevice_t device,
                                       nvmlPageRetirementCause_t cause,
                                       unsigned int *pageCount,
                                       unsigned long long *addresses) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&cause, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pageCount, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)addresses, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*pageCount) &&
                  is_unified_pointer(conn, (void *)addresses);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&addresses[i],
                               cudaMemcpyHostToDevice) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetRetiredPages) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &cause, sizeof(nvmlPageRetirementCause_t)) < 0 ||
      rpc_write(conn, pageCount, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pageCount, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, addresses, *pageCount * sizeof(unsigned long long)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&cause, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pageCount, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)addresses, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*pageCount) &&
                  is_unified_pointer(conn, (void *)addresses);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&addresses[i],
                               cudaMemcpyDeviceToHost) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetRetiredPages_v2(nvmlDevice_t device,
                                          nvmlPageRetirementCause_t cause,
                                          unsigned int *pageCount,
                                          unsigned long long *addresses,
                                          unsigned long long *timestamps) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&cause, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pageCount, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)addresses, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*pageCount) &&
                  is_unified_pointer(conn, (void *)addresses);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&addresses[i],
                               cudaMemcpyHostToDevice) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)timestamps, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*pageCount) &&
                  is_unified_pointer(conn, (void *)timestamps);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&timestamps[i],
                               cudaMemcpyHostToDevice) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetRetiredPages_v2) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &cause, sizeof(nvmlPageRetirementCause_t)) < 0 ||
      rpc_write(conn, pageCount, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pageCount, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, addresses, *pageCount * sizeof(unsigned long long)) < 0 ||
      rpc_read(conn, timestamps, *pageCount * sizeof(unsigned long long)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&cause, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pageCount, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)addresses, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*pageCount) &&
                  is_unified_pointer(conn, (void *)addresses);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&addresses[i],
                               cudaMemcpyDeviceToHost) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)timestamps, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*pageCount) &&
                  is_unified_pointer(conn, (void *)timestamps);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&timestamps[i],
                               cudaMemcpyDeviceToHost) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t
nvmlDeviceGetRetiredPagesPendingStatus(nvmlDevice_t device,
                                       nvmlEnableState_t *isPending) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)isPending, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn,
                              RPC_nvmlDeviceGetRetiredPagesPendingStatus) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, isPending, sizeof(nvmlEnableState_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)isPending, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetRemappedRows(nvmlDevice_t device,
                                       unsigned int *corrRows,
                                       unsigned int *uncRows,
                                       unsigned int *isPending,
                                       unsigned int *failureOccurred) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)corrRows, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)uncRows, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)isPending, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)failureOccurred,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetRemappedRows) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, corrRows, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, uncRows, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, isPending, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, failureOccurred, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)corrRows, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)uncRows, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)isPending, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)failureOccurred,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t
nvmlDeviceGetRowRemapperHistogram(nvmlDevice_t device,
                                  nvmlRowRemapperHistogramValues_t *values) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)values, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetRowRemapperHistogram) <
          0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, values, sizeof(nvmlRowRemapperHistogramValues_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)values, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetArchitecture(nvmlDevice_t device,
                                       nvmlDeviceArchitecture_t *arch) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)arch, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetArchitecture) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, arch, sizeof(nvmlDeviceArchitecture_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)arch, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlUnitSetLedState(nvmlUnit_t unit, nvmlLedColor_t color) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&unit, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&color, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlUnitSetLedState) < 0 ||
      rpc_write(conn, &unit, sizeof(nvmlUnit_t)) < 0 ||
      rpc_write(conn, &color, sizeof(nvmlLedColor_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&unit, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&color, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceSetPersistenceMode(nvmlDevice_t device,
                                          nvmlEnableState_t mode) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceSetPersistenceMode) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &mode, sizeof(nvmlEnableState_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceSetComputeMode(nvmlDevice_t device,
                                      nvmlComputeMode_t mode) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceSetComputeMode) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &mode, sizeof(nvmlComputeMode_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceSetEccMode(nvmlDevice_t device, nvmlEnableState_t ecc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&ecc, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceSetEccMode) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &ecc, sizeof(nvmlEnableState_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&ecc, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceClearEccErrorCounts(nvmlDevice_t device,
                                           nvmlEccCounterType_t counterType) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&counterType,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceClearEccErrorCounts) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &counterType, sizeof(nvmlEccCounterType_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&counterType,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceSetDriverModel(nvmlDevice_t device,
                                      nvmlDriverModel_t driverModel,
                                      unsigned int flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&driverModel,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceSetDriverModel) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &driverModel, sizeof(nvmlDriverModel_t)) < 0 ||
      rpc_write(conn, &flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&driverModel,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceSetGpuLockedClocks(nvmlDevice_t device,
                                          unsigned int minGpuClockMHz,
                                          unsigned int maxGpuClockMHz) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&minGpuClockMHz,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&maxGpuClockMHz,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceSetGpuLockedClocks) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &minGpuClockMHz, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &maxGpuClockMHz, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&minGpuClockMHz,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&maxGpuClockMHz,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceResetGpuLockedClocks(nvmlDevice_t device) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceResetGpuLockedClocks) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceSetMemoryLockedClocks(nvmlDevice_t device,
                                             unsigned int minMemClockMHz,
                                             unsigned int maxMemClockMHz) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&minMemClockMHz,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&maxMemClockMHz,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceSetMemoryLockedClocks) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &minMemClockMHz, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &maxMemClockMHz, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&minMemClockMHz,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&maxMemClockMHz,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceResetMemoryLockedClocks(nvmlDevice_t device) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceResetMemoryLockedClocks) <
          0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceSetApplicationsClocks(nvmlDevice_t device,
                                             unsigned int memClockMHz,
                                             unsigned int graphicsClockMHz) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&memClockMHz,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&graphicsClockMHz,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceSetApplicationsClocks) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &memClockMHz, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &graphicsClockMHz, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&memClockMHz,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&graphicsClockMHz,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetClkMonStatus(nvmlDevice_t device,
                                       nvmlClkMonStatus_t *status) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)status, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetClkMonStatus) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, status, sizeof(nvmlClkMonStatus_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)status, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceSetPowerManagementLimit(nvmlDevice_t device,
                                               unsigned int limit) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&limit, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceSetPowerManagementLimit) <
          0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &limit, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&limit, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceSetGpuOperationMode(nvmlDevice_t device,
                                           nvmlGpuOperationMode_t mode) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceSetGpuOperationMode) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &mode, sizeof(nvmlGpuOperationMode_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceSetAPIRestriction(nvmlDevice_t device,
                                         nvmlRestrictedAPI_t apiType,
                                         nvmlEnableState_t isRestricted) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&apiType, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&isRestricted,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceSetAPIRestriction) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &apiType, sizeof(nvmlRestrictedAPI_t)) < 0 ||
      rpc_write(conn, &isRestricted, sizeof(nvmlEnableState_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&apiType, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&isRestricted,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceSetAccountingMode(nvmlDevice_t device,
                                         nvmlEnableState_t mode) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceSetAccountingMode) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &mode, sizeof(nvmlEnableState_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceClearAccountingPids(nvmlDevice_t device) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceClearAccountingPids) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetNvLinkState(nvmlDevice_t device, unsigned int link,
                                      nvmlEnableState_t *isActive) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&link, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)isActive, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetNvLinkState) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &link, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, isActive, sizeof(nvmlEnableState_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&link, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)isActive, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetNvLinkVersion(nvmlDevice_t device, unsigned int link,
                                        unsigned int *version) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&link, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)version, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetNvLinkVersion) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &link, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, version, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&link, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)version, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetNvLinkCapability(nvmlDevice_t device,
                                           unsigned int link,
                                           nvmlNvLinkCapability_t capability,
                                           unsigned int *capResult) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&link, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&capability,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)capResult, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetNvLinkCapability) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &link, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &capability, sizeof(nvmlNvLinkCapability_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, capResult, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&link, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&capability,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)capResult, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetNvLinkRemotePciInfo_v2(nvmlDevice_t device,
                                                 unsigned int link,
                                                 nvmlPciInfo_t *pci) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&link, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pci, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetNvLinkRemotePciInfo_v2) <
          0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &link, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pci, sizeof(nvmlPciInfo_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&link, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pci, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetNvLinkErrorCounter(nvmlDevice_t device,
                                             unsigned int link,
                                             nvmlNvLinkErrorCounter_t counter,
                                             unsigned long long *counterValue) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&link, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&counter, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)counterValue,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetNvLinkErrorCounter) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &link, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &counter, sizeof(nvmlNvLinkErrorCounter_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, counterValue, sizeof(unsigned long long)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&link, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&counter, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)counterValue,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceResetNvLinkErrorCounters(nvmlDevice_t device,
                                                unsigned int link) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&link, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceResetNvLinkErrorCounters) <
          0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &link, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&link, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceSetNvLinkUtilizationControl(
    nvmlDevice_t device, unsigned int link, unsigned int counter,
    nvmlNvLinkUtilizationControl_t *control, unsigned int reset) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&link, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&counter, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)control, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&reset, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceSetNvLinkUtilizationControl) <
          0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &link, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &counter, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &control, sizeof(nvmlNvLinkUtilizationControl_t *)) < 0 ||
      rpc_write(conn, &reset, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&link, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&counter, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)control, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&reset, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t
nvmlDeviceGetNvLinkUtilizationControl(nvmlDevice_t device, unsigned int link,
                                      unsigned int counter,
                                      nvmlNvLinkUtilizationControl_t *control) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&link, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&counter, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)control, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetNvLinkUtilizationControl) <
          0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &link, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &counter, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, control, sizeof(nvmlNvLinkUtilizationControl_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&link, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&counter, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)control, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetNvLinkUtilizationCounter(
    nvmlDevice_t device, unsigned int link, unsigned int counter,
    unsigned long long *rxcounter, unsigned long long *txcounter) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&link, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&counter, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)rxcounter, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)txcounter, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetNvLinkUtilizationCounter) <
          0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &link, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &counter, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, rxcounter, sizeof(unsigned long long)) < 0 ||
      rpc_read(conn, txcounter, sizeof(unsigned long long)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&link, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&counter, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)rxcounter, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)txcounter, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t
nvmlDeviceFreezeNvLinkUtilizationCounter(nvmlDevice_t device, unsigned int link,
                                         unsigned int counter,
                                         nvmlEnableState_t freeze) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&link, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&counter, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&freeze, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(
          conn, RPC_nvmlDeviceFreezeNvLinkUtilizationCounter) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &link, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &counter, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &freeze, sizeof(nvmlEnableState_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&link, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&counter, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&freeze, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceResetNvLinkUtilizationCounter(nvmlDevice_t device,
                                                     unsigned int link,
                                                     unsigned int counter) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&link, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&counter, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(
          conn, RPC_nvmlDeviceResetNvLinkUtilizationCounter) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &link, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &counter, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&link, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&counter, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetNvLinkRemoteDeviceType(
    nvmlDevice_t device, unsigned int link,
    nvmlIntNvLinkDeviceType_t *pNvLinkDeviceType) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&link, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pNvLinkDeviceType,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetNvLinkRemoteDeviceType) <
          0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &link, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pNvLinkDeviceType, sizeof(nvmlIntNvLinkDeviceType_t)) <
          0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&link, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pNvLinkDeviceType,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlEventSetCreate(nvmlEventSet_t *set) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)set, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlEventSetCreate) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, set, sizeof(nvmlEventSet_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)set, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceRegisterEvents(nvmlDevice_t device,
                                      unsigned long long eventTypes,
                                      nvmlEventSet_t set) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&eventTypes,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&set, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceRegisterEvents) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &eventTypes, sizeof(unsigned long long)) < 0 ||
      rpc_write(conn, &set, sizeof(nvmlEventSet_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&eventTypes,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&set, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetSupportedEventTypes(nvmlDevice_t device,
                                              unsigned long long *eventTypes) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)eventTypes, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetSupportedEventTypes) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, eventTypes, sizeof(unsigned long long)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)eventTypes, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlEventSetWait_v2(nvmlEventSet_t set, nvmlEventData_t *data,
                                 unsigned int timeoutms) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&set, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)data, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&timeoutms, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlEventSetWait_v2) < 0 ||
      rpc_write(conn, &set, sizeof(nvmlEventSet_t)) < 0 ||
      rpc_write(conn, &timeoutms, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, data, sizeof(nvmlEventData_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&set, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)data, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&timeoutms, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlEventSetFree(nvmlEventSet_t set) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&set, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlEventSetFree) < 0 ||
      rpc_write(conn, &set, sizeof(nvmlEventSet_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&set, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceModifyDrainState(nvmlPciInfo_t *pciInfo,
                                        nvmlEnableState_t newState) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pciInfo, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&newState, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceModifyDrainState) < 0 ||
      rpc_write(conn, pciInfo, sizeof(nvmlPciInfo_t)) < 0 ||
      rpc_write(conn, &newState, sizeof(nvmlEnableState_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pciInfo, sizeof(nvmlPciInfo_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pciInfo, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&newState, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceQueryDrainState(nvmlPciInfo_t *pciInfo,
                                       nvmlEnableState_t *currentState) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pciInfo, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)currentState,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceQueryDrainState) < 0 ||
      rpc_write(conn, pciInfo, sizeof(nvmlPciInfo_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pciInfo, sizeof(nvmlPciInfo_t)) < 0 ||
      rpc_read(conn, currentState, sizeof(nvmlEnableState_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pciInfo, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)currentState,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceRemoveGpu_v2(nvmlPciInfo_t *pciInfo,
                                    nvmlDetachGpuState_t gpuState,
                                    nvmlPcieLinkState_t linkState) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pciInfo, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&gpuState, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&linkState, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceRemoveGpu_v2) < 0 ||
      rpc_write(conn, pciInfo, sizeof(nvmlPciInfo_t)) < 0 ||
      rpc_write(conn, &gpuState, sizeof(nvmlDetachGpuState_t)) < 0 ||
      rpc_write(conn, &linkState, sizeof(nvmlPcieLinkState_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pciInfo, sizeof(nvmlPciInfo_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pciInfo, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&gpuState, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&linkState, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceDiscoverGpus(nvmlPciInfo_t *pciInfo) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pciInfo, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceDiscoverGpus) < 0 ||
      rpc_write(conn, pciInfo, sizeof(nvmlPciInfo_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pciInfo, sizeof(nvmlPciInfo_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pciInfo, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetFieldValues(nvmlDevice_t device, int valuesCount,
                                      nvmlFieldValue_t *values) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&valuesCount,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)values, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(valuesCount) &&
                  is_unified_pointer(conn, (void *)values);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&values[i],
                               cudaMemcpyHostToDevice) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetFieldValues) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &valuesCount, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, values, valuesCount * sizeof(nvmlFieldValue_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&valuesCount,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)values, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(valuesCount) &&
                  is_unified_pointer(conn, (void *)values);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&values[i],
                               cudaMemcpyDeviceToHost) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceClearFieldValues(nvmlDevice_t device, int valuesCount,
                                        nvmlFieldValue_t *values) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&valuesCount,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)values, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(valuesCount) &&
                  is_unified_pointer(conn, (void *)values);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&values[i],
                               cudaMemcpyHostToDevice) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceClearFieldValues) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &valuesCount, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, values, valuesCount * sizeof(nvmlFieldValue_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&valuesCount,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)values, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(valuesCount) &&
                  is_unified_pointer(conn, (void *)values);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&values[i],
                               cudaMemcpyDeviceToHost) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t
nvmlDeviceGetVirtualizationMode(nvmlDevice_t device,
                                nvmlGpuVirtualizationMode_t *pVirtualMode) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pVirtualMode,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetVirtualizationMode) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pVirtualMode, sizeof(nvmlGpuVirtualizationMode_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pVirtualMode,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetHostVgpuMode(nvmlDevice_t device,
                                       nvmlHostVgpuMode_t *pHostVgpuMode) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pHostVgpuMode,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetHostVgpuMode) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pHostVgpuMode, sizeof(nvmlHostVgpuMode_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pHostVgpuMode,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t
nvmlDeviceSetVirtualizationMode(nvmlDevice_t device,
                                nvmlGpuVirtualizationMode_t virtualMode) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&virtualMode,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceSetVirtualizationMode) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &virtualMode, sizeof(nvmlGpuVirtualizationMode_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&virtualMode,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetGridLicensableFeatures_v4(
    nvmlDevice_t device,
    nvmlGridLicensableFeatures_t *pGridLicensableFeatures) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pGridLicensableFeatures,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn,
                              RPC_nvmlDeviceGetGridLicensableFeatures_v4) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pGridLicensableFeatures,
               sizeof(nvmlGridLicensableFeatures_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pGridLicensableFeatures,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetProcessUtilization(
    nvmlDevice_t device, nvmlProcessUtilizationSample_t *utilization,
    unsigned int *processSamplesCount, unsigned long long lastSeenTimeStamp) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)processSamplesCount,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)utilization,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*processSamplesCount) &&
                  is_unified_pointer(conn, (void *)utilization);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&utilization[i],
                               cudaMemcpyHostToDevice) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&lastSeenTimeStamp,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetProcessUtilization) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, processSamplesCount, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &lastSeenTimeStamp, sizeof(unsigned long long)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, processSamplesCount, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, utilization,
               *processSamplesCount * sizeof(nvmlProcessUtilizationSample_t)) <
          0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)processSamplesCount,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)utilization,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*processSamplesCount) &&
                  is_unified_pointer(conn, (void *)utilization);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&utilization[i],
                               cudaMemcpyDeviceToHost) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&lastSeenTimeStamp,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetGspFirmwareVersion(nvmlDevice_t device,
                                             char *version) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)version, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetGspFirmwareVersion) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, version, sizeof(char)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)version, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetGspFirmwareMode(nvmlDevice_t device,
                                          unsigned int *isEnabled,
                                          unsigned int *defaultMode) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)isEnabled, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)defaultMode,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetGspFirmwareMode) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, isEnabled, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, defaultMode, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)isEnabled, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)defaultMode,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t
nvmlGetVgpuDriverCapabilities(nvmlVgpuDriverCapability_t capability,
                              unsigned int *capResult) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&capability,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)capResult, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlGetVgpuDriverCapabilities) < 0 ||
      rpc_write(conn, &capability, sizeof(nvmlVgpuDriverCapability_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, capResult, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&capability,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)capResult, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t
nvmlDeviceGetVgpuCapabilities(nvmlDevice_t device,
                              nvmlDeviceVgpuCapability_t capability,
                              unsigned int *capResult) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&capability,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)capResult, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetVgpuCapabilities) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &capability, sizeof(nvmlDeviceVgpuCapability_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, capResult, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&capability,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)capResult, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetSupportedVgpus(nvmlDevice_t device,
                                         unsigned int *vgpuCount,
                                         nvmlVgpuTypeId_t *vgpuTypeIds) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)vgpuCount, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)vgpuTypeIds,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*vgpuCount) &&
                  is_unified_pointer(conn, (void *)vgpuTypeIds);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&vgpuTypeIds[i],
                               cudaMemcpyHostToDevice) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetSupportedVgpus) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, vgpuCount, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, vgpuCount, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, vgpuTypeIds, *vgpuCount * sizeof(nvmlVgpuTypeId_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)vgpuCount, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)vgpuTypeIds,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*vgpuCount) &&
                  is_unified_pointer(conn, (void *)vgpuTypeIds);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&vgpuTypeIds[i],
                               cudaMemcpyDeviceToHost) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetCreatableVgpus(nvmlDevice_t device,
                                         unsigned int *vgpuCount,
                                         nvmlVgpuTypeId_t *vgpuTypeIds) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)vgpuCount, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)vgpuTypeIds,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*vgpuCount) &&
                  is_unified_pointer(conn, (void *)vgpuTypeIds);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&vgpuTypeIds[i],
                               cudaMemcpyHostToDevice) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetCreatableVgpus) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, vgpuCount, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, vgpuCount, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, vgpuTypeIds, *vgpuCount * sizeof(nvmlVgpuTypeId_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)vgpuCount, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)vgpuTypeIds,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*vgpuCount) &&
                  is_unified_pointer(conn, (void *)vgpuTypeIds);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&vgpuTypeIds[i],
                               cudaMemcpyDeviceToHost) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlVgpuTypeGetClass(nvmlVgpuTypeId_t vgpuTypeId,
                                  char *vgpuTypeClass, unsigned int *size) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&vgpuTypeId,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)size, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)vgpuTypeClass,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*size) &&
                  is_unified_pointer(conn, (void *)vgpuTypeClass);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&vgpuTypeClass[i],
                               cudaMemcpyHostToDevice) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlVgpuTypeGetClass) < 0 ||
      rpc_write(conn, &vgpuTypeId, sizeof(nvmlVgpuTypeId_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, size, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, vgpuTypeClass, *size * sizeof(char)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&vgpuTypeId,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)size, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)vgpuTypeClass,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*size) &&
                  is_unified_pointer(conn, (void *)vgpuTypeClass);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&vgpuTypeClass[i],
                               cudaMemcpyDeviceToHost) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlVgpuTypeGetName(nvmlVgpuTypeId_t vgpuTypeId,
                                 char *vgpuTypeName, unsigned int *size) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&vgpuTypeId,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)size, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)vgpuTypeName,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*size) &&
                  is_unified_pointer(conn, (void *)vgpuTypeName);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&vgpuTypeName[i],
                               cudaMemcpyHostToDevice) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlVgpuTypeGetName) < 0 ||
      rpc_write(conn, &vgpuTypeId, sizeof(nvmlVgpuTypeId_t)) < 0 ||
      rpc_write(conn, size, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, size, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, vgpuTypeName, *size * sizeof(char)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&vgpuTypeId,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)size, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)vgpuTypeName,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*size) &&
                  is_unified_pointer(conn, (void *)vgpuTypeName);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&vgpuTypeName[i],
                               cudaMemcpyDeviceToHost) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t
nvmlVgpuTypeGetGpuInstanceProfileId(nvmlVgpuTypeId_t vgpuTypeId,
                                    unsigned int *gpuInstanceProfileId) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&vgpuTypeId,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)gpuInstanceProfileId,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlVgpuTypeGetGpuInstanceProfileId) <
          0 ||
      rpc_write(conn, &vgpuTypeId, sizeof(nvmlVgpuTypeId_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, gpuInstanceProfileId, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&vgpuTypeId,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)gpuInstanceProfileId,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlVgpuTypeGetDeviceID(nvmlVgpuTypeId_t vgpuTypeId,
                                     unsigned long long *deviceID,
                                     unsigned long long *subsystemID) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&vgpuTypeId,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)deviceID, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)subsystemID,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlVgpuTypeGetDeviceID) < 0 ||
      rpc_write(conn, &vgpuTypeId, sizeof(nvmlVgpuTypeId_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, deviceID, sizeof(unsigned long long)) < 0 ||
      rpc_read(conn, subsystemID, sizeof(unsigned long long)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&vgpuTypeId,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)deviceID, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)subsystemID,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlVgpuTypeGetFramebufferSize(nvmlVgpuTypeId_t vgpuTypeId,
                                            unsigned long long *fbSize) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&vgpuTypeId,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)fbSize, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlVgpuTypeGetFramebufferSize) < 0 ||
      rpc_write(conn, &vgpuTypeId, sizeof(nvmlVgpuTypeId_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, fbSize, sizeof(unsigned long long)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&vgpuTypeId,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)fbSize, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlVgpuTypeGetNumDisplayHeads(nvmlVgpuTypeId_t vgpuTypeId,
                                            unsigned int *numDisplayHeads) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&vgpuTypeId,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)numDisplayHeads,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlVgpuTypeGetNumDisplayHeads) < 0 ||
      rpc_write(conn, &vgpuTypeId, sizeof(nvmlVgpuTypeId_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, numDisplayHeads, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&vgpuTypeId,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)numDisplayHeads,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlVgpuTypeGetResolution(nvmlVgpuTypeId_t vgpuTypeId,
                                       unsigned int displayIndex,
                                       unsigned int *xdim, unsigned int *ydim) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&vgpuTypeId,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&displayIndex,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)xdim, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)ydim, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlVgpuTypeGetResolution) < 0 ||
      rpc_write(conn, &vgpuTypeId, sizeof(nvmlVgpuTypeId_t)) < 0 ||
      rpc_write(conn, &displayIndex, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, xdim, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, ydim, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&vgpuTypeId,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&displayIndex,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)xdim, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)ydim, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlVgpuTypeGetLicense(nvmlVgpuTypeId_t vgpuTypeId,
                                    char *vgpuTypeLicenseString,
                                    unsigned int size) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&vgpuTypeId,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&size, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)vgpuTypeLicenseString,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(size) &&
                  is_unified_pointer(conn, (void *)vgpuTypeLicenseString);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&vgpuTypeLicenseString[i],
                               cudaMemcpyHostToDevice) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlVgpuTypeGetLicense) < 0 ||
      rpc_write(conn, &vgpuTypeId, sizeof(nvmlVgpuTypeId_t)) < 0 ||
      rpc_write(conn, &size, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, vgpuTypeLicenseString, size * sizeof(char)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&vgpuTypeId,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&size, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)vgpuTypeLicenseString,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(size) &&
                  is_unified_pointer(conn, (void *)vgpuTypeLicenseString);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&vgpuTypeLicenseString[i],
                               cudaMemcpyDeviceToHost) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlVgpuTypeGetFrameRateLimit(nvmlVgpuTypeId_t vgpuTypeId,
                                           unsigned int *frameRateLimit) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&vgpuTypeId,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)frameRateLimit,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlVgpuTypeGetFrameRateLimit) < 0 ||
      rpc_write(conn, &vgpuTypeId, sizeof(nvmlVgpuTypeId_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, frameRateLimit, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&vgpuTypeId,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)frameRateLimit,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlVgpuTypeGetMaxInstances(nvmlDevice_t device,
                                         nvmlVgpuTypeId_t vgpuTypeId,
                                         unsigned int *vgpuInstanceCount) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&vgpuTypeId,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)vgpuInstanceCount,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlVgpuTypeGetMaxInstances) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &vgpuTypeId, sizeof(nvmlVgpuTypeId_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, vgpuInstanceCount, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&vgpuTypeId,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)vgpuInstanceCount,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t
nvmlVgpuTypeGetMaxInstancesPerVm(nvmlVgpuTypeId_t vgpuTypeId,
                                 unsigned int *vgpuInstanceCountPerVm) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&vgpuTypeId,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)vgpuInstanceCountPerVm,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlVgpuTypeGetMaxInstancesPerVm) < 0 ||
      rpc_write(conn, &vgpuTypeId, sizeof(nvmlVgpuTypeId_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, vgpuInstanceCountPerVm, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&vgpuTypeId,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)vgpuInstanceCountPerVm,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetActiveVgpus(nvmlDevice_t device,
                                      unsigned int *vgpuCount,
                                      nvmlVgpuInstance_t *vgpuInstances) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)vgpuCount, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)vgpuInstances,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*vgpuCount) &&
                  is_unified_pointer(conn, (void *)vgpuInstances);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&vgpuInstances[i],
                               cudaMemcpyHostToDevice) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetActiveVgpus) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, vgpuCount, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, vgpuCount, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, vgpuInstances, *vgpuCount * sizeof(nvmlVgpuInstance_t)) <
          0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)vgpuCount, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)vgpuInstances,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*vgpuCount) &&
                  is_unified_pointer(conn, (void *)vgpuInstances);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&vgpuInstances[i],
                               cudaMemcpyDeviceToHost) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlVgpuInstanceGetVmID(nvmlVgpuInstance_t vgpuInstance,
                                     char *vmId, unsigned int size,
                                     nvmlVgpuVmIdType_t *vmIdType) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&vgpuInstance,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&size, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)vmId, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0;
       i < static_cast<int>(size) && is_unified_pointer(conn, (void *)vmId);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&vmId[i], cudaMemcpyHostToDevice) <
        0)
      return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)vmIdType, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlVgpuInstanceGetVmID) < 0 ||
      rpc_write(conn, &vgpuInstance, sizeof(nvmlVgpuInstance_t)) < 0 ||
      rpc_write(conn, &size, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, vmId, size * sizeof(char)) < 0 ||
      rpc_read(conn, vmIdType, sizeof(nvmlVgpuVmIdType_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&vgpuInstance,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&size, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)vmId, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0;
       i < static_cast<int>(size) && is_unified_pointer(conn, (void *)vmId);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&vmId[i], cudaMemcpyDeviceToHost) <
        0)
      return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)vmIdType, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlVgpuInstanceGetUUID(nvmlVgpuInstance_t vgpuInstance,
                                     char *uuid, unsigned int size) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&vgpuInstance,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&size, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)uuid, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0;
       i < static_cast<int>(size) && is_unified_pointer(conn, (void *)uuid);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&uuid[i], cudaMemcpyHostToDevice) <
        0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlVgpuInstanceGetUUID) < 0 ||
      rpc_write(conn, &vgpuInstance, sizeof(nvmlVgpuInstance_t)) < 0 ||
      rpc_write(conn, &size, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, uuid, size * sizeof(char)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&vgpuInstance,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&size, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)uuid, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0;
       i < static_cast<int>(size) && is_unified_pointer(conn, (void *)uuid);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&uuid[i], cudaMemcpyDeviceToHost) <
        0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlVgpuInstanceGetVmDriverVersion(nvmlVgpuInstance_t vgpuInstance,
                                                char *version,
                                                unsigned int length) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&vgpuInstance,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&length, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)version, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(length) &&
                  is_unified_pointer(conn, (void *)version);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&version[i],
                               cudaMemcpyHostToDevice) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlVgpuInstanceGetVmDriverVersion) <
          0 ||
      rpc_write(conn, &vgpuInstance, sizeof(nvmlVgpuInstance_t)) < 0 ||
      rpc_write(conn, &length, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, version, length * sizeof(char)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&vgpuInstance,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&length, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)version, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(length) &&
                  is_unified_pointer(conn, (void *)version);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&version[i],
                               cudaMemcpyDeviceToHost) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlVgpuInstanceGetFbUsage(nvmlVgpuInstance_t vgpuInstance,
                                        unsigned long long *fbUsage) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&vgpuInstance,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)fbUsage, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlVgpuInstanceGetFbUsage) < 0 ||
      rpc_write(conn, &vgpuInstance, sizeof(nvmlVgpuInstance_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, fbUsage, sizeof(unsigned long long)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&vgpuInstance,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)fbUsage, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlVgpuInstanceGetLicenseStatus(nvmlVgpuInstance_t vgpuInstance,
                                              unsigned int *licensed) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&vgpuInstance,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)licensed, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlVgpuInstanceGetLicenseStatus) < 0 ||
      rpc_write(conn, &vgpuInstance, sizeof(nvmlVgpuInstance_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, licensed, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&vgpuInstance,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)licensed, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlVgpuInstanceGetType(nvmlVgpuInstance_t vgpuInstance,
                                     nvmlVgpuTypeId_t *vgpuTypeId) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&vgpuInstance,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)vgpuTypeId, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlVgpuInstanceGetType) < 0 ||
      rpc_write(conn, &vgpuInstance, sizeof(nvmlVgpuInstance_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, vgpuTypeId, sizeof(nvmlVgpuTypeId_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&vgpuInstance,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)vgpuTypeId, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlVgpuInstanceGetFrameRateLimit(nvmlVgpuInstance_t vgpuInstance,
                                               unsigned int *frameRateLimit) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&vgpuInstance,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)frameRateLimit,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlVgpuInstanceGetFrameRateLimit) <
          0 ||
      rpc_write(conn, &vgpuInstance, sizeof(nvmlVgpuInstance_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, frameRateLimit, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&vgpuInstance,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)frameRateLimit,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlVgpuInstanceGetEccMode(nvmlVgpuInstance_t vgpuInstance,
                                        nvmlEnableState_t *eccMode) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&vgpuInstance,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)eccMode, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlVgpuInstanceGetEccMode) < 0 ||
      rpc_write(conn, &vgpuInstance, sizeof(nvmlVgpuInstance_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, eccMode, sizeof(nvmlEnableState_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&vgpuInstance,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)eccMode, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlVgpuInstanceGetEncoderCapacity(nvmlVgpuInstance_t vgpuInstance,
                                                unsigned int *encoderCapacity) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&vgpuInstance,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)encoderCapacity,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlVgpuInstanceGetEncoderCapacity) <
          0 ||
      rpc_write(conn, &vgpuInstance, sizeof(nvmlVgpuInstance_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, encoderCapacity, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&vgpuInstance,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)encoderCapacity,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlVgpuInstanceSetEncoderCapacity(nvmlVgpuInstance_t vgpuInstance,
                                                unsigned int encoderCapacity) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&vgpuInstance,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&encoderCapacity,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlVgpuInstanceSetEncoderCapacity) <
          0 ||
      rpc_write(conn, &vgpuInstance, sizeof(nvmlVgpuInstance_t)) < 0 ||
      rpc_write(conn, &encoderCapacity, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&vgpuInstance,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&encoderCapacity,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlVgpuInstanceGetEncoderStats(nvmlVgpuInstance_t vgpuInstance,
                                             unsigned int *sessionCount,
                                             unsigned int *averageFps,
                                             unsigned int *averageLatency) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&vgpuInstance,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)sessionCount,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)averageFps, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)averageLatency,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlVgpuInstanceGetEncoderStats) < 0 ||
      rpc_write(conn, &vgpuInstance, sizeof(nvmlVgpuInstance_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, sessionCount, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, averageFps, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, averageLatency, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&vgpuInstance,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)sessionCount,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)averageFps, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)averageLatency,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t
nvmlVgpuInstanceGetEncoderSessions(nvmlVgpuInstance_t vgpuInstance,
                                   unsigned int *sessionCount,
                                   nvmlEncoderSessionInfo_t *sessionInfo) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&vgpuInstance,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)sessionCount,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)sessionInfo,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*sessionCount) &&
                  is_unified_pointer(conn, (void *)sessionInfo);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&sessionInfo[i],
                               cudaMemcpyHostToDevice) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlVgpuInstanceGetEncoderSessions) <
          0 ||
      rpc_write(conn, &vgpuInstance, sizeof(nvmlVgpuInstance_t)) < 0 ||
      rpc_write(conn, sessionCount, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, sessionCount, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, sessionInfo,
               *sessionCount * sizeof(nvmlEncoderSessionInfo_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&vgpuInstance,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)sessionCount,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)sessionInfo,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*sessionCount) &&
                  is_unified_pointer(conn, (void *)sessionInfo);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&sessionInfo[i],
                               cudaMemcpyDeviceToHost) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlVgpuInstanceGetFBCStats(nvmlVgpuInstance_t vgpuInstance,
                                         nvmlFBCStats_t *fbcStats) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&vgpuInstance,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)fbcStats, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlVgpuInstanceGetFBCStats) < 0 ||
      rpc_write(conn, &vgpuInstance, sizeof(nvmlVgpuInstance_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, fbcStats, sizeof(nvmlFBCStats_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&vgpuInstance,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)fbcStats, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlVgpuInstanceGetFBCSessions(nvmlVgpuInstance_t vgpuInstance,
                                            unsigned int *sessionCount,
                                            nvmlFBCSessionInfo_t *sessionInfo) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&vgpuInstance,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)sessionCount,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)sessionInfo,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*sessionCount) &&
                  is_unified_pointer(conn, (void *)sessionInfo);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&sessionInfo[i],
                               cudaMemcpyHostToDevice) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlVgpuInstanceGetFBCSessions) < 0 ||
      rpc_write(conn, &vgpuInstance, sizeof(nvmlVgpuInstance_t)) < 0 ||
      rpc_write(conn, sessionCount, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, sessionCount, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, sessionInfo,
               *sessionCount * sizeof(nvmlFBCSessionInfo_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&vgpuInstance,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)sessionCount,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)sessionInfo,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*sessionCount) &&
                  is_unified_pointer(conn, (void *)sessionInfo);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&sessionInfo[i],
                               cudaMemcpyDeviceToHost) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlVgpuInstanceGetGpuInstanceId(nvmlVgpuInstance_t vgpuInstance,
                                              unsigned int *gpuInstanceId) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&vgpuInstance,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)gpuInstanceId,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlVgpuInstanceGetGpuInstanceId) < 0 ||
      rpc_write(conn, &vgpuInstance, sizeof(nvmlVgpuInstance_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, gpuInstanceId, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&vgpuInstance,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)gpuInstanceId,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlVgpuInstanceGetGpuPciId(nvmlVgpuInstance_t vgpuInstance,
                                         char *vgpuPciId,
                                         unsigned int *length) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&vgpuInstance,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)length, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)vgpuPciId, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*length) &&
                  is_unified_pointer(conn, (void *)vgpuPciId);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&vgpuPciId[i],
                               cudaMemcpyHostToDevice) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlVgpuInstanceGetGpuPciId) < 0 ||
      rpc_write(conn, &vgpuInstance, sizeof(nvmlVgpuInstance_t)) < 0 ||
      rpc_write(conn, length, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, length, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, vgpuPciId, *length * sizeof(char)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&vgpuInstance,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)length, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)vgpuPciId, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*length) &&
                  is_unified_pointer(conn, (void *)vgpuPciId);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&vgpuPciId[i],
                               cudaMemcpyDeviceToHost) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlVgpuTypeGetCapabilities(nvmlVgpuTypeId_t vgpuTypeId,
                                         nvmlVgpuCapability_t capability,
                                         unsigned int *capResult) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&vgpuTypeId,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&capability,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)capResult, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlVgpuTypeGetCapabilities) < 0 ||
      rpc_write(conn, &vgpuTypeId, sizeof(nvmlVgpuTypeId_t)) < 0 ||
      rpc_write(conn, &capability, sizeof(nvmlVgpuCapability_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, capResult, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&vgpuTypeId,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&capability,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)capResult, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlVgpuInstanceGetMetadata(nvmlVgpuInstance_t vgpuInstance,
                                         nvmlVgpuMetadata_t *vgpuMetadata,
                                         unsigned int *bufferSize) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&vgpuInstance,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)bufferSize, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)vgpuMetadata,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*bufferSize) &&
                  is_unified_pointer(conn, (void *)vgpuMetadata);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&vgpuMetadata[i],
                               cudaMemcpyHostToDevice) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlVgpuInstanceGetMetadata) < 0 ||
      rpc_write(conn, &vgpuInstance, sizeof(nvmlVgpuInstance_t)) < 0 ||
      rpc_write(conn, bufferSize, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, bufferSize, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, vgpuMetadata, *bufferSize * sizeof(nvmlVgpuMetadata_t)) <
          0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&vgpuInstance,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)bufferSize, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)vgpuMetadata,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*bufferSize) &&
                  is_unified_pointer(conn, (void *)vgpuMetadata);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&vgpuMetadata[i],
                               cudaMemcpyDeviceToHost) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetVgpuMetadata(nvmlDevice_t device,
                                       nvmlVgpuPgpuMetadata_t *pgpuMetadata,
                                       unsigned int *bufferSize) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)bufferSize, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pgpuMetadata,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*bufferSize) &&
                  is_unified_pointer(conn, (void *)pgpuMetadata);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&pgpuMetadata[i],
                               cudaMemcpyHostToDevice) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetVgpuMetadata) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, bufferSize, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, bufferSize, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, pgpuMetadata,
               *bufferSize * sizeof(nvmlVgpuPgpuMetadata_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)bufferSize, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pgpuMetadata,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*bufferSize) &&
                  is_unified_pointer(conn, (void *)pgpuMetadata);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&pgpuMetadata[i],
                               cudaMemcpyDeviceToHost) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t
nvmlGetVgpuCompatibility(nvmlVgpuMetadata_t *vgpuMetadata,
                         nvmlVgpuPgpuMetadata_t *pgpuMetadata,
                         nvmlVgpuPgpuCompatibility_t *compatibilityInfo) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)vgpuMetadata,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pgpuMetadata,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)compatibilityInfo,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlGetVgpuCompatibility) < 0 ||
      rpc_write(conn, vgpuMetadata, sizeof(nvmlVgpuMetadata_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, vgpuMetadata, sizeof(nvmlVgpuMetadata_t)) < 0 ||
      rpc_read(conn, pgpuMetadata, sizeof(nvmlVgpuPgpuMetadata_t)) < 0 ||
      rpc_read(conn, compatibilityInfo, sizeof(nvmlVgpuPgpuCompatibility_t)) <
          0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)vgpuMetadata,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pgpuMetadata,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)compatibilityInfo,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetPgpuMetadataString(nvmlDevice_t device,
                                             char *pgpuMetadata,
                                             unsigned int *bufferSize) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)bufferSize, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pgpuMetadata,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*bufferSize) &&
                  is_unified_pointer(conn, (void *)pgpuMetadata);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&pgpuMetadata[i],
                               cudaMemcpyHostToDevice) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetPgpuMetadataString) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, bufferSize, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, bufferSize, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, pgpuMetadata, *bufferSize * sizeof(char)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)bufferSize, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pgpuMetadata,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*bufferSize) &&
                  is_unified_pointer(conn, (void *)pgpuMetadata);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&pgpuMetadata[i],
                               cudaMemcpyDeviceToHost) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t
nvmlDeviceGetVgpuSchedulerLog(nvmlDevice_t device,
                              nvmlVgpuSchedulerLog_t *pSchedulerLog) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pSchedulerLog,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetVgpuSchedulerLog) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pSchedulerLog, sizeof(nvmlVgpuSchedulerLog_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pSchedulerLog,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t
nvmlDeviceGetVgpuSchedulerState(nvmlDevice_t device,
                                nvmlVgpuSchedulerGetState_t *pSchedulerState) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pSchedulerState,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetVgpuSchedulerState) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pSchedulerState, sizeof(nvmlVgpuSchedulerGetState_t)) <
          0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pSchedulerState,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetVgpuSchedulerCapabilities(
    nvmlDevice_t device, nvmlVgpuSchedulerCapabilities_t *pCapabilities) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pCapabilities,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn,
                              RPC_nvmlDeviceGetVgpuSchedulerCapabilities) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pCapabilities, sizeof(nvmlVgpuSchedulerCapabilities_t)) <
          0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pCapabilities,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlGetVgpuVersion(nvmlVgpuVersion_t *supported,
                                nvmlVgpuVersion_t *current) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)supported, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)current, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlGetVgpuVersion) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, supported, sizeof(nvmlVgpuVersion_t)) < 0 ||
      rpc_read(conn, current, sizeof(nvmlVgpuVersion_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)supported, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)current, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlSetVgpuVersion(nvmlVgpuVersion_t *vgpuVersion) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)vgpuVersion,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlSetVgpuVersion) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, vgpuVersion, sizeof(nvmlVgpuVersion_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)vgpuVersion,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetVgpuUtilization(
    nvmlDevice_t device, unsigned long long lastSeenTimeStamp,
    nvmlValueType_t *sampleValType, unsigned int *vgpuInstanceSamplesCount,
    nvmlVgpuInstanceUtilizationSample_t *utilizationSamples) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&lastSeenTimeStamp,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)sampleValType,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)vgpuInstanceSamplesCount,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)utilizationSamples,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*vgpuInstanceSamplesCount) &&
                  is_unified_pointer(conn, (void *)utilizationSamples);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&utilizationSamples[i],
                               cudaMemcpyHostToDevice) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetVgpuUtilization) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &lastSeenTimeStamp, sizeof(unsigned long long)) < 0 ||
      rpc_write(conn, sampleValType, sizeof(nvmlValueType_t)) < 0 ||
      rpc_write(conn, vgpuInstanceSamplesCount, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, sampleValType, sizeof(nvmlValueType_t)) < 0 ||
      rpc_read(conn, vgpuInstanceSamplesCount, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, utilizationSamples,
               *vgpuInstanceSamplesCount *
                   sizeof(nvmlVgpuInstanceUtilizationSample_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&lastSeenTimeStamp,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)sampleValType,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)vgpuInstanceSamplesCount,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)utilizationSamples,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*vgpuInstanceSamplesCount) &&
                  is_unified_pointer(conn, (void *)utilizationSamples);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&utilizationSamples[i],
                               cudaMemcpyDeviceToHost) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetVgpuProcessUtilization(
    nvmlDevice_t device, unsigned long long lastSeenTimeStamp,
    unsigned int *vgpuProcessSamplesCount,
    nvmlVgpuProcessUtilizationSample_t *utilizationSamples) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&lastSeenTimeStamp,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)vgpuProcessSamplesCount,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)utilizationSamples,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*vgpuProcessSamplesCount) &&
                  is_unified_pointer(conn, (void *)utilizationSamples);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&utilizationSamples[i],
                               cudaMemcpyHostToDevice) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetVgpuProcessUtilization) <
          0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &lastSeenTimeStamp, sizeof(unsigned long long)) < 0 ||
      rpc_write(conn, vgpuProcessSamplesCount, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, vgpuProcessSamplesCount, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, utilizationSamples,
               *vgpuProcessSamplesCount *
                   sizeof(nvmlVgpuProcessUtilizationSample_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&lastSeenTimeStamp,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)vgpuProcessSamplesCount,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)utilizationSamples,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*vgpuProcessSamplesCount) &&
                  is_unified_pointer(conn, (void *)utilizationSamples);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&utilizationSamples[i],
                               cudaMemcpyDeviceToHost) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlVgpuInstanceGetAccountingMode(nvmlVgpuInstance_t vgpuInstance,
                                               nvmlEnableState_t *mode) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&vgpuInstance,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)mode, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlVgpuInstanceGetAccountingMode) <
          0 ||
      rpc_write(conn, &vgpuInstance, sizeof(nvmlVgpuInstance_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, mode, sizeof(nvmlEnableState_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&vgpuInstance,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)mode, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlVgpuInstanceGetAccountingPids(nvmlVgpuInstance_t vgpuInstance,
                                               unsigned int *count,
                                               unsigned int *pids) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&vgpuInstance,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)count, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pids, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0;
       i < static_cast<int>(*count) && is_unified_pointer(conn, (void *)pids);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&pids[i], cudaMemcpyHostToDevice) <
        0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlVgpuInstanceGetAccountingPids) <
          0 ||
      rpc_write(conn, &vgpuInstance, sizeof(nvmlVgpuInstance_t)) < 0 ||
      rpc_write(conn, count, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, count, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, pids, *count * sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&vgpuInstance,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)count, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pids, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0;
       i < static_cast<int>(*count) && is_unified_pointer(conn, (void *)pids);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&pids[i], cudaMemcpyDeviceToHost) <
        0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlVgpuInstanceGetAccountingStats(nvmlVgpuInstance_t vgpuInstance,
                                                unsigned int pid,
                                                nvmlAccountingStats_t *stats) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&vgpuInstance,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&pid, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)stats, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlVgpuInstanceGetAccountingStats) <
          0 ||
      rpc_write(conn, &vgpuInstance, sizeof(nvmlVgpuInstance_t)) < 0 ||
      rpc_write(conn, &pid, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, stats, sizeof(nvmlAccountingStats_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&vgpuInstance,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&pid, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)stats, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t
nvmlVgpuInstanceClearAccountingPids(nvmlVgpuInstance_t vgpuInstance) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&vgpuInstance,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlVgpuInstanceClearAccountingPids) <
          0 ||
      rpc_write(conn, &vgpuInstance, sizeof(nvmlVgpuInstance_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&vgpuInstance,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t
nvmlVgpuInstanceGetLicenseInfo_v2(nvmlVgpuInstance_t vgpuInstance,
                                  nvmlVgpuLicenseInfo_t *licenseInfo) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&vgpuInstance,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)licenseInfo,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlVgpuInstanceGetLicenseInfo_v2) <
          0 ||
      rpc_write(conn, &vgpuInstance, sizeof(nvmlVgpuInstance_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, licenseInfo, sizeof(nvmlVgpuLicenseInfo_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&vgpuInstance,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)licenseInfo,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlGetExcludedDeviceCount(unsigned int *deviceCount) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)deviceCount,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlGetExcludedDeviceCount) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, deviceCount, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)deviceCount,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlGetExcludedDeviceInfoByIndex(unsigned int index,
                                              nvmlExcludedDeviceInfo_t *info) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&index, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)info, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlGetExcludedDeviceInfoByIndex) < 0 ||
      rpc_write(conn, &index, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, info, sizeof(nvmlExcludedDeviceInfo_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&index, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)info, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceSetMigMode(nvmlDevice_t device, unsigned int mode,
                                  nvmlReturn_t *activationStatus) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)activationStatus,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceSetMigMode) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &mode, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, activationStatus, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)activationStatus,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetMigMode(nvmlDevice_t device,
                                  unsigned int *currentMode,
                                  unsigned int *pendingMode) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)currentMode,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pendingMode,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetMigMode) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, currentMode, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, pendingMode, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)currentMode,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pendingMode,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t
nvmlDeviceGetGpuInstanceProfileInfo(nvmlDevice_t device, unsigned int profile,
                                    nvmlGpuInstanceProfileInfo_t *info) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&profile, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)info, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetGpuInstanceProfileInfo) <
          0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &profile, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, info, sizeof(nvmlGpuInstanceProfileInfo_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&profile, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)info, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t
nvmlDeviceGetGpuInstanceProfileInfoV(nvmlDevice_t device, unsigned int profile,
                                     nvmlGpuInstanceProfileInfo_v2_t *info) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&profile, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)info, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetGpuInstanceProfileInfoV) <
          0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &profile, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, info, sizeof(nvmlGpuInstanceProfileInfo_v2_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&profile, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)info, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetGpuInstancePossiblePlacements_v2(
    nvmlDevice_t device, unsigned int profileId,
    nvmlGpuInstancePlacement_t *placements, unsigned int *count) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&profileId, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)count, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)placements, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*count) &&
                  is_unified_pointer(conn, (void *)placements);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&placements[i],
                               cudaMemcpyHostToDevice) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(
          conn, RPC_nvmlDeviceGetGpuInstancePossiblePlacements_v2) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &profileId, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, count, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, count, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, placements, *count * sizeof(nvmlGpuInstancePlacement_t)) <
          0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&profileId, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)count, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)placements, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*count) &&
                  is_unified_pointer(conn, (void *)placements);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&placements[i],
                               cudaMemcpyDeviceToHost) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetGpuInstanceRemainingCapacity(nvmlDevice_t device,
                                                       unsigned int profileId,
                                                       unsigned int *count) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&profileId, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)count, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(
          conn, RPC_nvmlDeviceGetGpuInstanceRemainingCapacity) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &profileId, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, count, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&profileId, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)count, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceCreateGpuInstance(nvmlDevice_t device,
                                         unsigned int profileId,
                                         nvmlGpuInstance_t *gpuInstance) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&profileId, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)gpuInstance,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceCreateGpuInstance) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &profileId, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, gpuInstance, sizeof(nvmlGpuInstance_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&profileId, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)gpuInstance,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlGpuInstanceDestroy(nvmlGpuInstance_t gpuInstance) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&gpuInstance,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlGpuInstanceDestroy) < 0 ||
      rpc_write(conn, &gpuInstance, sizeof(nvmlGpuInstance_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&gpuInstance,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetGpuInstances(nvmlDevice_t device,
                                       unsigned int profileId,
                                       nvmlGpuInstance_t *gpuInstances,
                                       unsigned int *count) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&profileId, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)count, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)gpuInstances,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*count) &&
                  is_unified_pointer(conn, (void *)gpuInstances);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&gpuInstances[i],
                               cudaMemcpyHostToDevice) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetGpuInstances) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &profileId, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, count, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, count, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, gpuInstances, *count * sizeof(nvmlGpuInstance_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&profileId, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)count, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)gpuInstances,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*count) &&
                  is_unified_pointer(conn, (void *)gpuInstances);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&gpuInstances[i],
                               cudaMemcpyDeviceToHost) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetGpuInstanceById(nvmlDevice_t device, unsigned int id,
                                          nvmlGpuInstance_t *gpuInstance) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&id, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)gpuInstance,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetGpuInstanceById) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &id, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, gpuInstance, sizeof(nvmlGpuInstance_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&id, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)gpuInstance,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlGpuInstanceGetInfo(nvmlGpuInstance_t gpuInstance,
                                    nvmlGpuInstanceInfo_t *info) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&gpuInstance,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)info, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlGpuInstanceGetInfo) < 0 ||
      rpc_write(conn, &gpuInstance, sizeof(nvmlGpuInstance_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, info, sizeof(nvmlGpuInstanceInfo_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&gpuInstance,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)info, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlGpuInstanceGetComputeInstanceProfileInfo(
    nvmlGpuInstance_t gpuInstance, unsigned int profile,
    unsigned int engProfile, nvmlComputeInstanceProfileInfo_t *info) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&gpuInstance,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&profile, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&engProfile,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)info, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(
          conn, RPC_nvmlGpuInstanceGetComputeInstanceProfileInfo) < 0 ||
      rpc_write(conn, &gpuInstance, sizeof(nvmlGpuInstance_t)) < 0 ||
      rpc_write(conn, &profile, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &engProfile, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, info, sizeof(nvmlComputeInstanceProfileInfo_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&gpuInstance,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&profile, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&engProfile,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)info, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlGpuInstanceGetComputeInstanceProfileInfoV(
    nvmlGpuInstance_t gpuInstance, unsigned int profile,
    unsigned int engProfile, nvmlComputeInstanceProfileInfo_v2_t *info) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&gpuInstance,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&profile, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&engProfile,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)info, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(
          conn, RPC_nvmlGpuInstanceGetComputeInstanceProfileInfoV) < 0 ||
      rpc_write(conn, &gpuInstance, sizeof(nvmlGpuInstance_t)) < 0 ||
      rpc_write(conn, &profile, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &engProfile, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, info, sizeof(nvmlComputeInstanceProfileInfo_v2_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&gpuInstance,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&profile, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&engProfile,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)info, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlGpuInstanceGetComputeInstanceRemainingCapacity(
    nvmlGpuInstance_t gpuInstance, unsigned int profileId,
    unsigned int *count) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&gpuInstance,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&profileId, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)count, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(
          conn, RPC_nvmlGpuInstanceGetComputeInstanceRemainingCapacity) < 0 ||
      rpc_write(conn, &gpuInstance, sizeof(nvmlGpuInstance_t)) < 0 ||
      rpc_write(conn, &profileId, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, count, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&gpuInstance,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&profileId, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)count, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlGpuInstanceGetComputeInstancePossiblePlacements(
    nvmlGpuInstance_t gpuInstance, unsigned int profileId,
    nvmlComputeInstancePlacement_t *placements, unsigned int *count) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&gpuInstance,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&profileId, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)count, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)placements, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*count) &&
                  is_unified_pointer(conn, (void *)placements);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&placements[i],
                               cudaMemcpyHostToDevice) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(
          conn, RPC_nvmlGpuInstanceGetComputeInstancePossiblePlacements) < 0 ||
      rpc_write(conn, &gpuInstance, sizeof(nvmlGpuInstance_t)) < 0 ||
      rpc_write(conn, &profileId, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, count, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, count, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, placements,
               *count * sizeof(nvmlComputeInstancePlacement_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&gpuInstance,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&profileId, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)count, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)placements, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*count) &&
                  is_unified_pointer(conn, (void *)placements);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&placements[i],
                               cudaMemcpyDeviceToHost) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t
nvmlGpuInstanceCreateComputeInstance(nvmlGpuInstance_t gpuInstance,
                                     unsigned int profileId,
                                     nvmlComputeInstance_t *computeInstance) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&gpuInstance,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&profileId, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)computeInstance,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlGpuInstanceCreateComputeInstance) <
          0 ||
      rpc_write(conn, &gpuInstance, sizeof(nvmlGpuInstance_t)) < 0 ||
      rpc_write(conn, &profileId, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, computeInstance, sizeof(nvmlComputeInstance_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&gpuInstance,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&profileId, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)computeInstance,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlComputeInstanceDestroy(nvmlComputeInstance_t computeInstance) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&computeInstance,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlComputeInstanceDestroy) < 0 ||
      rpc_write(conn, &computeInstance, sizeof(nvmlComputeInstance_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&computeInstance,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlGpuInstanceGetComputeInstances(
    nvmlGpuInstance_t gpuInstance, unsigned int profileId,
    nvmlComputeInstance_t *computeInstances, unsigned int *count) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&gpuInstance,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&profileId, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)count, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)computeInstances,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*count) &&
                  is_unified_pointer(conn, (void *)computeInstances);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&computeInstances[i],
                               cudaMemcpyHostToDevice) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlGpuInstanceGetComputeInstances) <
          0 ||
      rpc_write(conn, &gpuInstance, sizeof(nvmlGpuInstance_t)) < 0 ||
      rpc_write(conn, &profileId, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, count, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, count, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, computeInstances, *count * sizeof(nvmlComputeInstance_t)) <
          0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&gpuInstance,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&profileId, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)count, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)computeInstances,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0; i < static_cast<int>(*count) &&
                  is_unified_pointer(conn, (void *)computeInstances);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&computeInstances[i],
                               cudaMemcpyDeviceToHost) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t
nvmlGpuInstanceGetComputeInstanceById(nvmlGpuInstance_t gpuInstance,
                                      unsigned int id,
                                      nvmlComputeInstance_t *computeInstance) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&gpuInstance,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&id, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)computeInstance,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlGpuInstanceGetComputeInstanceById) <
          0 ||
      rpc_write(conn, &gpuInstance, sizeof(nvmlGpuInstance_t)) < 0 ||
      rpc_write(conn, &id, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, computeInstance, sizeof(nvmlComputeInstance_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&gpuInstance,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&id, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)computeInstance,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t
nvmlComputeInstanceGetInfo_v2(nvmlComputeInstance_t computeInstance,
                              nvmlComputeInstanceInfo_t *info) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&computeInstance,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)info, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlComputeInstanceGetInfo_v2) < 0 ||
      rpc_write(conn, &computeInstance, sizeof(nvmlComputeInstance_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, info, sizeof(nvmlComputeInstanceInfo_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&computeInstance,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)info, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceIsMigDeviceHandle(nvmlDevice_t device,
                                         unsigned int *isMigDevice) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)isMigDevice,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceIsMigDeviceHandle) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, isMigDevice, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)isMigDevice,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetGpuInstanceId(nvmlDevice_t device, unsigned int *id) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)id, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetGpuInstanceId) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, id, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)id, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetComputeInstanceId(nvmlDevice_t device,
                                            unsigned int *id) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)id, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetComputeInstanceId) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, id, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)id, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetMaxMigDeviceCount(nvmlDevice_t device,
                                            unsigned int *count) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)count, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetMaxMigDeviceCount) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, count, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)count, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetMigDeviceHandleByIndex(nvmlDevice_t device,
                                                 unsigned int index,
                                                 nvmlDevice_t *migDevice) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&index, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)migDevice, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetMigDeviceHandleByIndex) <
          0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &index, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, migDevice, sizeof(nvmlDevice_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&index, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)migDevice, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t
nvmlDeviceGetDeviceHandleFromMigDeviceHandle(nvmlDevice_t migDevice,
                                             nvmlDevice_t *device) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&migDevice, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(
          conn, RPC_nvmlDeviceGetDeviceHandleFromMigDeviceHandle) < 0 ||
      rpc_write(conn, &migDevice, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&migDevice, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetBusType(nvmlDevice_t device, nvmlBusType_t *type) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)type, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetBusType) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, type, sizeof(nvmlBusType_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)type, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetDynamicPstatesInfo(
    nvmlDevice_t device, nvmlGpuDynamicPstatesInfo_t *pDynamicPstatesInfo) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pDynamicPstatesInfo,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetDynamicPstatesInfo) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pDynamicPstatesInfo, sizeof(nvmlGpuDynamicPstatesInfo_t)) <
          0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pDynamicPstatesInfo,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceSetFanSpeed_v2(nvmlDevice_t device, unsigned int fan,
                                      unsigned int speed) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&fan, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&speed, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceSetFanSpeed_v2) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &fan, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &speed, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&fan, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&speed, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetGpcClkVfOffset(nvmlDevice_t device, int *offset) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)offset, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetGpcClkVfOffset) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, offset, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)offset, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceSetGpcClkVfOffset(nvmlDevice_t device, int offset) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&offset, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceSetGpcClkVfOffset) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &offset, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&offset, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetMemClkVfOffset(nvmlDevice_t device, int *offset) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)offset, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetMemClkVfOffset) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, offset, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)offset, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceSetMemClkVfOffset(nvmlDevice_t device, int offset) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&offset, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceSetMemClkVfOffset) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &offset, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&offset, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetMinMaxClockOfPState(nvmlDevice_t device,
                                              nvmlClockType_t type,
                                              nvmlPstates_t pstate,
                                              unsigned int *minClockMHz,
                                              unsigned int *maxClockMHz) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&type, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&pstate, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)minClockMHz,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)maxClockMHz,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetMinMaxClockOfPState) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &type, sizeof(nvmlClockType_t)) < 0 ||
      rpc_write(conn, &pstate, sizeof(nvmlPstates_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, minClockMHz, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, maxClockMHz, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&type, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&pstate, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)minClockMHz,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)maxClockMHz,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetSupportedPerformanceStates(nvmlDevice_t device,
                                                     nvmlPstates_t *pstates,
                                                     unsigned int size) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&size, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pstates, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0;
       i < static_cast<int>(size) && is_unified_pointer(conn, (void *)pstates);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&pstates[i],
                               cudaMemcpyHostToDevice) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(
          conn, RPC_nvmlDeviceGetSupportedPerformanceStates) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &size, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pstates, size * sizeof(nvmlPstates_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&size, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)pstates, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  for (int i = 0;
       i < static_cast<int>(size) && is_unified_pointer(conn, (void *)pstates);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&pstates[i],
                               cudaMemcpyDeviceToHost) < 0)
      return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetGpcClkMinMaxVfOffset(nvmlDevice_t device,
                                               int *minOffset, int *maxOffset) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)minOffset, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)maxOffset, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetGpcClkMinMaxVfOffset) <
          0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, minOffset, sizeof(int)) < 0 ||
      rpc_read(conn, maxOffset, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)minOffset, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)maxOffset, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetMemClkMinMaxVfOffset(nvmlDevice_t device,
                                               int *minOffset, int *maxOffset) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)minOffset, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)maxOffset, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetMemClkMinMaxVfOffset) <
          0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, minOffset, sizeof(int)) < 0 ||
      rpc_read(conn, maxOffset, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)minOffset, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)maxOffset, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlDeviceGetGpuFabricInfo(nvmlDevice_t device,
                                        nvmlGpuFabricInfo_t *gpuFabricInfo) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)gpuFabricInfo,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlDeviceGetGpuFabricInfo) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, gpuFabricInfo, sizeof(nvmlGpuFabricInfo_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)gpuFabricInfo,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlGpmMetricsGet(nvmlGpmMetricsGet_t *metricsGet) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)metricsGet, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlGpmMetricsGet) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, metricsGet, sizeof(nvmlGpmMetricsGet_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)metricsGet, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlGpmSampleFree(nvmlGpmSample_t gpmSample) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&gpmSample, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlGpmSampleFree) < 0 ||
      rpc_write(conn, &gpmSample, sizeof(nvmlGpmSample_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&gpmSample, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlGpmSampleAlloc(nvmlGpmSample_t *gpmSample) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)gpmSample, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlGpmSampleAlloc) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, gpmSample, sizeof(nvmlGpmSample_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)gpmSample, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlGpmSampleGet(nvmlDevice_t device, nvmlGpmSample_t gpmSample) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&gpmSample, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlGpmSampleGet) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &gpmSample, sizeof(nvmlGpmSample_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&gpmSample, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlGpmMigSampleGet(nvmlDevice_t device,
                                 unsigned int gpuInstanceId,
                                 nvmlGpmSample_t gpmSample) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&gpuInstanceId,
                             cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&gpmSample, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlGpmMigSampleGet) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_write(conn, &gpuInstanceId, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &gpmSample, sizeof(nvmlGpmSample_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&gpuInstanceId,
                             cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&gpmSample, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t nvmlGpmQueryDeviceSupport(nvmlDevice_t device,
                                       nvmlGpmSupport_t *gpmSupport) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)gpmSupport, cudaMemcpyHostToDevice) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(conn, RPC_nvmlGpmQueryDeviceSupport) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, gpmSupport, sizeof(nvmlGpmSupport_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)gpmSupport, cudaMemcpyDeviceToHost) <
      0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

nvmlReturn_t
nvmlDeviceSetNvLinkDeviceLowPowerThreshold(nvmlDevice_t device,
                                           nvmlNvLinkPowerThres_t *info) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)info, cudaMemcpyHostToDevice) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  nvmlReturn_t return_value;
  if (rpc_write_start_request(
          conn, RPC_nvmlDeviceSetNvLinkDeviceLowPowerThreshold) < 0 ||
      rpc_write(conn, &device, sizeof(nvmlDevice_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, info, sizeof(nvmlNvLinkPowerThres_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(nvmlReturn_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  if (maybe_copy_unified_arg(conn, (void *)info, cudaMemcpyDeviceToHost) < 0)
    return NVML_ERROR_GPU_IS_LOST;
  return return_value;
}

CUresult cuInit(unsigned int Flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&Flags, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuInit) < 0 ||
      rpc_write(conn, &Flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Flags, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuDriverGetVersion(int *driverVersion) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)driverVersion,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuDriverGetVersion) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, driverVersion, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)driverVersion,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuDeviceGet(CUdevice *device, int ordinal) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)device, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ordinal, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuDeviceGet) < 0 ||
      rpc_write(conn, &ordinal, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, device, sizeof(CUdevice)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)device, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ordinal, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuDeviceGetCount(int *count) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)count, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuDeviceGetCount) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, count, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)count, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuDeviceGetName(char *name, int len, CUdevice dev) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&len, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)name, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  for (int i = 0;
       i < static_cast<int>(len) && is_unified_pointer(conn, (void *)name); i++)
    if (maybe_copy_unified_arg(conn, (void *)&name[i], cudaMemcpyHostToDevice) <
        0)
      return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dev, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuDeviceGetName) < 0 ||
      rpc_write(conn, &len, sizeof(int)) < 0 ||
      rpc_write(conn, &dev, sizeof(CUdevice)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, name, len * sizeof(char)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&len, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)name, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  for (int i = 0;
       i < static_cast<int>(len) && is_unified_pointer(conn, (void *)name); i++)
    if (maybe_copy_unified_arg(conn, (void *)&name[i], cudaMemcpyDeviceToHost) <
        0)
      return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dev, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuDeviceGetUuid(CUuuid *uuid, CUdevice dev) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)uuid, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  for (int i = 0; i < 16 && is_unified_pointer(conn, (void *)uuid); i++)
    if (maybe_copy_unified_arg(conn, (void *)&uuid[i], cudaMemcpyHostToDevice) <
        0)
      return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dev, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuDeviceGetUuid) < 0 ||
      rpc_write(conn, &dev, sizeof(CUdevice)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, uuid, 16) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)uuid, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  for (int i = 0; i < 16 && is_unified_pointer(conn, (void *)uuid); i++)
    if (maybe_copy_unified_arg(conn, (void *)&uuid[i], cudaMemcpyDeviceToHost) <
        0)
      return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dev, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuDeviceGetUuid_v2(CUuuid *uuid, CUdevice dev) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)uuid, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  for (int i = 0; i < 16 && is_unified_pointer(conn, (void *)uuid); i++)
    if (maybe_copy_unified_arg(conn, (void *)&uuid[i], cudaMemcpyHostToDevice) <
        0)
      return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dev, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuDeviceGetUuid_v2) < 0 ||
      rpc_write(conn, &dev, sizeof(CUdevice)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, uuid, 16) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)uuid, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  for (int i = 0; i < 16 && is_unified_pointer(conn, (void *)uuid); i++)
    if (maybe_copy_unified_arg(conn, (void *)&uuid[i], cudaMemcpyDeviceToHost) <
        0)
      return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dev, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuDeviceGetLuid(char *luid, unsigned int *deviceNodeMask,
                         CUdevice dev) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)luid, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)deviceNodeMask,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dev, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  std::size_t luid_len;
  if (rpc_write_start_request(conn, RPC_cuDeviceGetLuid) < 0 ||
      rpc_write(conn, &dev, sizeof(CUdevice)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &luid_len, sizeof(std::size_t)) < 0 ||
      rpc_read(conn, luid, luid_len) < 0 ||
      rpc_read(conn, deviceNodeMask, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)luid, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)deviceNodeMask,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dev, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuDeviceTotalMem_v2(size_t *bytes, CUdevice dev) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)bytes, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dev, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuDeviceTotalMem_v2) < 0 ||
      rpc_write(conn, &dev, sizeof(CUdevice)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, bytes, sizeof(size_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)bytes, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dev, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuDeviceGetTexture1DLinearMaxWidth(size_t *maxWidthInElements,
                                            CUarray_format format,
                                            unsigned numChannels,
                                            CUdevice dev) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)maxWidthInElements,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&format, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numChannels,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dev, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuDeviceGetTexture1DLinearMaxWidth) <
          0 ||
      rpc_write(conn, &format, sizeof(CUarray_format)) < 0 ||
      rpc_write(conn, &numChannels, sizeof(unsigned)) < 0 ||
      rpc_write(conn, &dev, sizeof(CUdevice)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, maxWidthInElements, sizeof(size_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)maxWidthInElements,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&format, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numChannels,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dev, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuDeviceGetAttribute(int *pi, CUdevice_attribute attrib,
                              CUdevice dev) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pi, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&attrib, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dev, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuDeviceGetAttribute) < 0 ||
      rpc_write(conn, &attrib, sizeof(CUdevice_attribute)) < 0 ||
      rpc_write(conn, &dev, sizeof(CUdevice)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, pi, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pi, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&attrib, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dev, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuDeviceSetMemPool(CUdevice dev, CUmemoryPool pool) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&dev, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&pool, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuDeviceSetMemPool) < 0 ||
      rpc_write(conn, &dev, sizeof(CUdevice)) < 0 ||
      rpc_write(conn, &pool, sizeof(CUmemoryPool)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dev, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&pool, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuDeviceGetMemPool(CUmemoryPool *pool, CUdevice dev) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pool, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dev, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuDeviceGetMemPool) < 0 ||
      rpc_write(conn, &dev, sizeof(CUdevice)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pool, sizeof(CUmemoryPool)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pool, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dev, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuDeviceGetDefaultMemPool(CUmemoryPool *pool_out, CUdevice dev) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pool_out, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dev, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuDeviceGetDefaultMemPool) < 0 ||
      rpc_write(conn, &dev, sizeof(CUdevice)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pool_out, sizeof(CUmemoryPool)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pool_out, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dev, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuDeviceGetExecAffinitySupport(int *pi, CUexecAffinityType type,
                                        CUdevice dev) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pi, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&type, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dev, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuDeviceGetExecAffinitySupport) < 0 ||
      rpc_write(conn, &type, sizeof(CUexecAffinityType)) < 0 ||
      rpc_write(conn, &dev, sizeof(CUdevice)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, pi, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pi, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&type, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dev, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuFlushGPUDirectRDMAWrites(CUflushGPUDirectRDMAWritesTarget target,
                                    CUflushGPUDirectRDMAWritesScope scope) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&target, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&scope, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuFlushGPUDirectRDMAWrites) < 0 ||
      rpc_write(conn, &target, sizeof(CUflushGPUDirectRDMAWritesTarget)) < 0 ||
      rpc_write(conn, &scope, sizeof(CUflushGPUDirectRDMAWritesScope)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&target, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&scope, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuDeviceGetProperties(CUdevprop *prop, CUdevice dev) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)prop, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dev, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuDeviceGetProperties) < 0 ||
      rpc_write(conn, &dev, sizeof(CUdevice)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, prop, sizeof(CUdevprop)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)prop, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dev, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuDeviceComputeCapability(int *major, int *minor, CUdevice dev) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)major, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)minor, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dev, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuDeviceComputeCapability) < 0 ||
      rpc_write(conn, &dev, sizeof(CUdevice)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, major, sizeof(int)) < 0 ||
      rpc_read(conn, minor, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)major, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)minor, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dev, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuDevicePrimaryCtxRetain(CUcontext *pctx, CUdevice dev) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pctx, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dev, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuDevicePrimaryCtxRetain) < 0 ||
      rpc_write(conn, &dev, sizeof(CUdevice)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pctx, sizeof(CUcontext)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pctx, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dev, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuDevicePrimaryCtxRelease_v2(CUdevice dev) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&dev, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuDevicePrimaryCtxRelease_v2) < 0 ||
      rpc_write(conn, &dev, sizeof(CUdevice)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dev, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuDevicePrimaryCtxSetFlags_v2(CUdevice dev, unsigned int flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&dev, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuDevicePrimaryCtxSetFlags_v2) < 0 ||
      rpc_write(conn, &dev, sizeof(CUdevice)) < 0 ||
      rpc_write(conn, &flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dev, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuDevicePrimaryCtxGetState(CUdevice dev, unsigned int *flags,
                                    int *active) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&dev, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)flags, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)active, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuDevicePrimaryCtxGetState) < 0 ||
      rpc_write(conn, &dev, sizeof(CUdevice)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, flags, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, active, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dev, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)flags, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)active, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuDevicePrimaryCtxReset_v2(CUdevice dev) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&dev, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuDevicePrimaryCtxReset_v2) < 0 ||
      rpc_write(conn, &dev, sizeof(CUdevice)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dev, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuCtxCreate_v2(CUcontext *pctx, unsigned int flags, CUdevice dev) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pctx, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dev, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuCtxCreate_v2) < 0 ||
      rpc_write(conn, &flags, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &dev, sizeof(CUdevice)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pctx, sizeof(CUcontext)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pctx, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dev, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuCtxCreate_v3(CUcontext *pctx, CUexecAffinityParam *paramsArray,
                        int numParams, unsigned int flags, CUdevice dev) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pctx, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numParams, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)paramsArray,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  for (int i = 0; i < static_cast<int>(numParams) &&
                  is_unified_pointer(conn, (void *)paramsArray);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&paramsArray[i],
                               cudaMemcpyHostToDevice) < 0)
      return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dev, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuCtxCreate_v3) < 0 ||
      rpc_write(conn, &numParams, sizeof(int)) < 0 ||
      rpc_write(conn, &flags, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &dev, sizeof(CUdevice)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pctx, sizeof(CUcontext)) < 0 ||
      rpc_read(conn, paramsArray, numParams * sizeof(CUexecAffinityParam)) <
          0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pctx, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numParams, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)paramsArray,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  for (int i = 0; i < static_cast<int>(numParams) &&
                  is_unified_pointer(conn, (void *)paramsArray);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&paramsArray[i],
                               cudaMemcpyDeviceToHost) < 0)
      return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dev, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuCtxDestroy_v2(CUcontext ctx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&ctx, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuCtxDestroy_v2) < 0 ||
      rpc_write(conn, &ctx, sizeof(CUcontext)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ctx, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuCtxPushCurrent_v2(CUcontext ctx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&ctx, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuCtxPushCurrent_v2) < 0 ||
      rpc_write(conn, &ctx, sizeof(CUcontext)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ctx, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuCtxPopCurrent_v2(CUcontext *pctx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pctx, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuCtxPopCurrent_v2) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pctx, sizeof(CUcontext)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pctx, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuCtxSetCurrent(CUcontext ctx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&ctx, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuCtxSetCurrent) < 0 ||
      rpc_write(conn, &ctx, sizeof(CUcontext)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ctx, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuCtxGetCurrent(CUcontext *pctx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pctx, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuCtxGetCurrent) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pctx, sizeof(CUcontext)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pctx, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuCtxGetDevice(CUdevice *device) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)device, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuCtxGetDevice) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, device, sizeof(CUdevice)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)device, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuCtxGetFlags(unsigned int *flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)flags, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuCtxGetFlags) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, flags, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)flags, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuCtxGetId(CUcontext ctx, unsigned long long *ctxId) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&ctx, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)ctxId, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuCtxGetId) < 0 ||
      rpc_write(conn, &ctx, sizeof(CUcontext)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, ctxId, sizeof(unsigned long long)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ctx, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)ctxId, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuCtxSynchronize() {
  conn_t *conn = rpc_client_get_connection(0);
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuCtxSynchronize) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuCtxSetLimit(CUlimit limit, size_t value) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&limit, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&value, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuCtxSetLimit) < 0 ||
      rpc_write(conn, &limit, sizeof(CUlimit)) < 0 ||
      rpc_write(conn, &value, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&limit, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&value, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuCtxGetLimit(size_t *pvalue, CUlimit limit) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pvalue, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&limit, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuCtxGetLimit) < 0 ||
      rpc_write(conn, &limit, sizeof(CUlimit)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pvalue, sizeof(size_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pvalue, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&limit, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuCtxGetCacheConfig(CUfunc_cache *pconfig) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pconfig, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuCtxGetCacheConfig) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pconfig, sizeof(CUfunc_cache)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pconfig, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuCtxSetCacheConfig(CUfunc_cache config) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&config, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuCtxSetCacheConfig) < 0 ||
      rpc_write(conn, &config, sizeof(CUfunc_cache)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&config, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuCtxGetSharedMemConfig(CUsharedconfig *pConfig) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pConfig, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuCtxGetSharedMemConfig) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pConfig, sizeof(CUsharedconfig)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pConfig, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuCtxSetSharedMemConfig(CUsharedconfig config) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&config, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuCtxSetSharedMemConfig) < 0 ||
      rpc_write(conn, &config, sizeof(CUsharedconfig)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&config, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuCtxGetApiVersion(CUcontext ctx, unsigned int *version) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&ctx, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)version, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuCtxGetApiVersion) < 0 ||
      rpc_write(conn, &ctx, sizeof(CUcontext)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, version, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ctx, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)version, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuCtxGetStreamPriorityRange(int *leastPriority,
                                     int *greatestPriority) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)leastPriority,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)greatestPriority,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuCtxGetStreamPriorityRange) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, leastPriority, sizeof(int)) < 0 ||
      rpc_read(conn, greatestPriority, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)leastPriority,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)greatestPriority,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuCtxResetPersistingL2Cache() {
  conn_t *conn = rpc_client_get_connection(0);
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuCtxResetPersistingL2Cache) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuCtxGetExecAffinity(CUexecAffinityParam *pExecAffinity,
                              CUexecAffinityType type) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pExecAffinity,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&type, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuCtxGetExecAffinity) < 0 ||
      rpc_write(conn, &type, sizeof(CUexecAffinityType)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pExecAffinity, sizeof(CUexecAffinityParam)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pExecAffinity,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&type, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuCtxAttach(CUcontext *pctx, unsigned int flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pctx, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuCtxAttach) < 0 ||
      rpc_write(conn, &flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pctx, sizeof(CUcontext)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pctx, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuCtxDetach(CUcontext ctx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&ctx, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuCtxDetach) < 0 ||
      rpc_write(conn, &ctx, sizeof(CUcontext)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ctx, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuModuleLoad(CUmodule *module, const char *fname) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)module, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)fname, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  std::size_t fname_len = std::strlen(fname) + 1;
  if (rpc_write_start_request(conn, RPC_cuModuleLoad) < 0 ||
      rpc_write(conn, &fname_len, sizeof(std::size_t)) < 0 ||
      rpc_write(conn, fname, fname_len) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, module, sizeof(CUmodule)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)module, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)fname, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuModuleUnload(CUmodule hmod) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hmod, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuModuleUnload) < 0 ||
      rpc_write(conn, &hmod, sizeof(CUmodule)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hmod, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuModuleGetLoadingMode(CUmoduleLoadingMode *mode) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)mode, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuModuleGetLoadingMode) < 0 ||
      rpc_write(conn, mode, sizeof(CUmoduleLoadingMode)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, mode, sizeof(CUmoduleLoadingMode)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)mode, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuModuleGetFunction(CUfunction *hfunc, CUmodule hmod,
                             const char *name) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)hfunc, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hmod, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)name, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  std::size_t name_len = std::strlen(name) + 1;
  if (rpc_write_start_request(conn, RPC_cuModuleGetFunction) < 0 ||
      rpc_write(conn, &hmod, sizeof(CUmodule)) < 0 ||
      rpc_write(conn, &name_len, sizeof(std::size_t)) < 0 ||
      rpc_write(conn, name, name_len) < 0 || rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, hfunc, sizeof(CUfunction)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)hfunc, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hmod, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)name, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuModuleGetGlobal_v2(CUdeviceptr *dptr, size_t *bytes, CUmodule hmod,
                              const char *name) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)dptr, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)bytes, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hmod, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)name, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  std::size_t name_len = std::strlen(name) + 1;
  if (rpc_write_start_request(conn, RPC_cuModuleGetGlobal_v2) < 0 ||
      rpc_write(conn, &hmod, sizeof(CUmodule)) < 0 ||
      rpc_write(conn, &name_len, sizeof(std::size_t)) < 0 ||
      rpc_write(conn, name, name_len) < 0 || rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, dptr, sizeof(CUdeviceptr)) < 0 ||
      rpc_read(conn, bytes, sizeof(size_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)dptr, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)bytes, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hmod, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)name, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuLinkCreate_v2(unsigned int numOptions, CUjit_option *options,
                         void **optionValues, CUlinkState *stateOut) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&numOptions,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)options, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)optionValues,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)stateOut, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuLinkCreate_v2) < 0 ||
      rpc_write(conn, &numOptions, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, options, sizeof(CUjit_option)) < 0 ||
      rpc_write(conn, optionValues, sizeof(void *)) < 0 ||
      rpc_write(conn, stateOut, sizeof(CUlinkState)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, options, sizeof(CUjit_option)) < 0 ||
      rpc_read(conn, optionValues, sizeof(void *)) < 0 ||
      rpc_read(conn, stateOut, sizeof(CUlinkState)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numOptions,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)options, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)optionValues,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)stateOut, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuLinkAddFile_v2(CUlinkState state, CUjitInputType type,
                          const char *path, unsigned int numOptions,
                          CUjit_option *options, void **optionValues) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&state, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&type, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)path, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numOptions,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)options, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  for (int i = 0; i < static_cast<int>(numOptions) &&
                  is_unified_pointer(conn, (void *)options);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&options[i],
                               cudaMemcpyHostToDevice) < 0)
      return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)optionValues,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  for (int i = 0; i < static_cast<int>(numOptions) &&
                  is_unified_pointer(conn, (void *)optionValues);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&optionValues[i],
                               cudaMemcpyHostToDevice) < 0)
      return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  std::size_t path_len = std::strlen(path) + 1;
  if (rpc_write_start_request(conn, RPC_cuLinkAddFile_v2) < 0 ||
      rpc_write(conn, &state, sizeof(CUlinkState)) < 0 ||
      rpc_write(conn, &type, sizeof(CUjitInputType)) < 0 ||
      rpc_write(conn, &path_len, sizeof(std::size_t)) < 0 ||
      rpc_write(conn, path, path_len) < 0 ||
      rpc_write(conn, &numOptions, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, options, numOptions * sizeof(CUjit_option)) < 0 ||
      rpc_write(conn, optionValues, numOptions * sizeof(void *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&state, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&type, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)path, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numOptions,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)options, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  for (int i = 0; i < static_cast<int>(numOptions) &&
                  is_unified_pointer(conn, (void *)options);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&options[i],
                               cudaMemcpyDeviceToHost) < 0)
      return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)optionValues,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  for (int i = 0; i < static_cast<int>(numOptions) &&
                  is_unified_pointer(conn, (void *)optionValues);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&optionValues[i],
                               cudaMemcpyDeviceToHost) < 0)
      return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuLinkComplete(CUlinkState state, void **cubinOut, size_t *sizeOut) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&state, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)cubinOut, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)sizeOut, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuLinkComplete) < 0 ||
      rpc_write(conn, &state, sizeof(CUlinkState)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, cubinOut, sizeof(void *)) < 0 ||
      rpc_read(conn, sizeOut, sizeof(size_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&state, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)cubinOut, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)sizeOut, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuLinkDestroy(CUlinkState state) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&state, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuLinkDestroy) < 0 ||
      rpc_write(conn, &state, sizeof(CUlinkState)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&state, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuModuleGetTexRef(CUtexref *pTexRef, CUmodule hmod, const char *name) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pTexRef, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hmod, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)name, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  std::size_t name_len = std::strlen(name) + 1;
  if (rpc_write_start_request(conn, RPC_cuModuleGetTexRef) < 0 ||
      rpc_write(conn, &hmod, sizeof(CUmodule)) < 0 ||
      rpc_write(conn, &name_len, sizeof(std::size_t)) < 0 ||
      rpc_write(conn, name, name_len) < 0 || rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pTexRef, sizeof(CUtexref)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pTexRef, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hmod, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)name, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuModuleGetSurfRef(CUsurfref *pSurfRef, CUmodule hmod,
                            const char *name) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pSurfRef, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hmod, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)name, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  std::size_t name_len = std::strlen(name) + 1;
  if (rpc_write_start_request(conn, RPC_cuModuleGetSurfRef) < 0 ||
      rpc_write(conn, &hmod, sizeof(CUmodule)) < 0 ||
      rpc_write(conn, &name_len, sizeof(std::size_t)) < 0 ||
      rpc_write(conn, name, name_len) < 0 || rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pSurfRef, sizeof(CUsurfref)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pSurfRef, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hmod, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)name, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuLibraryLoadFromFile(CUlibrary *library, const char *fileName,
                               CUjit_option *jitOptions,
                               void **jitOptionsValues,
                               unsigned int numJitOptions,
                               CUlibraryOption *libraryOptions,
                               void **libraryOptionValues,
                               unsigned int numLibraryOptions) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)library, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)fileName, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numJitOptions,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)jitOptions, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  for (int i = 0; i < static_cast<int>(numJitOptions) &&
                  is_unified_pointer(conn, (void *)jitOptions);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&jitOptions[i],
                               cudaMemcpyHostToDevice) < 0)
      return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)jitOptionsValues,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  for (int i = 0; i < static_cast<int>(numJitOptions) &&
                  is_unified_pointer(conn, (void *)jitOptionsValues);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&jitOptionsValues[i],
                               cudaMemcpyHostToDevice) < 0)
      return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numLibraryOptions,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)libraryOptions,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  for (int i = 0; i < static_cast<int>(numLibraryOptions) &&
                  is_unified_pointer(conn, (void *)libraryOptions);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&libraryOptions[i],
                               cudaMemcpyHostToDevice) < 0)
      return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)libraryOptionValues,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  for (int i = 0; i < static_cast<int>(numLibraryOptions) &&
                  is_unified_pointer(conn, (void *)libraryOptionValues);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&libraryOptionValues[i],
                               cudaMemcpyHostToDevice) < 0)
      return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  std::size_t fileName_len = std::strlen(fileName) + 1;
  if (rpc_write_start_request(conn, RPC_cuLibraryLoadFromFile) < 0 ||
      rpc_write(conn, &fileName_len, sizeof(std::size_t)) < 0 ||
      rpc_write(conn, fileName, fileName_len) < 0 ||
      rpc_write(conn, &numJitOptions, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, jitOptions, numJitOptions * sizeof(CUjit_option)) < 0 ||
      rpc_write(conn, jitOptionsValues, numJitOptions * sizeof(void *)) < 0 ||
      rpc_write(conn, &numLibraryOptions, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, libraryOptions,
                numLibraryOptions * sizeof(CUlibraryOption)) < 0 ||
      rpc_write(conn, libraryOptionValues, numLibraryOptions * sizeof(void *)) <
          0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, library, sizeof(CUlibrary)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)library, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)fileName, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numJitOptions,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)jitOptions, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  for (int i = 0; i < static_cast<int>(numJitOptions) &&
                  is_unified_pointer(conn, (void *)jitOptions);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&jitOptions[i],
                               cudaMemcpyDeviceToHost) < 0)
      return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)jitOptionsValues,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  for (int i = 0; i < static_cast<int>(numJitOptions) &&
                  is_unified_pointer(conn, (void *)jitOptionsValues);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&jitOptionsValues[i],
                               cudaMemcpyDeviceToHost) < 0)
      return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numLibraryOptions,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)libraryOptions,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  for (int i = 0; i < static_cast<int>(numLibraryOptions) &&
                  is_unified_pointer(conn, (void *)libraryOptions);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&libraryOptions[i],
                               cudaMemcpyDeviceToHost) < 0)
      return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)libraryOptionValues,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  for (int i = 0; i < static_cast<int>(numLibraryOptions) &&
                  is_unified_pointer(conn, (void *)libraryOptionValues);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&libraryOptionValues[i],
                               cudaMemcpyDeviceToHost) < 0)
      return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuLibraryUnload(CUlibrary library) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&library, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuLibraryUnload) < 0 ||
      rpc_write(conn, &library, sizeof(CUlibrary)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&library, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuLibraryGetKernel(CUkernel *pKernel, CUlibrary library,
                            const char *name) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pKernel, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&library, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)name, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  std::size_t name_len = std::strlen(name) + 1;
  if (rpc_write_start_request(conn, RPC_cuLibraryGetKernel) < 0 ||
      rpc_write(conn, &library, sizeof(CUlibrary)) < 0 ||
      rpc_write(conn, &name_len, sizeof(std::size_t)) < 0 ||
      rpc_write(conn, name, name_len) < 0 || rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pKernel, sizeof(CUkernel)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pKernel, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&library, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)name, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuLibraryGetModule(CUmodule *pMod, CUlibrary library) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pMod, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&library, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuLibraryGetModule) < 0 ||
      rpc_write(conn, &library, sizeof(CUlibrary)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pMod, sizeof(CUmodule)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pMod, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&library, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuKernelGetFunction(CUfunction *pFunc, CUkernel kernel) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pFunc, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&kernel, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuKernelGetFunction) < 0 ||
      rpc_write(conn, &kernel, sizeof(CUkernel)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pFunc, sizeof(CUfunction)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pFunc, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&kernel, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuLibraryGetGlobal(CUdeviceptr *dptr, size_t *bytes, CUlibrary library,
                            const char *name) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)dptr, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)bytes, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&library, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)name, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  std::size_t name_len = std::strlen(name) + 1;
  if (rpc_write_start_request(conn, RPC_cuLibraryGetGlobal) < 0 ||
      rpc_write(conn, &library, sizeof(CUlibrary)) < 0 ||
      rpc_write(conn, &name_len, sizeof(std::size_t)) < 0 ||
      rpc_write(conn, name, name_len) < 0 || rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, dptr, sizeof(CUdeviceptr)) < 0 ||
      rpc_read(conn, bytes, sizeof(size_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)dptr, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)bytes, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&library, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)name, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuLibraryGetManaged(CUdeviceptr *dptr, size_t *bytes,
                             CUlibrary library, const char *name) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)dptr, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)bytes, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&library, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)name, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  std::size_t name_len = std::strlen(name) + 1;
  if (rpc_write_start_request(conn, RPC_cuLibraryGetManaged) < 0 ||
      rpc_write(conn, &library, sizeof(CUlibrary)) < 0 ||
      rpc_write(conn, &name_len, sizeof(std::size_t)) < 0 ||
      rpc_write(conn, name, name_len) < 0 || rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, dptr, sizeof(CUdeviceptr)) < 0 ||
      rpc_read(conn, bytes, sizeof(size_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)dptr, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)bytes, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&library, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)name, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuLibraryGetUnifiedFunction(void **fptr, CUlibrary library,
                                     const char *symbol) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)fptr, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&library, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)symbol, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  std::size_t symbol_len = std::strlen(symbol) + 1;
  if (rpc_write_start_request(conn, RPC_cuLibraryGetUnifiedFunction) < 0 ||
      rpc_write(conn, &library, sizeof(CUlibrary)) < 0 ||
      rpc_write(conn, &symbol_len, sizeof(std::size_t)) < 0 ||
      rpc_write(conn, symbol, symbol_len) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, fptr, sizeof(void *)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)fptr, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&library, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)symbol, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuKernelGetAttribute(int *pi, CUfunction_attribute attrib,
                              CUkernel kernel, CUdevice dev) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pi, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&attrib, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&kernel, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dev, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuKernelGetAttribute) < 0 ||
      rpc_write(conn, pi, sizeof(int)) < 0 ||
      rpc_write(conn, &attrib, sizeof(CUfunction_attribute)) < 0 ||
      rpc_write(conn, &kernel, sizeof(CUkernel)) < 0 ||
      rpc_write(conn, &dev, sizeof(CUdevice)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, pi, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pi, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&attrib, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&kernel, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dev, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuKernelSetAttribute(CUfunction_attribute attrib, int val,
                              CUkernel kernel, CUdevice dev) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&attrib, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&val, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&kernel, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dev, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuKernelSetAttribute) < 0 ||
      rpc_write(conn, &attrib, sizeof(CUfunction_attribute)) < 0 ||
      rpc_write(conn, &val, sizeof(int)) < 0 ||
      rpc_write(conn, &kernel, sizeof(CUkernel)) < 0 ||
      rpc_write(conn, &dev, sizeof(CUdevice)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&attrib, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&val, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&kernel, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dev, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuKernelSetCacheConfig(CUkernel kernel, CUfunc_cache config,
                                CUdevice dev) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&kernel, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&config, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dev, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuKernelSetCacheConfig) < 0 ||
      rpc_write(conn, &kernel, sizeof(CUkernel)) < 0 ||
      rpc_write(conn, &config, sizeof(CUfunc_cache)) < 0 ||
      rpc_write(conn, &dev, sizeof(CUdevice)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&kernel, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&config, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dev, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemGetInfo_v2(size_t *free, size_t *total) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)free, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)total, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemGetInfo_v2) < 0 ||
      rpc_write(conn, free, sizeof(size_t)) < 0 ||
      rpc_write(conn, total, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, free, sizeof(size_t)) < 0 ||
      rpc_read(conn, total, sizeof(size_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)free, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)total, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemAlloc_v2(CUdeviceptr *dptr, size_t bytesize) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)dptr, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&bytesize, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemAlloc_v2) < 0 ||
      rpc_write(conn, dptr, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &bytesize, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, dptr, sizeof(CUdeviceptr)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)dptr, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&bytesize, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemAllocPitch_v2(CUdeviceptr *dptr, size_t *pPitch,
                            size_t WidthInBytes, size_t Height,
                            unsigned int ElementSizeBytes) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)dptr, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pPitch, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&WidthInBytes,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Height, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ElementSizeBytes,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemAllocPitch_v2) < 0 ||
      rpc_write(conn, dptr, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, pPitch, sizeof(size_t)) < 0 ||
      rpc_write(conn, &WidthInBytes, sizeof(size_t)) < 0 ||
      rpc_write(conn, &Height, sizeof(size_t)) < 0 ||
      rpc_write(conn, &ElementSizeBytes, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, dptr, sizeof(CUdeviceptr)) < 0 ||
      rpc_read(conn, pPitch, sizeof(size_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)dptr, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pPitch, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&WidthInBytes,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Height, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ElementSizeBytes,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemFree_v2(CUdeviceptr dptr) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&dptr, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemFree_v2) < 0 ||
      rpc_write(conn, &dptr, sizeof(CUdeviceptr)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dptr, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemGetAddressRange_v2(CUdeviceptr *pbase, size_t *psize,
                                 CUdeviceptr dptr) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pbase, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)psize, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dptr, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemGetAddressRange_v2) < 0 ||
      rpc_write(conn, pbase, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, psize, sizeof(size_t)) < 0 ||
      rpc_write(conn, &dptr, sizeof(CUdeviceptr)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pbase, sizeof(CUdeviceptr)) < 0 ||
      rpc_read(conn, psize, sizeof(size_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pbase, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)psize, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dptr, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemAllocHost_v2(void **pp, size_t bytesize) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pp, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&bytesize, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemAllocHost_v2) < 0 ||
      rpc_write(conn, &bytesize, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pp, sizeof(void *)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pp, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&bytesize, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemFreeHost(void *p) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)p, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemFreeHost) < 0 ||
      rpc_write(conn, &p, sizeof(void *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)p, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemHostAlloc(void **pp, size_t bytesize, unsigned int Flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pp, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&bytesize, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Flags, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemHostAlloc) < 0 ||
      rpc_write(conn, &bytesize, sizeof(size_t)) < 0 ||
      rpc_write(conn, &Flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pp, sizeof(void *)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pp, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&bytesize, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Flags, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemHostGetDevicePointer_v2(CUdeviceptr *pdptr, void *p,
                                      unsigned int Flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pdptr, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)p, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Flags, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemHostGetDevicePointer_v2) < 0 ||
      rpc_write(conn, pdptr, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &p, sizeof(void *)) < 0 ||
      rpc_write(conn, &Flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pdptr, sizeof(CUdeviceptr)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pdptr, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)p, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Flags, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemHostGetFlags(unsigned int *pFlags, void *p) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pFlags, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)p, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemHostGetFlags) < 0 ||
      rpc_write(conn, pFlags, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &p, sizeof(void *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pFlags, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pFlags, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)p, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemAllocManaged(CUdeviceptr *dptr, size_t bytesize,
                           unsigned int flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)dptr, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&bytesize, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemAllocManaged) < 0 ||
      rpc_write(conn, dptr, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &bytesize, sizeof(size_t)) < 0 ||
      rpc_write(conn, &flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, dptr, sizeof(CUdeviceptr)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)dptr, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&bytesize, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuDeviceGetByPCIBusId(CUdevice *dev, const char *pciBusId) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)dev, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pciBusId, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  std::size_t pciBusId_len = std::strlen(pciBusId) + 1;
  if (rpc_write_start_request(conn, RPC_cuDeviceGetByPCIBusId) < 0 ||
      rpc_write(conn, dev, sizeof(CUdevice)) < 0 ||
      rpc_write(conn, &pciBusId_len, sizeof(std::size_t)) < 0 ||
      rpc_write(conn, pciBusId, pciBusId_len) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, dev, sizeof(CUdevice)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)dev, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pciBusId, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuDeviceGetPCIBusId(char *pciBusId, int len, CUdevice dev) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&len, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pciBusId, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  for (int i = 0;
       i < static_cast<int>(len) && is_unified_pointer(conn, (void *)pciBusId);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&pciBusId[i],
                               cudaMemcpyHostToDevice) < 0)
      return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dev, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuDeviceGetPCIBusId) < 0 ||
      rpc_write(conn, &len, sizeof(int)) < 0 ||
      rpc_write(conn, &dev, sizeof(CUdevice)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pciBusId, len * sizeof(char)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&len, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pciBusId, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  for (int i = 0;
       i < static_cast<int>(len) && is_unified_pointer(conn, (void *)pciBusId);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&pciBusId[i],
                               cudaMemcpyDeviceToHost) < 0)
      return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dev, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuIpcGetEventHandle(CUipcEventHandle *pHandle, CUevent event) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pHandle, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&event, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuIpcGetEventHandle) < 0 ||
      rpc_write(conn, pHandle, sizeof(CUipcEventHandle)) < 0 ||
      rpc_write(conn, &event, sizeof(CUevent)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pHandle, sizeof(CUipcEventHandle)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pHandle, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&event, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuIpcOpenEventHandle(CUevent *phEvent, CUipcEventHandle handle) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)phEvent, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuIpcOpenEventHandle) < 0 ||
      rpc_write(conn, phEvent, sizeof(CUevent)) < 0 ||
      rpc_write(conn, &handle, sizeof(CUipcEventHandle)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, phEvent, sizeof(CUevent)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)phEvent, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuIpcGetMemHandle(CUipcMemHandle *pHandle, CUdeviceptr dptr) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pHandle, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dptr, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuIpcGetMemHandle) < 0 ||
      rpc_write(conn, pHandle, sizeof(CUipcMemHandle)) < 0 ||
      rpc_write(conn, &dptr, sizeof(CUdeviceptr)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pHandle, sizeof(CUipcMemHandle)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pHandle, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dptr, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuIpcOpenMemHandle_v2(CUdeviceptr *pdptr, CUipcMemHandle handle,
                               unsigned int Flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pdptr, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Flags, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuIpcOpenMemHandle_v2) < 0 ||
      rpc_write(conn, pdptr, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &handle, sizeof(CUipcMemHandle)) < 0 ||
      rpc_write(conn, &Flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pdptr, sizeof(CUdeviceptr)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pdptr, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Flags, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuIpcCloseMemHandle(CUdeviceptr dptr) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&dptr, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuIpcCloseMemHandle) < 0 ||
      rpc_write(conn, &dptr, sizeof(CUdeviceptr)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dptr, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemcpy(CUdeviceptr dst, CUdeviceptr src, size_t ByteCount) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&dst, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&src, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ByteCount, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemcpy) < 0 ||
      rpc_write(conn, &dst, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &src, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &ByteCount, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dst, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&src, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ByteCount, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemcpyPeer(CUdeviceptr dstDevice, CUcontext dstContext,
                      CUdeviceptr srcDevice, CUcontext srcContext,
                      size_t ByteCount) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&dstDevice, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dstContext,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&srcDevice, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&srcContext,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ByteCount, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemcpyPeer) < 0 ||
      rpc_write(conn, &dstDevice, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &dstContext, sizeof(CUcontext)) < 0 ||
      rpc_write(conn, &srcDevice, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &srcContext, sizeof(CUcontext)) < 0 ||
      rpc_write(conn, &ByteCount, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dstDevice, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dstContext,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&srcDevice, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&srcContext,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ByteCount, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemcpyHtoD_v2(CUdeviceptr dstDevice, const void *srcHost,
                         size_t ByteCount) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&dstDevice, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)srcHost, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ByteCount, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemcpyHtoD_v2) < 0 ||
      rpc_write(conn, &dstDevice, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &srcHost, sizeof(const void *)) < 0 ||
      rpc_write(conn, &ByteCount, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dstDevice, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)srcHost, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ByteCount, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemcpyDtoD_v2(CUdeviceptr dstDevice, CUdeviceptr srcDevice,
                         size_t ByteCount) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&dstDevice, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&srcDevice, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ByteCount, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemcpyDtoD_v2) < 0 ||
      rpc_write(conn, &dstDevice, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &srcDevice, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &ByteCount, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dstDevice, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&srcDevice, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ByteCount, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemcpyDtoA_v2(CUarray dstArray, size_t dstOffset,
                         CUdeviceptr srcDevice, size_t ByteCount) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&dstArray, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dstOffset, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&srcDevice, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ByteCount, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemcpyDtoA_v2) < 0 ||
      rpc_write(conn, &dstArray, sizeof(CUarray)) < 0 ||
      rpc_write(conn, &dstOffset, sizeof(size_t)) < 0 ||
      rpc_write(conn, &srcDevice, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &ByteCount, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dstArray, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dstOffset, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&srcDevice, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ByteCount, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemcpyAtoD_v2(CUdeviceptr dstDevice, CUarray srcArray,
                         size_t srcOffset, size_t ByteCount) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&dstDevice, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&srcArray, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&srcOffset, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ByteCount, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemcpyAtoD_v2) < 0 ||
      rpc_write(conn, &dstDevice, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &srcArray, sizeof(CUarray)) < 0 ||
      rpc_write(conn, &srcOffset, sizeof(size_t)) < 0 ||
      rpc_write(conn, &ByteCount, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dstDevice, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&srcArray, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&srcOffset, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ByteCount, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemcpyAtoH_v2(void *dstHost, CUarray srcArray, size_t srcOffset,
                         size_t ByteCount) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)dstHost, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&srcArray, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&srcOffset, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ByteCount, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemcpyAtoH_v2) < 0 ||
      rpc_write(conn, &dstHost, sizeof(void *)) < 0 ||
      rpc_write(conn, &srcArray, sizeof(CUarray)) < 0 ||
      rpc_write(conn, &srcOffset, sizeof(size_t)) < 0 ||
      rpc_write(conn, &ByteCount, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)dstHost, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&srcArray, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&srcOffset, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ByteCount, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemcpyAtoA_v2(CUarray dstArray, size_t dstOffset, CUarray srcArray,
                         size_t srcOffset, size_t ByteCount) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&dstArray, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dstOffset, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&srcArray, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&srcOffset, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ByteCount, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemcpyAtoA_v2) < 0 ||
      rpc_write(conn, &dstArray, sizeof(CUarray)) < 0 ||
      rpc_write(conn, &dstOffset, sizeof(size_t)) < 0 ||
      rpc_write(conn, &srcArray, sizeof(CUarray)) < 0 ||
      rpc_write(conn, &srcOffset, sizeof(size_t)) < 0 ||
      rpc_write(conn, &ByteCount, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dstArray, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dstOffset, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&srcArray, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&srcOffset, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ByteCount, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemcpyAsync(CUdeviceptr dst, CUdeviceptr src, size_t ByteCount,
                       CUstream hStream) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&dst, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&src, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ByteCount, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemcpyAsync) < 0 ||
      rpc_write(conn, &dst, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &src, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &ByteCount, sizeof(size_t)) < 0 ||
      rpc_write(conn, &hStream, sizeof(CUstream)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dst, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&src, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ByteCount, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemcpyPeerAsync(CUdeviceptr dstDevice, CUcontext dstContext,
                           CUdeviceptr srcDevice, CUcontext srcContext,
                           size_t ByteCount, CUstream hStream) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&dstDevice, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dstContext,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&srcDevice, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&srcContext,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ByteCount, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemcpyPeerAsync) < 0 ||
      rpc_write(conn, &dstDevice, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &dstContext, sizeof(CUcontext)) < 0 ||
      rpc_write(conn, &srcDevice, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &srcContext, sizeof(CUcontext)) < 0 ||
      rpc_write(conn, &ByteCount, sizeof(size_t)) < 0 ||
      rpc_write(conn, &hStream, sizeof(CUstream)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dstDevice, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dstContext,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&srcDevice, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&srcContext,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ByteCount, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemcpyHtoDAsync_v2(CUdeviceptr dstDevice, const void *srcHost,
                              size_t ByteCount, CUstream hStream) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&dstDevice, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)srcHost, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ByteCount, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemcpyHtoDAsync_v2) < 0 ||
      rpc_write(conn, &dstDevice, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &srcHost, sizeof(const void *)) < 0 ||
      rpc_write(conn, &ByteCount, sizeof(size_t)) < 0 ||
      rpc_write(conn, &hStream, sizeof(CUstream)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dstDevice, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)srcHost, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ByteCount, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemcpyDtoDAsync_v2(CUdeviceptr dstDevice, CUdeviceptr srcDevice,
                              size_t ByteCount, CUstream hStream) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&dstDevice, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&srcDevice, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ByteCount, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemcpyDtoDAsync_v2) < 0 ||
      rpc_write(conn, &dstDevice, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &srcDevice, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &ByteCount, sizeof(size_t)) < 0 ||
      rpc_write(conn, &hStream, sizeof(CUstream)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dstDevice, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&srcDevice, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ByteCount, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemsetD8_v2(CUdeviceptr dstDevice, unsigned char uc, size_t N) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&dstDevice, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&uc, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&N, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemsetD8_v2) < 0 ||
      rpc_write(conn, &dstDevice, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &uc, sizeof(unsigned char)) < 0 ||
      rpc_write(conn, &N, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dstDevice, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&uc, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&N, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemsetD16_v2(CUdeviceptr dstDevice, unsigned short us, size_t N) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&dstDevice, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&us, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&N, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemsetD16_v2) < 0 ||
      rpc_write(conn, &dstDevice, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &us, sizeof(unsigned short)) < 0 ||
      rpc_write(conn, &N, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dstDevice, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&us, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&N, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemsetD32_v2(CUdeviceptr dstDevice, unsigned int ui, size_t N) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&dstDevice, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ui, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&N, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemsetD32_v2) < 0 ||
      rpc_write(conn, &dstDevice, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &ui, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &N, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dstDevice, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ui, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&N, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemsetD2D8_v2(CUdeviceptr dstDevice, size_t dstPitch,
                         unsigned char uc, size_t Width, size_t Height) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&dstDevice, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dstPitch, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&uc, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Width, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Height, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemsetD2D8_v2) < 0 ||
      rpc_write(conn, &dstDevice, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &dstPitch, sizeof(size_t)) < 0 ||
      rpc_write(conn, &uc, sizeof(unsigned char)) < 0 ||
      rpc_write(conn, &Width, sizeof(size_t)) < 0 ||
      rpc_write(conn, &Height, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dstDevice, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dstPitch, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&uc, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Width, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Height, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemsetD2D16_v2(CUdeviceptr dstDevice, size_t dstPitch,
                          unsigned short us, size_t Width, size_t Height) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&dstDevice, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dstPitch, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&us, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Width, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Height, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemsetD2D16_v2) < 0 ||
      rpc_write(conn, &dstDevice, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &dstPitch, sizeof(size_t)) < 0 ||
      rpc_write(conn, &us, sizeof(unsigned short)) < 0 ||
      rpc_write(conn, &Width, sizeof(size_t)) < 0 ||
      rpc_write(conn, &Height, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dstDevice, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dstPitch, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&us, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Width, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Height, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemsetD2D32_v2(CUdeviceptr dstDevice, size_t dstPitch,
                          unsigned int ui, size_t Width, size_t Height) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&dstDevice, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dstPitch, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ui, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Width, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Height, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemsetD2D32_v2) < 0 ||
      rpc_write(conn, &dstDevice, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &dstPitch, sizeof(size_t)) < 0 ||
      rpc_write(conn, &ui, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &Width, sizeof(size_t)) < 0 ||
      rpc_write(conn, &Height, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dstDevice, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dstPitch, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ui, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Width, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Height, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemsetD8Async(CUdeviceptr dstDevice, unsigned char uc, size_t N,
                         CUstream hStream) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&dstDevice, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&uc, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&N, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemsetD8Async) < 0 ||
      rpc_write(conn, &dstDevice, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &uc, sizeof(unsigned char)) < 0 ||
      rpc_write(conn, &N, sizeof(size_t)) < 0 ||
      rpc_write(conn, &hStream, sizeof(CUstream)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dstDevice, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&uc, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&N, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemsetD16Async(CUdeviceptr dstDevice, unsigned short us, size_t N,
                          CUstream hStream) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&dstDevice, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&us, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&N, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemsetD16Async) < 0 ||
      rpc_write(conn, &dstDevice, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &us, sizeof(unsigned short)) < 0 ||
      rpc_write(conn, &N, sizeof(size_t)) < 0 ||
      rpc_write(conn, &hStream, sizeof(CUstream)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dstDevice, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&us, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&N, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemsetD32Async(CUdeviceptr dstDevice, unsigned int ui, size_t N,
                          CUstream hStream) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&dstDevice, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ui, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&N, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemsetD32Async) < 0 ||
      rpc_write(conn, &dstDevice, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &ui, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &N, sizeof(size_t)) < 0 ||
      rpc_write(conn, &hStream, sizeof(CUstream)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dstDevice, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ui, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&N, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemsetD2D8Async(CUdeviceptr dstDevice, size_t dstPitch,
                           unsigned char uc, size_t Width, size_t Height,
                           CUstream hStream) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&dstDevice, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dstPitch, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&uc, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Width, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Height, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemsetD2D8Async) < 0 ||
      rpc_write(conn, &dstDevice, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &dstPitch, sizeof(size_t)) < 0 ||
      rpc_write(conn, &uc, sizeof(unsigned char)) < 0 ||
      rpc_write(conn, &Width, sizeof(size_t)) < 0 ||
      rpc_write(conn, &Height, sizeof(size_t)) < 0 ||
      rpc_write(conn, &hStream, sizeof(CUstream)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dstDevice, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dstPitch, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&uc, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Width, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Height, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemsetD2D16Async(CUdeviceptr dstDevice, size_t dstPitch,
                            unsigned short us, size_t Width, size_t Height,
                            CUstream hStream) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&dstDevice, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dstPitch, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&us, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Width, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Height, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemsetD2D16Async) < 0 ||
      rpc_write(conn, &dstDevice, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &dstPitch, sizeof(size_t)) < 0 ||
      rpc_write(conn, &us, sizeof(unsigned short)) < 0 ||
      rpc_write(conn, &Width, sizeof(size_t)) < 0 ||
      rpc_write(conn, &Height, sizeof(size_t)) < 0 ||
      rpc_write(conn, &hStream, sizeof(CUstream)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dstDevice, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dstPitch, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&us, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Width, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Height, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemsetD2D32Async(CUdeviceptr dstDevice, size_t dstPitch,
                            unsigned int ui, size_t Width, size_t Height,
                            CUstream hStream) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&dstDevice, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dstPitch, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ui, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Width, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Height, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemsetD2D32Async) < 0 ||
      rpc_write(conn, &dstDevice, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &dstPitch, sizeof(size_t)) < 0 ||
      rpc_write(conn, &ui, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &Width, sizeof(size_t)) < 0 ||
      rpc_write(conn, &Height, sizeof(size_t)) < 0 ||
      rpc_write(conn, &hStream, sizeof(CUstream)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dstDevice, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dstPitch, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ui, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Width, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Height, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuArrayCreate_v2(CUarray *pHandle,
                          const CUDA_ARRAY_DESCRIPTOR *pAllocateArray) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pHandle, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pAllocateArray,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuArrayCreate_v2) < 0 ||
      rpc_write(conn, pHandle, sizeof(CUarray)) < 0 ||
      rpc_write(conn, &pAllocateArray, sizeof(const CUDA_ARRAY_DESCRIPTOR *)) <
          0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pHandle, sizeof(CUarray)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pHandle, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pAllocateArray,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuArrayGetDescriptor_v2(CUDA_ARRAY_DESCRIPTOR *pArrayDescriptor,
                                 CUarray hArray) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pArrayDescriptor,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hArray, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuArrayGetDescriptor_v2) < 0 ||
      rpc_write(conn, pArrayDescriptor, sizeof(CUDA_ARRAY_DESCRIPTOR)) < 0 ||
      rpc_write(conn, &hArray, sizeof(CUarray)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pArrayDescriptor, sizeof(CUDA_ARRAY_DESCRIPTOR)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pArrayDescriptor,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hArray, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult
cuArrayGetSparseProperties(CUDA_ARRAY_SPARSE_PROPERTIES *sparseProperties,
                           CUarray array) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)sparseProperties,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&array, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuArrayGetSparseProperties) < 0 ||
      rpc_write(conn, sparseProperties, sizeof(CUDA_ARRAY_SPARSE_PROPERTIES)) <
          0 ||
      rpc_write(conn, &array, sizeof(CUarray)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, sparseProperties, sizeof(CUDA_ARRAY_SPARSE_PROPERTIES)) <
          0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)sparseProperties,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&array, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMipmappedArrayGetSparseProperties(
    CUDA_ARRAY_SPARSE_PROPERTIES *sparseProperties, CUmipmappedArray mipmap) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)sparseProperties,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&mipmap, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMipmappedArrayGetSparseProperties) <
          0 ||
      rpc_write(conn, sparseProperties, sizeof(CUDA_ARRAY_SPARSE_PROPERTIES)) <
          0 ||
      rpc_write(conn, &mipmap, sizeof(CUmipmappedArray)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, sparseProperties, sizeof(CUDA_ARRAY_SPARSE_PROPERTIES)) <
          0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)sparseProperties,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&mipmap, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult
cuArrayGetMemoryRequirements(CUDA_ARRAY_MEMORY_REQUIREMENTS *memoryRequirements,
                             CUarray array, CUdevice device) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)memoryRequirements,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&array, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuArrayGetMemoryRequirements) < 0 ||
      rpc_write(conn, memoryRequirements,
                sizeof(CUDA_ARRAY_MEMORY_REQUIREMENTS)) < 0 ||
      rpc_write(conn, &array, sizeof(CUarray)) < 0 ||
      rpc_write(conn, &device, sizeof(CUdevice)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, memoryRequirements,
               sizeof(CUDA_ARRAY_MEMORY_REQUIREMENTS)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)memoryRequirements,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&array, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMipmappedArrayGetMemoryRequirements(
    CUDA_ARRAY_MEMORY_REQUIREMENTS *memoryRequirements, CUmipmappedArray mipmap,
    CUdevice device) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)memoryRequirements,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&mipmap, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMipmappedArrayGetMemoryRequirements) <
          0 ||
      rpc_write(conn, memoryRequirements,
                sizeof(CUDA_ARRAY_MEMORY_REQUIREMENTS)) < 0 ||
      rpc_write(conn, &mipmap, sizeof(CUmipmappedArray)) < 0 ||
      rpc_write(conn, &device, sizeof(CUdevice)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, memoryRequirements,
               sizeof(CUDA_ARRAY_MEMORY_REQUIREMENTS)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)memoryRequirements,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&mipmap, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuArrayGetPlane(CUarray *pPlaneArray, CUarray hArray,
                         unsigned int planeIdx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pPlaneArray,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hArray, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&planeIdx, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuArrayGetPlane) < 0 ||
      rpc_write(conn, pPlaneArray, sizeof(CUarray)) < 0 ||
      rpc_write(conn, &hArray, sizeof(CUarray)) < 0 ||
      rpc_write(conn, &planeIdx, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pPlaneArray, sizeof(CUarray)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pPlaneArray,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hArray, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&planeIdx, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuArrayDestroy(CUarray hArray) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hArray, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuArrayDestroy) < 0 ||
      rpc_write(conn, &hArray, sizeof(CUarray)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hArray, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuArray3DCreate_v2(CUarray *pHandle,
                            const CUDA_ARRAY3D_DESCRIPTOR *pAllocateArray) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pHandle, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pAllocateArray,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuArray3DCreate_v2) < 0 ||
      rpc_write(conn, pHandle, sizeof(CUarray)) < 0 ||
      rpc_write(conn, &pAllocateArray,
                sizeof(const CUDA_ARRAY3D_DESCRIPTOR *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pHandle, sizeof(CUarray)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pHandle, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pAllocateArray,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuArray3DGetDescriptor_v2(CUDA_ARRAY3D_DESCRIPTOR *pArrayDescriptor,
                                   CUarray hArray) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pArrayDescriptor,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hArray, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuArray3DGetDescriptor_v2) < 0 ||
      rpc_write(conn, pArrayDescriptor, sizeof(CUDA_ARRAY3D_DESCRIPTOR)) < 0 ||
      rpc_write(conn, &hArray, sizeof(CUarray)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pArrayDescriptor, sizeof(CUDA_ARRAY3D_DESCRIPTOR)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pArrayDescriptor,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hArray, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult
cuMipmappedArrayCreate(CUmipmappedArray *pHandle,
                       const CUDA_ARRAY3D_DESCRIPTOR *pMipmappedArrayDesc,
                       unsigned int numMipmapLevels) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pHandle, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pMipmappedArrayDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numMipmapLevels,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMipmappedArrayCreate) < 0 ||
      rpc_write(conn, pHandle, sizeof(CUmipmappedArray)) < 0 ||
      rpc_write(conn, &pMipmappedArrayDesc,
                sizeof(const CUDA_ARRAY3D_DESCRIPTOR *)) < 0 ||
      rpc_write(conn, &numMipmapLevels, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pHandle, sizeof(CUmipmappedArray)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pHandle, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pMipmappedArrayDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numMipmapLevels,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMipmappedArrayGetLevel(CUarray *pLevelArray,
                                  CUmipmappedArray hMipmappedArray,
                                  unsigned int level) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pLevelArray,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hMipmappedArray,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&level, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMipmappedArrayGetLevel) < 0 ||
      rpc_write(conn, pLevelArray, sizeof(CUarray)) < 0 ||
      rpc_write(conn, &hMipmappedArray, sizeof(CUmipmappedArray)) < 0 ||
      rpc_write(conn, &level, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pLevelArray, sizeof(CUarray)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pLevelArray,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hMipmappedArray,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&level, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMipmappedArrayDestroy(CUmipmappedArray hMipmappedArray) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hMipmappedArray,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMipmappedArrayDestroy) < 0 ||
      rpc_write(conn, &hMipmappedArray, sizeof(CUmipmappedArray)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hMipmappedArray,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemAddressReserve(CUdeviceptr *ptr, size_t size, size_t alignment,
                             CUdeviceptr addr, unsigned long long flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)ptr, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&size, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&alignment, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&addr, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemAddressReserve) < 0 ||
      rpc_write(conn, ptr, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &size, sizeof(size_t)) < 0 ||
      rpc_write(conn, &alignment, sizeof(size_t)) < 0 ||
      rpc_write(conn, &addr, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &flags, sizeof(unsigned long long)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, ptr, sizeof(CUdeviceptr)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)ptr, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&size, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&alignment, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&addr, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemAddressFree(CUdeviceptr ptr, size_t size) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&ptr, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&size, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemAddressFree) < 0 ||
      rpc_write(conn, &ptr, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &size, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ptr, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&size, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemCreate(CUmemGenericAllocationHandle *handle, size_t size,
                     const CUmemAllocationProp *prop,
                     unsigned long long flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)handle, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&size, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)prop, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemCreate) < 0 ||
      rpc_write(conn, handle, sizeof(CUmemGenericAllocationHandle)) < 0 ||
      rpc_write(conn, &size, sizeof(size_t)) < 0 ||
      rpc_write(conn, &prop, sizeof(const CUmemAllocationProp *)) < 0 ||
      rpc_write(conn, &flags, sizeof(unsigned long long)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, handle, sizeof(CUmemGenericAllocationHandle)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)handle, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&size, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)prop, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemRelease(CUmemGenericAllocationHandle handle) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemRelease) < 0 ||
      rpc_write(conn, &handle, sizeof(CUmemGenericAllocationHandle)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemMap(CUdeviceptr ptr, size_t size, size_t offset,
                  CUmemGenericAllocationHandle handle,
                  unsigned long long flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&ptr, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&size, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&offset, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemMap) < 0 ||
      rpc_write(conn, &ptr, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &size, sizeof(size_t)) < 0 ||
      rpc_write(conn, &offset, sizeof(size_t)) < 0 ||
      rpc_write(conn, &handle, sizeof(CUmemGenericAllocationHandle)) < 0 ||
      rpc_write(conn, &flags, sizeof(unsigned long long)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ptr, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&size, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&offset, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemMapArrayAsync(CUarrayMapInfo *mapInfoList, unsigned int count,
                            CUstream hStream) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)mapInfoList,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemMapArrayAsync) < 0 ||
      rpc_write(conn, mapInfoList, sizeof(CUarrayMapInfo)) < 0 ||
      rpc_write(conn, &count, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &hStream, sizeof(CUstream)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, mapInfoList, sizeof(CUarrayMapInfo)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)mapInfoList,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemUnmap(CUdeviceptr ptr, size_t size) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&ptr, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&size, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemUnmap) < 0 ||
      rpc_write(conn, &ptr, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &size, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ptr, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&size, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemSetAccess(CUdeviceptr ptr, size_t size,
                        const CUmemAccessDesc *desc, size_t count) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&ptr, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&size, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)desc, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemSetAccess) < 0 ||
      rpc_write(conn, &ptr, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &size, sizeof(size_t)) < 0 ||
      rpc_write(conn, &desc, sizeof(const CUmemAccessDesc *)) < 0 ||
      rpc_write(conn, &count, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ptr, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&size, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)desc, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemGetAccess(unsigned long long *flags,
                        const CUmemLocation *location, CUdeviceptr ptr) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)flags, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)location, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ptr, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemGetAccess) < 0 ||
      rpc_write(conn, flags, sizeof(unsigned long long)) < 0 ||
      rpc_write(conn, &location, sizeof(const CUmemLocation *)) < 0 ||
      rpc_write(conn, &ptr, sizeof(CUdeviceptr)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, flags, sizeof(unsigned long long)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)flags, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)location, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ptr, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult
cuMemGetAllocationGranularity(size_t *granularity,
                              const CUmemAllocationProp *prop,
                              CUmemAllocationGranularity_flags option) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)granularity,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)prop, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&option, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemGetAllocationGranularity) < 0 ||
      rpc_write(conn, granularity, sizeof(size_t)) < 0 ||
      rpc_write(conn, &prop, sizeof(const CUmemAllocationProp *)) < 0 ||
      rpc_write(conn, &option, sizeof(CUmemAllocationGranularity_flags)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, granularity, sizeof(size_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)granularity,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)prop, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&option, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult
cuMemGetAllocationPropertiesFromHandle(CUmemAllocationProp *prop,
                                       CUmemGenericAllocationHandle handle) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)prop, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn,
                              RPC_cuMemGetAllocationPropertiesFromHandle) < 0 ||
      rpc_write(conn, prop, sizeof(CUmemAllocationProp)) < 0 ||
      rpc_write(conn, &handle, sizeof(CUmemGenericAllocationHandle)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, prop, sizeof(CUmemAllocationProp)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)prop, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemFreeAsync(CUdeviceptr dptr, CUstream hStream) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&dptr, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemFreeAsync) < 0 ||
      rpc_write(conn, &dptr, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &hStream, sizeof(CUstream)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dptr, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemAllocAsync(CUdeviceptr *dptr, size_t bytesize, CUstream hStream) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)dptr, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&bytesize, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemAllocAsync) < 0 ||
      rpc_write(conn, dptr, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &bytesize, sizeof(size_t)) < 0 ||
      rpc_write(conn, &hStream, sizeof(CUstream)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, dptr, sizeof(CUdeviceptr)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)dptr, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&bytesize, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemPoolTrimTo(CUmemoryPool pool, size_t minBytesToKeep) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&pool, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&minBytesToKeep,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemPoolTrimTo) < 0 ||
      rpc_write(conn, &pool, sizeof(CUmemoryPool)) < 0 ||
      rpc_write(conn, &minBytesToKeep, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&pool, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&minBytesToKeep,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemPoolSetAccess(CUmemoryPool pool, const CUmemAccessDesc *map,
                            size_t count) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&pool, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)map, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemPoolSetAccess) < 0 ||
      rpc_write(conn, &pool, sizeof(CUmemoryPool)) < 0 ||
      rpc_write(conn, &map, sizeof(const CUmemAccessDesc *)) < 0 ||
      rpc_write(conn, &count, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&pool, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)map, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemPoolGetAccess(CUmemAccess_flags *flags, CUmemoryPool memPool,
                            CUmemLocation *location) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)flags, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&memPool, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)location, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemPoolGetAccess) < 0 ||
      rpc_write(conn, flags, sizeof(CUmemAccess_flags)) < 0 ||
      rpc_write(conn, &memPool, sizeof(CUmemoryPool)) < 0 ||
      rpc_write(conn, location, sizeof(CUmemLocation)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, flags, sizeof(CUmemAccess_flags)) < 0 ||
      rpc_read(conn, location, sizeof(CUmemLocation)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)flags, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&memPool, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)location, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemPoolCreate(CUmemoryPool *pool, const CUmemPoolProps *poolProps) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pool, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)poolProps, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemPoolCreate) < 0 ||
      rpc_write(conn, pool, sizeof(CUmemoryPool)) < 0 ||
      rpc_write(conn, &poolProps, sizeof(const CUmemPoolProps *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pool, sizeof(CUmemoryPool)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pool, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)poolProps, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemPoolDestroy(CUmemoryPool pool) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&pool, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemPoolDestroy) < 0 ||
      rpc_write(conn, &pool, sizeof(CUmemoryPool)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&pool, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemAllocFromPoolAsync(CUdeviceptr *dptr, size_t bytesize,
                                 CUmemoryPool pool, CUstream hStream) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)dptr, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&bytesize, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&pool, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemAllocFromPoolAsync) < 0 ||
      rpc_write(conn, dptr, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &bytesize, sizeof(size_t)) < 0 ||
      rpc_write(conn, &pool, sizeof(CUmemoryPool)) < 0 ||
      rpc_write(conn, &hStream, sizeof(CUstream)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, dptr, sizeof(CUdeviceptr)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)dptr, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&bytesize, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&pool, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemPoolExportPointer(CUmemPoolPtrExportData *shareData_out,
                                CUdeviceptr ptr) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)shareData_out,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ptr, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemPoolExportPointer) < 0 ||
      rpc_write(conn, shareData_out, sizeof(CUmemPoolPtrExportData)) < 0 ||
      rpc_write(conn, &ptr, sizeof(CUdeviceptr)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, shareData_out, sizeof(CUmemPoolPtrExportData)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)shareData_out,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ptr, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemPoolImportPointer(CUdeviceptr *ptr_out, CUmemoryPool pool,
                                CUmemPoolPtrExportData *shareData) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)ptr_out, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&pool, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)shareData, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemPoolImportPointer) < 0 ||
      rpc_write(conn, ptr_out, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &pool, sizeof(CUmemoryPool)) < 0 ||
      rpc_write(conn, shareData, sizeof(CUmemPoolPtrExportData)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, ptr_out, sizeof(CUdeviceptr)) < 0 ||
      rpc_read(conn, shareData, sizeof(CUmemPoolPtrExportData)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)ptr_out, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&pool, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)shareData, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemPrefetchAsync(CUdeviceptr devPtr, size_t count,
                            CUdevice dstDevice, CUstream hStream) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&devPtr, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dstDevice, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemPrefetchAsync) < 0 ||
      rpc_write(conn, &devPtr, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &count, sizeof(size_t)) < 0 ||
      rpc_write(conn, &dstDevice, sizeof(CUdevice)) < 0 ||
      rpc_write(conn, &hStream, sizeof(CUstream)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&devPtr, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dstDevice, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemAdvise(CUdeviceptr devPtr, size_t count, CUmem_advise advice,
                     CUdevice device) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&devPtr, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&advice, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemAdvise) < 0 ||
      rpc_write(conn, &devPtr, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &count, sizeof(size_t)) < 0 ||
      rpc_write(conn, &advice, sizeof(CUmem_advise)) < 0 ||
      rpc_write(conn, &device, sizeof(CUdevice)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&devPtr, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&advice, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuMemRangeGetAttributes(void **data, size_t *dataSizes,
                                 CUmem_range_attribute *attributes,
                                 size_t numAttributes, CUdeviceptr devPtr,
                                 size_t count) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)data, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)dataSizes, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)attributes, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numAttributes,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&devPtr, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuMemRangeGetAttributes) < 0 ||
      rpc_write(conn, data, sizeof(void *)) < 0 ||
      rpc_write(conn, dataSizes, sizeof(size_t)) < 0 ||
      rpc_write(conn, attributes, sizeof(CUmem_range_attribute)) < 0 ||
      rpc_write(conn, &numAttributes, sizeof(size_t)) < 0 ||
      rpc_write(conn, &devPtr, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &count, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, data, sizeof(void *)) < 0 ||
      rpc_read(conn, dataSizes, sizeof(size_t)) < 0 ||
      rpc_read(conn, attributes, sizeof(CUmem_range_attribute)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)data, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)dataSizes, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)attributes, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numAttributes,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&devPtr, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuPointerSetAttribute(const void *value, CUpointer_attribute attribute,
                               CUdeviceptr ptr) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)value, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&attribute, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ptr, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuPointerSetAttribute) < 0 ||
      rpc_write(conn, &value, sizeof(const void *)) < 0 ||
      rpc_write(conn, &attribute, sizeof(CUpointer_attribute)) < 0 ||
      rpc_write(conn, &ptr, sizeof(CUdeviceptr)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)value, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&attribute, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ptr, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuPointerGetAttributes(unsigned int numAttributes,
                                CUpointer_attribute *attributes, void **data,
                                CUdeviceptr ptr) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&numAttributes,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)attributes, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)data, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ptr, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuPointerGetAttributes) < 0 ||
      rpc_write(conn, &numAttributes, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, attributes, sizeof(CUpointer_attribute)) < 0 ||
      rpc_write(conn, data, sizeof(void *)) < 0 ||
      rpc_write(conn, &ptr, sizeof(CUdeviceptr)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, attributes, sizeof(CUpointer_attribute)) < 0 ||
      rpc_read(conn, data, sizeof(void *)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numAttributes,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)attributes, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)data, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ptr, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuStreamCreate(CUstream *phStream, unsigned int Flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)phStream, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Flags, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuStreamCreate) < 0 ||
      rpc_write(conn, phStream, sizeof(CUstream)) < 0 ||
      rpc_write(conn, &Flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, phStream, sizeof(CUstream)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)phStream, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Flags, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuStreamCreateWithPriority(CUstream *phStream, unsigned int flags,
                                    int priority) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)phStream, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&priority, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuStreamCreateWithPriority) < 0 ||
      rpc_write(conn, phStream, sizeof(CUstream)) < 0 ||
      rpc_write(conn, &flags, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &priority, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, phStream, sizeof(CUstream)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)phStream, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&priority, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuStreamGetPriority(CUstream hStream, int *priority) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)priority, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuStreamGetPriority) < 0 ||
      rpc_write(conn, &hStream, sizeof(CUstream)) < 0 ||
      rpc_write(conn, priority, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, priority, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)priority, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuStreamGetFlags(CUstream hStream, unsigned int *flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)flags, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuStreamGetFlags) < 0 ||
      rpc_write(conn, &hStream, sizeof(CUstream)) < 0 ||
      rpc_write(conn, flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, flags, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)flags, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuStreamGetId(CUstream hStream, unsigned long long *streamId) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)streamId, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuStreamGetId) < 0 ||
      rpc_write(conn, &hStream, sizeof(CUstream)) < 0 ||
      rpc_write(conn, streamId, sizeof(unsigned long long)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, streamId, sizeof(unsigned long long)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)streamId, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuStreamGetCtx(CUstream hStream, CUcontext *pctx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pctx, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuStreamGetCtx) < 0 ||
      rpc_write(conn, &hStream, sizeof(CUstream)) < 0 ||
      rpc_write(conn, pctx, sizeof(CUcontext)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pctx, sizeof(CUcontext)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pctx, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuStreamWaitEvent(CUstream hStream, CUevent hEvent,
                           unsigned int Flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hEvent, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Flags, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuStreamWaitEvent) < 0 ||
      rpc_write(conn, &hStream, sizeof(CUstream)) < 0 ||
      rpc_write(conn, &hEvent, sizeof(CUevent)) < 0 ||
      rpc_write(conn, &Flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hEvent, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Flags, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuStreamBeginCapture_v2(CUstream hStream, CUstreamCaptureMode mode) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuStreamBeginCapture_v2) < 0 ||
      rpc_write(conn, &hStream, sizeof(CUstream)) < 0 ||
      rpc_write(conn, &mode, sizeof(CUstreamCaptureMode)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuThreadExchangeStreamCaptureMode(CUstreamCaptureMode *mode) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)mode, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuThreadExchangeStreamCaptureMode) <
          0 ||
      rpc_write(conn, mode, sizeof(CUstreamCaptureMode)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, mode, sizeof(CUstreamCaptureMode)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)mode, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuStreamEndCapture(CUstream hStream, CUgraph *phGraph) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)phGraph, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuStreamEndCapture) < 0 ||
      rpc_write(conn, &hStream, sizeof(CUstream)) < 0 ||
      rpc_write(conn, phGraph, sizeof(CUgraph)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, phGraph, sizeof(CUgraph)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)phGraph, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuStreamIsCapturing(CUstream hStream,
                             CUstreamCaptureStatus *captureStatus) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)captureStatus,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuStreamIsCapturing) < 0 ||
      rpc_write(conn, &hStream, sizeof(CUstream)) < 0 ||
      rpc_write(conn, captureStatus, sizeof(CUstreamCaptureStatus)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, captureStatus, sizeof(CUstreamCaptureStatus)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)captureStatus,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuStreamUpdateCaptureDependencies(CUstream hStream,
                                           CUgraphNode *dependencies,
                                           size_t numDependencies,
                                           unsigned int flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)dependencies,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuStreamUpdateCaptureDependencies) <
          0 ||
      rpc_write(conn, &hStream, sizeof(CUstream)) < 0 ||
      rpc_write(conn, dependencies, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, &numDependencies, sizeof(size_t)) < 0 ||
      rpc_write(conn, &flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, dependencies, sizeof(CUgraphNode)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)dependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuStreamAttachMemAsync(CUstream hStream, CUdeviceptr dptr,
                                size_t length, unsigned int flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dptr, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&length, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuStreamAttachMemAsync) < 0 ||
      rpc_write(conn, &hStream, sizeof(CUstream)) < 0 ||
      rpc_write(conn, &dptr, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &length, sizeof(size_t)) < 0 ||
      rpc_write(conn, &flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dptr, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&length, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuStreamQuery(CUstream hStream) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuStreamQuery) < 0 ||
      rpc_write(conn, &hStream, sizeof(CUstream)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuStreamSynchronize(CUstream hStream) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuStreamSynchronize) < 0 ||
      rpc_write(conn, &hStream, sizeof(CUstream)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuStreamDestroy_v2(CUstream hStream) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuStreamDestroy_v2) < 0 ||
      rpc_write(conn, &hStream, sizeof(CUstream)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuStreamCopyAttributes(CUstream dst, CUstream src) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&dst, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&src, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuStreamCopyAttributes) < 0 ||
      rpc_write(conn, &dst, sizeof(CUstream)) < 0 ||
      rpc_write(conn, &src, sizeof(CUstream)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dst, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&src, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuStreamGetAttribute(CUstream hStream, CUstreamAttrID attr,
                              CUstreamAttrValue *value_out) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&attr, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)value_out, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuStreamGetAttribute) < 0 ||
      rpc_write(conn, &hStream, sizeof(CUstream)) < 0 ||
      rpc_write(conn, &attr, sizeof(CUstreamAttrID)) < 0 ||
      rpc_write(conn, value_out, sizeof(CUstreamAttrValue)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, value_out, sizeof(CUstreamAttrValue)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&attr, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)value_out, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuStreamSetAttribute(CUstream hStream, CUstreamAttrID attr,
                              const CUstreamAttrValue *value) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&attr, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)value, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuStreamSetAttribute) < 0 ||
      rpc_write(conn, &hStream, sizeof(CUstream)) < 0 ||
      rpc_write(conn, &attr, sizeof(CUstreamAttrID)) < 0 ||
      rpc_write(conn, &value, sizeof(const CUstreamAttrValue *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&attr, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)value, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuEventCreate(CUevent *phEvent, unsigned int Flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)phEvent, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Flags, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuEventCreate) < 0 ||
      rpc_write(conn, phEvent, sizeof(CUevent)) < 0 ||
      rpc_write(conn, &Flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, phEvent, sizeof(CUevent)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)phEvent, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Flags, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuEventRecord(CUevent hEvent, CUstream hStream) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hEvent, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuEventRecord) < 0 ||
      rpc_write(conn, &hEvent, sizeof(CUevent)) < 0 ||
      rpc_write(conn, &hStream, sizeof(CUstream)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hEvent, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuEventRecordWithFlags(CUevent hEvent, CUstream hStream,
                                unsigned int flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hEvent, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuEventRecordWithFlags) < 0 ||
      rpc_write(conn, &hEvent, sizeof(CUevent)) < 0 ||
      rpc_write(conn, &hStream, sizeof(CUstream)) < 0 ||
      rpc_write(conn, &flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hEvent, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuEventQuery(CUevent hEvent) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hEvent, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuEventQuery) < 0 ||
      rpc_write(conn, &hEvent, sizeof(CUevent)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hEvent, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuEventSynchronize(CUevent hEvent) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hEvent, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuEventSynchronize) < 0 ||
      rpc_write(conn, &hEvent, sizeof(CUevent)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hEvent, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuEventDestroy_v2(CUevent hEvent) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hEvent, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuEventDestroy_v2) < 0 ||
      rpc_write(conn, &hEvent, sizeof(CUevent)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hEvent, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuEventElapsedTime(float *pMilliseconds, CUevent hStart,
                            CUevent hEnd) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pMilliseconds,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStart, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hEnd, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuEventElapsedTime) < 0 ||
      rpc_write(conn, pMilliseconds, sizeof(float)) < 0 ||
      rpc_write(conn, &hStart, sizeof(CUevent)) < 0 ||
      rpc_write(conn, &hEnd, sizeof(CUevent)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pMilliseconds, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pMilliseconds,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStart, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hEnd, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult
cuImportExternalMemory(CUexternalMemory *extMem_out,
                       const CUDA_EXTERNAL_MEMORY_HANDLE_DESC *memHandleDesc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)extMem_out, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)memHandleDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuImportExternalMemory) < 0 ||
      rpc_write(conn, extMem_out, sizeof(CUexternalMemory)) < 0 ||
      rpc_write(conn, &memHandleDesc,
                sizeof(const CUDA_EXTERNAL_MEMORY_HANDLE_DESC *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, extMem_out, sizeof(CUexternalMemory)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)extMem_out, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)memHandleDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuExternalMemoryGetMappedBuffer(
    CUdeviceptr *devPtr, CUexternalMemory extMem,
    const CUDA_EXTERNAL_MEMORY_BUFFER_DESC *bufferDesc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)devPtr, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&extMem, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)bufferDesc, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuExternalMemoryGetMappedBuffer) < 0 ||
      rpc_write(conn, devPtr, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &extMem, sizeof(CUexternalMemory)) < 0 ||
      rpc_write(conn, &bufferDesc,
                sizeof(const CUDA_EXTERNAL_MEMORY_BUFFER_DESC *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, devPtr, sizeof(CUdeviceptr)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)devPtr, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&extMem, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)bufferDesc, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuExternalMemoryGetMappedMipmappedArray(
    CUmipmappedArray *mipmap, CUexternalMemory extMem,
    const CUDA_EXTERNAL_MEMORY_MIPMAPPED_ARRAY_DESC *mipmapDesc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)mipmap, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&extMem, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)mipmapDesc, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(
          conn, RPC_cuExternalMemoryGetMappedMipmappedArray) < 0 ||
      rpc_write(conn, mipmap, sizeof(CUmipmappedArray)) < 0 ||
      rpc_write(conn, &extMem, sizeof(CUexternalMemory)) < 0 ||
      rpc_write(conn, &mipmapDesc,
                sizeof(const CUDA_EXTERNAL_MEMORY_MIPMAPPED_ARRAY_DESC *)) <
          0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, mipmap, sizeof(CUmipmappedArray)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)mipmap, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&extMem, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)mipmapDesc, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuDestroyExternalMemory(CUexternalMemory extMem) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&extMem, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuDestroyExternalMemory) < 0 ||
      rpc_write(conn, &extMem, sizeof(CUexternalMemory)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&extMem, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuImportExternalSemaphore(
    CUexternalSemaphore *extSem_out,
    const CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC *semHandleDesc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)extSem_out, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)semHandleDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuImportExternalSemaphore) < 0 ||
      rpc_write(conn, extSem_out, sizeof(CUexternalSemaphore)) < 0 ||
      rpc_write(conn, &semHandleDesc,
                sizeof(const CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, extSem_out, sizeof(CUexternalSemaphore)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)extSem_out, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)semHandleDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuSignalExternalSemaphoresAsync(
    const CUexternalSemaphore *extSemArray,
    const CUDA_EXTERNAL_SEMAPHORE_SIGNAL_PARAMS *paramsArray,
    unsigned int numExtSems, CUstream stream) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)extSemArray,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)paramsArray,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numExtSems,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuSignalExternalSemaphoresAsync) < 0 ||
      rpc_write(conn, &extSemArray, sizeof(const CUexternalSemaphore *)) < 0 ||
      rpc_write(conn, &paramsArray,
                sizeof(const CUDA_EXTERNAL_SEMAPHORE_SIGNAL_PARAMS *)) < 0 ||
      rpc_write(conn, &numExtSems, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &stream, sizeof(CUstream)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)extSemArray,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)paramsArray,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numExtSems,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuWaitExternalSemaphoresAsync(
    const CUexternalSemaphore *extSemArray,
    const CUDA_EXTERNAL_SEMAPHORE_WAIT_PARAMS *paramsArray,
    unsigned int numExtSems, CUstream stream) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)extSemArray,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)paramsArray,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numExtSems,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuWaitExternalSemaphoresAsync) < 0 ||
      rpc_write(conn, &extSemArray, sizeof(const CUexternalSemaphore *)) < 0 ||
      rpc_write(conn, &paramsArray,
                sizeof(const CUDA_EXTERNAL_SEMAPHORE_WAIT_PARAMS *)) < 0 ||
      rpc_write(conn, &numExtSems, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &stream, sizeof(CUstream)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)extSemArray,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)paramsArray,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numExtSems,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuDestroyExternalSemaphore(CUexternalSemaphore extSem) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&extSem, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuDestroyExternalSemaphore) < 0 ||
      rpc_write(conn, &extSem, sizeof(CUexternalSemaphore)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&extSem, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuStreamWaitValue32_v2(CUstream stream, CUdeviceptr addr,
                                cuuint32_t value, unsigned int flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&addr, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&value, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuStreamWaitValue32_v2) < 0 ||
      rpc_write(conn, &stream, sizeof(CUstream)) < 0 ||
      rpc_write(conn, &addr, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &value, sizeof(cuuint32_t)) < 0 ||
      rpc_write(conn, &flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&addr, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&value, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuStreamWaitValue64_v2(CUstream stream, CUdeviceptr addr,
                                cuuint64_t value, unsigned int flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&addr, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&value, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuStreamWaitValue64_v2) < 0 ||
      rpc_write(conn, &stream, sizeof(CUstream)) < 0 ||
      rpc_write(conn, &addr, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &value, sizeof(cuuint64_t)) < 0 ||
      rpc_write(conn, &flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&addr, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&value, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuStreamWriteValue32_v2(CUstream stream, CUdeviceptr addr,
                                 cuuint32_t value, unsigned int flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&addr, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&value, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuStreamWriteValue32_v2) < 0 ||
      rpc_write(conn, &stream, sizeof(CUstream)) < 0 ||
      rpc_write(conn, &addr, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &value, sizeof(cuuint32_t)) < 0 ||
      rpc_write(conn, &flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&addr, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&value, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuStreamWriteValue64_v2(CUstream stream, CUdeviceptr addr,
                                 cuuint64_t value, unsigned int flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&addr, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&value, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuStreamWriteValue64_v2) < 0 ||
      rpc_write(conn, &stream, sizeof(CUstream)) < 0 ||
      rpc_write(conn, &addr, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &value, sizeof(cuuint64_t)) < 0 ||
      rpc_write(conn, &flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&addr, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&value, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuStreamBatchMemOp_v2(CUstream stream, unsigned int count,
                               CUstreamBatchMemOpParams *paramArray,
                               unsigned int flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)paramArray, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuStreamBatchMemOp_v2) < 0 ||
      rpc_write(conn, &stream, sizeof(CUstream)) < 0 ||
      rpc_write(conn, &count, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, paramArray, sizeof(CUstreamBatchMemOpParams)) < 0 ||
      rpc_write(conn, &flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, paramArray, sizeof(CUstreamBatchMemOpParams)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)paramArray, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuFuncGetAttribute(int *pi, CUfunction_attribute attrib,
                            CUfunction hfunc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pi, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&attrib, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hfunc, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuFuncGetAttribute) < 0 ||
      rpc_write(conn, pi, sizeof(int)) < 0 ||
      rpc_write(conn, &attrib, sizeof(CUfunction_attribute)) < 0 ||
      rpc_write(conn, &hfunc, sizeof(CUfunction)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, pi, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pi, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&attrib, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hfunc, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuFuncSetAttribute(CUfunction hfunc, CUfunction_attribute attrib,
                            int value) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hfunc, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&attrib, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&value, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuFuncSetAttribute) < 0 ||
      rpc_write(conn, &hfunc, sizeof(CUfunction)) < 0 ||
      rpc_write(conn, &attrib, sizeof(CUfunction_attribute)) < 0 ||
      rpc_write(conn, &value, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hfunc, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&attrib, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&value, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuFuncSetCacheConfig(CUfunction hfunc, CUfunc_cache config) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hfunc, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&config, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuFuncSetCacheConfig) < 0 ||
      rpc_write(conn, &hfunc, sizeof(CUfunction)) < 0 ||
      rpc_write(conn, &config, sizeof(CUfunc_cache)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hfunc, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&config, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuFuncSetSharedMemConfig(CUfunction hfunc, CUsharedconfig config) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hfunc, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&config, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuFuncSetSharedMemConfig) < 0 ||
      rpc_write(conn, &hfunc, sizeof(CUfunction)) < 0 ||
      rpc_write(conn, &config, sizeof(CUsharedconfig)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hfunc, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&config, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuFuncGetModule(CUmodule *hmod, CUfunction hfunc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)hmod, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hfunc, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuFuncGetModule) < 0 ||
      rpc_write(conn, hmod, sizeof(CUmodule)) < 0 ||
      rpc_write(conn, &hfunc, sizeof(CUfunction)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, hmod, sizeof(CUmodule)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)hmod, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hfunc, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuLaunchKernel(CUfunction f, unsigned int gridDimX,
                        unsigned int gridDimY, unsigned int gridDimZ,
                        unsigned int blockDimX, unsigned int blockDimY,
                        unsigned int blockDimZ, unsigned int sharedMemBytes,
                        CUstream hStream, void **kernelParams, void **extra) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&f, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&gridDimX, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&gridDimY, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&gridDimZ, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&blockDimX, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&blockDimY, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&blockDimZ, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&sharedMemBytes,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)kernelParams,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)extra, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuLaunchKernel) < 0 ||
      rpc_write(conn, &f, sizeof(CUfunction)) < 0 ||
      rpc_write(conn, &gridDimX, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &gridDimY, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &gridDimZ, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &blockDimX, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &blockDimY, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &blockDimZ, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &sharedMemBytes, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &hStream, sizeof(CUstream)) < 0 ||
      rpc_write(conn, &kernelParams, sizeof(void **)) < 0 ||
      rpc_write(conn, &extra, sizeof(void **)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&f, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&gridDimX, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&gridDimY, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&gridDimZ, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&blockDimX, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&blockDimY, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&blockDimZ, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&sharedMemBytes,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)kernelParams,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)extra, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuLaunchCooperativeKernel(CUfunction f, unsigned int gridDimX,
                                   unsigned int gridDimY, unsigned int gridDimZ,
                                   unsigned int blockDimX,
                                   unsigned int blockDimY,
                                   unsigned int blockDimZ,
                                   unsigned int sharedMemBytes,
                                   CUstream hStream, void **kernelParams) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&f, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&gridDimX, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&gridDimY, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&gridDimZ, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&blockDimX, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&blockDimY, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&blockDimZ, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&sharedMemBytes,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)kernelParams,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuLaunchCooperativeKernel) < 0 ||
      rpc_write(conn, &f, sizeof(CUfunction)) < 0 ||
      rpc_write(conn, &gridDimX, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &gridDimY, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &gridDimZ, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &blockDimX, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &blockDimY, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &blockDimZ, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &sharedMemBytes, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &hStream, sizeof(CUstream)) < 0 ||
      rpc_write(conn, kernelParams, sizeof(void *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, kernelParams, sizeof(void *)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&f, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&gridDimX, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&gridDimY, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&gridDimZ, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&blockDimX, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&blockDimY, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&blockDimZ, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&sharedMemBytes,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)kernelParams,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult
cuLaunchCooperativeKernelMultiDevice(CUDA_LAUNCH_PARAMS *launchParamsList,
                                     unsigned int numDevices,
                                     unsigned int flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)launchParamsList,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numDevices,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuLaunchCooperativeKernelMultiDevice) <
          0 ||
      rpc_write(conn, launchParamsList, sizeof(CUDA_LAUNCH_PARAMS)) < 0 ||
      rpc_write(conn, &numDevices, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, launchParamsList, sizeof(CUDA_LAUNCH_PARAMS)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)launchParamsList,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numDevices,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuFuncSetBlockShape(CUfunction hfunc, int x, int y, int z) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hfunc, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&x, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&y, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&z, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuFuncSetBlockShape) < 0 ||
      rpc_write(conn, &hfunc, sizeof(CUfunction)) < 0 ||
      rpc_write(conn, &x, sizeof(int)) < 0 ||
      rpc_write(conn, &y, sizeof(int)) < 0 ||
      rpc_write(conn, &z, sizeof(int)) < 0 || rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hfunc, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&x, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&y, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&z, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuFuncSetSharedSize(CUfunction hfunc, unsigned int bytes) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hfunc, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&bytes, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuFuncSetSharedSize) < 0 ||
      rpc_write(conn, &hfunc, sizeof(CUfunction)) < 0 ||
      rpc_write(conn, &bytes, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hfunc, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&bytes, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuParamSetSize(CUfunction hfunc, unsigned int numbytes) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hfunc, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numbytes, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuParamSetSize) < 0 ||
      rpc_write(conn, &hfunc, sizeof(CUfunction)) < 0 ||
      rpc_write(conn, &numbytes, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hfunc, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numbytes, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuParamSeti(CUfunction hfunc, int offset, unsigned int value) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hfunc, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&offset, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&value, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuParamSeti) < 0 ||
      rpc_write(conn, &hfunc, sizeof(CUfunction)) < 0 ||
      rpc_write(conn, &offset, sizeof(int)) < 0 ||
      rpc_write(conn, &value, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hfunc, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&offset, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&value, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuParamSetf(CUfunction hfunc, int offset, float value) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hfunc, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&offset, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&value, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuParamSetf) < 0 ||
      rpc_write(conn, &hfunc, sizeof(CUfunction)) < 0 ||
      rpc_write(conn, &offset, sizeof(int)) < 0 ||
      rpc_write(conn, &value, sizeof(float)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hfunc, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&offset, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&value, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuLaunch(CUfunction f) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&f, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuLaunch) < 0 ||
      rpc_write(conn, &f, sizeof(CUfunction)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&f, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuLaunchGrid(CUfunction f, int grid_width, int grid_height) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&f, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&grid_width,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&grid_height,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuLaunchGrid) < 0 ||
      rpc_write(conn, &f, sizeof(CUfunction)) < 0 ||
      rpc_write(conn, &grid_width, sizeof(int)) < 0 ||
      rpc_write(conn, &grid_height, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&f, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&grid_width,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&grid_height,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuLaunchGridAsync(CUfunction f, int grid_width, int grid_height,
                           CUstream hStream) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&f, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&grid_width,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&grid_height,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuLaunchGridAsync) < 0 ||
      rpc_write(conn, &f, sizeof(CUfunction)) < 0 ||
      rpc_write(conn, &grid_width, sizeof(int)) < 0 ||
      rpc_write(conn, &grid_height, sizeof(int)) < 0 ||
      rpc_write(conn, &hStream, sizeof(CUstream)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&f, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&grid_width,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&grid_height,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuParamSetTexRef(CUfunction hfunc, int texunit, CUtexref hTexRef) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hfunc, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&texunit, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuParamSetTexRef) < 0 ||
      rpc_write(conn, &hfunc, sizeof(CUfunction)) < 0 ||
      rpc_write(conn, &texunit, sizeof(int)) < 0 ||
      rpc_write(conn, &hTexRef, sizeof(CUtexref)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hfunc, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&texunit, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphCreate(CUgraph *phGraph, unsigned int flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)phGraph, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphCreate) < 0 ||
      rpc_write(conn, phGraph, sizeof(CUgraph)) < 0 ||
      rpc_write(conn, &flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, phGraph, sizeof(CUgraph)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)phGraph, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphAddKernelNode_v2(CUgraphNode *phGraphNode, CUgraph hGraph,
                                 const CUgraphNode *dependencies,
                                 size_t numDependencies,
                                 const CUDA_KERNEL_NODE_PARAMS *nodeParams) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)phGraphNode,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraph, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)dependencies,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphAddKernelNode_v2) < 0 ||
      rpc_write(conn, phGraphNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, &hGraph, sizeof(CUgraph)) < 0 ||
      rpc_write(conn, &dependencies, sizeof(const CUgraphNode *)) < 0 ||
      rpc_write(conn, &numDependencies, sizeof(size_t)) < 0 ||
      rpc_write(conn, &nodeParams, sizeof(const CUDA_KERNEL_NODE_PARAMS *)) <
          0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, phGraphNode, sizeof(CUgraphNode)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)phGraphNode,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraph, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)dependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphKernelNodeGetParams_v2(CUgraphNode hNode,
                                       CUDA_KERNEL_NODE_PARAMS *nodeParams) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphKernelNodeGetParams_v2) < 0 ||
      rpc_write(conn, &hNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, nodeParams, sizeof(CUDA_KERNEL_NODE_PARAMS)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, nodeParams, sizeof(CUDA_KERNEL_NODE_PARAMS)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult
cuGraphKernelNodeSetParams_v2(CUgraphNode hNode,
                              const CUDA_KERNEL_NODE_PARAMS *nodeParams) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphKernelNodeSetParams_v2) < 0 ||
      rpc_write(conn, &hNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, &nodeParams, sizeof(const CUDA_KERNEL_NODE_PARAMS *)) <
          0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphAddMemcpyNode(CUgraphNode *phGraphNode, CUgraph hGraph,
                              const CUgraphNode *dependencies,
                              size_t numDependencies,
                              const CUDA_MEMCPY3D *copyParams, CUcontext ctx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)phGraphNode,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraph, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)dependencies,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)copyParams, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ctx, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphAddMemcpyNode) < 0 ||
      rpc_write(conn, phGraphNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, &hGraph, sizeof(CUgraph)) < 0 ||
      rpc_write(conn, &dependencies, sizeof(const CUgraphNode *)) < 0 ||
      rpc_write(conn, &numDependencies, sizeof(size_t)) < 0 ||
      rpc_write(conn, &copyParams, sizeof(const CUDA_MEMCPY3D *)) < 0 ||
      rpc_write(conn, &ctx, sizeof(CUcontext)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, phGraphNode, sizeof(CUgraphNode)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)phGraphNode,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraph, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)dependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)copyParams, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ctx, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphMemcpyNodeGetParams(CUgraphNode hNode,
                                    CUDA_MEMCPY3D *nodeParams) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphMemcpyNodeGetParams) < 0 ||
      rpc_write(conn, &hNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, nodeParams, sizeof(CUDA_MEMCPY3D)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, nodeParams, sizeof(CUDA_MEMCPY3D)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphMemcpyNodeSetParams(CUgraphNode hNode,
                                    const CUDA_MEMCPY3D *nodeParams) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphMemcpyNodeSetParams) < 0 ||
      rpc_write(conn, &hNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, &nodeParams, sizeof(const CUDA_MEMCPY3D *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphAddMemsetNode(CUgraphNode *phGraphNode, CUgraph hGraph,
                              const CUgraphNode *dependencies,
                              size_t numDependencies,
                              const CUDA_MEMSET_NODE_PARAMS *memsetParams,
                              CUcontext ctx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)phGraphNode,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraph, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)dependencies,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)memsetParams,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ctx, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphAddMemsetNode) < 0 ||
      rpc_write(conn, phGraphNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, &hGraph, sizeof(CUgraph)) < 0 ||
      rpc_write(conn, &dependencies, sizeof(const CUgraphNode *)) < 0 ||
      rpc_write(conn, &numDependencies, sizeof(size_t)) < 0 ||
      rpc_write(conn, &memsetParams, sizeof(const CUDA_MEMSET_NODE_PARAMS *)) <
          0 ||
      rpc_write(conn, &ctx, sizeof(CUcontext)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, phGraphNode, sizeof(CUgraphNode)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)phGraphNode,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraph, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)dependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)memsetParams,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ctx, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphMemsetNodeGetParams(CUgraphNode hNode,
                                    CUDA_MEMSET_NODE_PARAMS *nodeParams) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphMemsetNodeGetParams) < 0 ||
      rpc_write(conn, &hNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, nodeParams, sizeof(CUDA_MEMSET_NODE_PARAMS)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, nodeParams, sizeof(CUDA_MEMSET_NODE_PARAMS)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphMemsetNodeSetParams(CUgraphNode hNode,
                                    const CUDA_MEMSET_NODE_PARAMS *nodeParams) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphMemsetNodeSetParams) < 0 ||
      rpc_write(conn, &hNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, &nodeParams, sizeof(const CUDA_MEMSET_NODE_PARAMS *)) <
          0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphAddHostNode(CUgraphNode *phGraphNode, CUgraph hGraph,
                            const CUgraphNode *dependencies,
                            size_t numDependencies,
                            const CUDA_HOST_NODE_PARAMS *nodeParams) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)phGraphNode,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraph, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)dependencies,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphAddHostNode) < 0 ||
      rpc_write(conn, phGraphNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, &hGraph, sizeof(CUgraph)) < 0 ||
      rpc_write(conn, &dependencies, sizeof(const CUgraphNode *)) < 0 ||
      rpc_write(conn, &numDependencies, sizeof(size_t)) < 0 ||
      rpc_write(conn, &nodeParams, sizeof(const CUDA_HOST_NODE_PARAMS *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, phGraphNode, sizeof(CUgraphNode)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)phGraphNode,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraph, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)dependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphHostNodeGetParams(CUgraphNode hNode,
                                  CUDA_HOST_NODE_PARAMS *nodeParams) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphHostNodeGetParams) < 0 ||
      rpc_write(conn, &hNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, nodeParams, sizeof(CUDA_HOST_NODE_PARAMS)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, nodeParams, sizeof(CUDA_HOST_NODE_PARAMS)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphHostNodeSetParams(CUgraphNode hNode,
                                  const CUDA_HOST_NODE_PARAMS *nodeParams) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphHostNodeSetParams) < 0 ||
      rpc_write(conn, &hNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, &nodeParams, sizeof(const CUDA_HOST_NODE_PARAMS *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphAddChildGraphNode(CUgraphNode *phGraphNode, CUgraph hGraph,
                                  const CUgraphNode *dependencies,
                                  size_t numDependencies, CUgraph childGraph) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)phGraphNode,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraph, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)dependencies,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&childGraph,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphAddChildGraphNode) < 0 ||
      rpc_write(conn, phGraphNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, &hGraph, sizeof(CUgraph)) < 0 ||
      rpc_write(conn, &dependencies, sizeof(const CUgraphNode *)) < 0 ||
      rpc_write(conn, &numDependencies, sizeof(size_t)) < 0 ||
      rpc_write(conn, &childGraph, sizeof(CUgraph)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, phGraphNode, sizeof(CUgraphNode)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)phGraphNode,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraph, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)dependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&childGraph,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphChildGraphNodeGetGraph(CUgraphNode hNode, CUgraph *phGraph) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)phGraph, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphChildGraphNodeGetGraph) < 0 ||
      rpc_write(conn, &hNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, phGraph, sizeof(CUgraph)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, phGraph, sizeof(CUgraph)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)phGraph, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphAddEmptyNode(CUgraphNode *phGraphNode, CUgraph hGraph,
                             const CUgraphNode *dependencies,
                             size_t numDependencies) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)phGraphNode,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraph, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)dependencies,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphAddEmptyNode) < 0 ||
      rpc_write(conn, phGraphNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, &hGraph, sizeof(CUgraph)) < 0 ||
      rpc_write(conn, &dependencies, sizeof(const CUgraphNode *)) < 0 ||
      rpc_write(conn, &numDependencies, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, phGraphNode, sizeof(CUgraphNode)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)phGraphNode,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraph, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)dependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphAddEventRecordNode(CUgraphNode *phGraphNode, CUgraph hGraph,
                                   const CUgraphNode *dependencies,
                                   size_t numDependencies, CUevent event) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)phGraphNode,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraph, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)dependencies,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&event, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphAddEventRecordNode) < 0 ||
      rpc_write(conn, phGraphNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, &hGraph, sizeof(CUgraph)) < 0 ||
      rpc_write(conn, &dependencies, sizeof(const CUgraphNode *)) < 0 ||
      rpc_write(conn, &numDependencies, sizeof(size_t)) < 0 ||
      rpc_write(conn, &event, sizeof(CUevent)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, phGraphNode, sizeof(CUgraphNode)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)phGraphNode,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraph, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)dependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&event, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphEventRecordNodeGetEvent(CUgraphNode hNode, CUevent *event_out) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)event_out, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphEventRecordNodeGetEvent) < 0 ||
      rpc_write(conn, &hNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, event_out, sizeof(CUevent)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, event_out, sizeof(CUevent)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)event_out, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphEventRecordNodeSetEvent(CUgraphNode hNode, CUevent event) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&event, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphEventRecordNodeSetEvent) < 0 ||
      rpc_write(conn, &hNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, &event, sizeof(CUevent)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&event, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphAddEventWaitNode(CUgraphNode *phGraphNode, CUgraph hGraph,
                                 const CUgraphNode *dependencies,
                                 size_t numDependencies, CUevent event) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)phGraphNode,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraph, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)dependencies,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&event, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphAddEventWaitNode) < 0 ||
      rpc_write(conn, phGraphNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, &hGraph, sizeof(CUgraph)) < 0 ||
      rpc_write(conn, &dependencies, sizeof(const CUgraphNode *)) < 0 ||
      rpc_write(conn, &numDependencies, sizeof(size_t)) < 0 ||
      rpc_write(conn, &event, sizeof(CUevent)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, phGraphNode, sizeof(CUgraphNode)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)phGraphNode,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraph, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)dependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&event, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphEventWaitNodeGetEvent(CUgraphNode hNode, CUevent *event_out) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)event_out, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphEventWaitNodeGetEvent) < 0 ||
      rpc_write(conn, &hNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, event_out, sizeof(CUevent)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, event_out, sizeof(CUevent)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)event_out, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphEventWaitNodeSetEvent(CUgraphNode hNode, CUevent event) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&event, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphEventWaitNodeSetEvent) < 0 ||
      rpc_write(conn, &hNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, &event, sizeof(CUevent)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&event, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphAddExternalSemaphoresSignalNode(
    CUgraphNode *phGraphNode, CUgraph hGraph, const CUgraphNode *dependencies,
    size_t numDependencies, const CUDA_EXT_SEM_SIGNAL_NODE_PARAMS *nodeParams) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)phGraphNode,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraph, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)dependencies,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn,
                              RPC_cuGraphAddExternalSemaphoresSignalNode) < 0 ||
      rpc_write(conn, phGraphNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, &hGraph, sizeof(CUgraph)) < 0 ||
      rpc_write(conn, &dependencies, sizeof(const CUgraphNode *)) < 0 ||
      rpc_write(conn, &numDependencies, sizeof(size_t)) < 0 ||
      rpc_write(conn, &nodeParams,
                sizeof(const CUDA_EXT_SEM_SIGNAL_NODE_PARAMS *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, phGraphNode, sizeof(CUgraphNode)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)phGraphNode,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraph, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)dependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphExternalSemaphoresSignalNodeGetParams(
    CUgraphNode hNode, CUDA_EXT_SEM_SIGNAL_NODE_PARAMS *params_out) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)params_out, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(
          conn, RPC_cuGraphExternalSemaphoresSignalNodeGetParams) < 0 ||
      rpc_write(conn, &hNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, params_out, sizeof(CUDA_EXT_SEM_SIGNAL_NODE_PARAMS)) <
          0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, params_out, sizeof(CUDA_EXT_SEM_SIGNAL_NODE_PARAMS)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)params_out, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphExternalSemaphoresSignalNodeSetParams(
    CUgraphNode hNode, const CUDA_EXT_SEM_SIGNAL_NODE_PARAMS *nodeParams) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(
          conn, RPC_cuGraphExternalSemaphoresSignalNodeSetParams) < 0 ||
      rpc_write(conn, &hNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, &nodeParams,
                sizeof(const CUDA_EXT_SEM_SIGNAL_NODE_PARAMS *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphAddExternalSemaphoresWaitNode(
    CUgraphNode *phGraphNode, CUgraph hGraph, const CUgraphNode *dependencies,
    size_t numDependencies, const CUDA_EXT_SEM_WAIT_NODE_PARAMS *nodeParams) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)phGraphNode,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraph, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)dependencies,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphAddExternalSemaphoresWaitNode) <
          0 ||
      rpc_write(conn, phGraphNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, &hGraph, sizeof(CUgraph)) < 0 ||
      rpc_write(conn, &dependencies, sizeof(const CUgraphNode *)) < 0 ||
      rpc_write(conn, &numDependencies, sizeof(size_t)) < 0 ||
      rpc_write(conn, &nodeParams,
                sizeof(const CUDA_EXT_SEM_WAIT_NODE_PARAMS *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, phGraphNode, sizeof(CUgraphNode)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)phGraphNode,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraph, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)dependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphExternalSemaphoresWaitNodeGetParams(
    CUgraphNode hNode, CUDA_EXT_SEM_WAIT_NODE_PARAMS *params_out) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)params_out, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(
          conn, RPC_cuGraphExternalSemaphoresWaitNodeGetParams) < 0 ||
      rpc_write(conn, &hNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, params_out, sizeof(CUDA_EXT_SEM_WAIT_NODE_PARAMS)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, params_out, sizeof(CUDA_EXT_SEM_WAIT_NODE_PARAMS)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)params_out, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphExternalSemaphoresWaitNodeSetParams(
    CUgraphNode hNode, const CUDA_EXT_SEM_WAIT_NODE_PARAMS *nodeParams) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(
          conn, RPC_cuGraphExternalSemaphoresWaitNodeSetParams) < 0 ||
      rpc_write(conn, &hNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, &nodeParams,
                sizeof(const CUDA_EXT_SEM_WAIT_NODE_PARAMS *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphAddBatchMemOpNode(
    CUgraphNode *phGraphNode, CUgraph hGraph, const CUgraphNode *dependencies,
    size_t numDependencies, const CUDA_BATCH_MEM_OP_NODE_PARAMS *nodeParams) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)phGraphNode,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraph, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)dependencies,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphAddBatchMemOpNode) < 0 ||
      rpc_write(conn, phGraphNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, &hGraph, sizeof(CUgraph)) < 0 ||
      rpc_write(conn, &dependencies, sizeof(const CUgraphNode *)) < 0 ||
      rpc_write(conn, &numDependencies, sizeof(size_t)) < 0 ||
      rpc_write(conn, &nodeParams,
                sizeof(const CUDA_BATCH_MEM_OP_NODE_PARAMS *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, phGraphNode, sizeof(CUgraphNode)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)phGraphNode,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraph, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)dependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult
cuGraphBatchMemOpNodeGetParams(CUgraphNode hNode,
                               CUDA_BATCH_MEM_OP_NODE_PARAMS *nodeParams_out) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams_out,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphBatchMemOpNodeGetParams) < 0 ||
      rpc_write(conn, &hNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, nodeParams_out, sizeof(CUDA_BATCH_MEM_OP_NODE_PARAMS)) <
          0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, nodeParams_out, sizeof(CUDA_BATCH_MEM_OP_NODE_PARAMS)) <
          0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams_out,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphBatchMemOpNodeSetParams(
    CUgraphNode hNode, const CUDA_BATCH_MEM_OP_NODE_PARAMS *nodeParams) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphBatchMemOpNodeSetParams) < 0 ||
      rpc_write(conn, &hNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, &nodeParams,
                sizeof(const CUDA_BATCH_MEM_OP_NODE_PARAMS *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphExecBatchMemOpNodeSetParams(
    CUgraphExec hGraphExec, CUgraphNode hNode,
    const CUDA_BATCH_MEM_OP_NODE_PARAMS *nodeParams) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphExecBatchMemOpNodeSetParams) <
          0 ||
      rpc_write(conn, &hGraphExec, sizeof(CUgraphExec)) < 0 ||
      rpc_write(conn, &hNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, &nodeParams,
                sizeof(const CUDA_BATCH_MEM_OP_NODE_PARAMS *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphAddMemAllocNode(CUgraphNode *phGraphNode, CUgraph hGraph,
                                const CUgraphNode *dependencies,
                                size_t numDependencies,
                                CUDA_MEM_ALLOC_NODE_PARAMS *nodeParams) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)phGraphNode,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraph, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)dependencies,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphAddMemAllocNode) < 0 ||
      rpc_write(conn, phGraphNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, &hGraph, sizeof(CUgraph)) < 0 ||
      rpc_write(conn, &dependencies, sizeof(const CUgraphNode *)) < 0 ||
      rpc_write(conn, &numDependencies, sizeof(size_t)) < 0 ||
      rpc_write(conn, nodeParams, sizeof(CUDA_MEM_ALLOC_NODE_PARAMS)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, phGraphNode, sizeof(CUgraphNode)) < 0 ||
      rpc_read(conn, nodeParams, sizeof(CUDA_MEM_ALLOC_NODE_PARAMS)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)phGraphNode,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraph, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)dependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphMemAllocNodeGetParams(CUgraphNode hNode,
                                      CUDA_MEM_ALLOC_NODE_PARAMS *params_out) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)params_out, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphMemAllocNodeGetParams) < 0 ||
      rpc_write(conn, &hNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, params_out, sizeof(CUDA_MEM_ALLOC_NODE_PARAMS)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, params_out, sizeof(CUDA_MEM_ALLOC_NODE_PARAMS)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)params_out, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphAddMemFreeNode(CUgraphNode *phGraphNode, CUgraph hGraph,
                               const CUgraphNode *dependencies,
                               size_t numDependencies, CUdeviceptr dptr) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)phGraphNode,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraph, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)dependencies,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  for (int i = 0; i < static_cast<int>(numDependencies) &&
                  is_unified_pointer(conn, (void *)dependencies);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&dependencies[i],
                               cudaMemcpyHostToDevice) < 0)
      return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dptr, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphAddMemFreeNode) < 0 ||
      rpc_write(conn, phGraphNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, &hGraph, sizeof(CUgraph)) < 0 ||
      rpc_write(conn, &numDependencies, sizeof(size_t)) < 0 ||
      rpc_write(conn, dependencies,
                numDependencies * sizeof(const CUgraphNode)) < 0 ||
      rpc_write(conn, &dptr, sizeof(CUdeviceptr)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, phGraphNode, sizeof(CUgraphNode)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)phGraphNode,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraph, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)dependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  for (int i = 0; i < static_cast<int>(numDependencies) &&
                  is_unified_pointer(conn, (void *)dependencies);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&dependencies[i],
                               cudaMemcpyDeviceToHost) < 0)
      return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dptr, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphMemFreeNodeGetParams(CUgraphNode hNode, CUdeviceptr *dptr_out) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)dptr_out, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphMemFreeNodeGetParams) < 0 ||
      rpc_write(conn, &hNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, dptr_out, sizeof(CUdeviceptr)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, dptr_out, sizeof(CUdeviceptr)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)dptr_out, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuDeviceGraphMemTrim(CUdevice device) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuDeviceGraphMemTrim) < 0 ||
      rpc_write(conn, &device, sizeof(CUdevice)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphClone(CUgraph *phGraphClone, CUgraph originalGraph) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)phGraphClone,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&originalGraph,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphClone) < 0 ||
      rpc_write(conn, phGraphClone, sizeof(CUgraph)) < 0 ||
      rpc_write(conn, &originalGraph, sizeof(CUgraph)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, phGraphClone, sizeof(CUgraph)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)phGraphClone,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&originalGraph,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphNodeFindInClone(CUgraphNode *phNode, CUgraphNode hOriginalNode,
                                CUgraph hClonedGraph) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)phNode, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hOriginalNode,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hClonedGraph,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphNodeFindInClone) < 0 ||
      rpc_write(conn, phNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, &hOriginalNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, &hClonedGraph, sizeof(CUgraph)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, phNode, sizeof(CUgraphNode)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)phNode, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hOriginalNode,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hClonedGraph,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphNodeGetType(CUgraphNode hNode, CUgraphNodeType *type) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)type, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphNodeGetType) < 0 ||
      rpc_write(conn, &hNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, type, sizeof(CUgraphNodeType)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, type, sizeof(CUgraphNodeType)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)type, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphGetNodes(CUgraph hGraph, CUgraphNode *nodes, size_t *numNodes) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hGraph, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)nodes, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)numNodes, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphGetNodes) < 0 ||
      rpc_write(conn, &hGraph, sizeof(CUgraph)) < 0 ||
      rpc_write(conn, nodes, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, numNodes, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, nodes, sizeof(CUgraphNode)) < 0 ||
      rpc_read(conn, numNodes, sizeof(size_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraph, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)nodes, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)numNodes, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphGetRootNodes(CUgraph hGraph, CUgraphNode *rootNodes,
                             size_t *numRootNodes) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hGraph, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)rootNodes, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)numRootNodes,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphGetRootNodes) < 0 ||
      rpc_write(conn, &hGraph, sizeof(CUgraph)) < 0 ||
      rpc_write(conn, rootNodes, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, numRootNodes, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, rootNodes, sizeof(CUgraphNode)) < 0 ||
      rpc_read(conn, numRootNodes, sizeof(size_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraph, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)rootNodes, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)numRootNodes,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphGetEdges(CUgraph hGraph, CUgraphNode *from, CUgraphNode *to,
                         size_t *numEdges) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hGraph, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)from, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)to, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)numEdges, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphGetEdges) < 0 ||
      rpc_write(conn, &hGraph, sizeof(CUgraph)) < 0 ||
      rpc_write(conn, from, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, to, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, numEdges, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, from, sizeof(CUgraphNode)) < 0 ||
      rpc_read(conn, to, sizeof(CUgraphNode)) < 0 ||
      rpc_read(conn, numEdges, sizeof(size_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraph, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)from, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)to, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)numEdges, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphNodeGetDependencies(CUgraphNode hNode,
                                    CUgraphNode *dependencies,
                                    size_t *numDependencies) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)dependencies,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)numDependencies,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphNodeGetDependencies) < 0 ||
      rpc_write(conn, &hNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, dependencies, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, numDependencies, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, dependencies, sizeof(CUgraphNode)) < 0 ||
      rpc_read(conn, numDependencies, sizeof(size_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)dependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)numDependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphNodeGetDependentNodes(CUgraphNode hNode,
                                      CUgraphNode *dependentNodes,
                                      size_t *numDependentNodes) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)dependentNodes,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)numDependentNodes,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphNodeGetDependentNodes) < 0 ||
      rpc_write(conn, &hNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, dependentNodes, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, numDependentNodes, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, dependentNodes, sizeof(CUgraphNode)) < 0 ||
      rpc_read(conn, numDependentNodes, sizeof(size_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)dependentNodes,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)numDependentNodes,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphAddDependencies(CUgraph hGraph, const CUgraphNode *from,
                                const CUgraphNode *to, size_t numDependencies) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hGraph, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)from, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)to, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphAddDependencies) < 0 ||
      rpc_write(conn, &hGraph, sizeof(CUgraph)) < 0 ||
      rpc_write(conn, &from, sizeof(const CUgraphNode *)) < 0 ||
      rpc_write(conn, &to, sizeof(const CUgraphNode *)) < 0 ||
      rpc_write(conn, &numDependencies, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraph, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)from, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)to, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphRemoveDependencies(CUgraph hGraph, const CUgraphNode *from,
                                   const CUgraphNode *to,
                                   size_t numDependencies) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hGraph, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)from, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)to, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphRemoveDependencies) < 0 ||
      rpc_write(conn, &hGraph, sizeof(CUgraph)) < 0 ||
      rpc_write(conn, &from, sizeof(const CUgraphNode *)) < 0 ||
      rpc_write(conn, &to, sizeof(const CUgraphNode *)) < 0 ||
      rpc_write(conn, &numDependencies, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraph, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)from, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)to, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphDestroyNode(CUgraphNode hNode) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphDestroyNode) < 0 ||
      rpc_write(conn, &hNode, sizeof(CUgraphNode)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphInstantiateWithFlags(CUgraphExec *phGraphExec, CUgraph hGraph,
                                     unsigned long long flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)phGraphExec,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraph, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphInstantiateWithFlags) < 0 ||
      rpc_write(conn, phGraphExec, sizeof(CUgraphExec)) < 0 ||
      rpc_write(conn, &hGraph, sizeof(CUgraph)) < 0 ||
      rpc_write(conn, &flags, sizeof(unsigned long long)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, phGraphExec, sizeof(CUgraphExec)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)phGraphExec,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraph, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult
cuGraphInstantiateWithParams(CUgraphExec *phGraphExec, CUgraph hGraph,
                             CUDA_GRAPH_INSTANTIATE_PARAMS *instantiateParams) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)phGraphExec,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraph, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)instantiateParams,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphInstantiateWithParams) < 0 ||
      rpc_write(conn, phGraphExec, sizeof(CUgraphExec)) < 0 ||
      rpc_write(conn, &hGraph, sizeof(CUgraph)) < 0 ||
      rpc_write(conn, instantiateParams,
                sizeof(CUDA_GRAPH_INSTANTIATE_PARAMS)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, phGraphExec, sizeof(CUgraphExec)) < 0 ||
      rpc_read(conn, instantiateParams, sizeof(CUDA_GRAPH_INSTANTIATE_PARAMS)) <
          0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)phGraphExec,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraph, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)instantiateParams,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphExecGetFlags(CUgraphExec hGraphExec, cuuint64_t *flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)flags, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphExecGetFlags) < 0 ||
      rpc_write(conn, &hGraphExec, sizeof(CUgraphExec)) < 0 ||
      rpc_write(conn, flags, sizeof(cuuint64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, flags, sizeof(cuuint64_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)flags, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult
cuGraphExecKernelNodeSetParams_v2(CUgraphExec hGraphExec, CUgraphNode hNode,
                                  const CUDA_KERNEL_NODE_PARAMS *nodeParams) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphExecKernelNodeSetParams_v2) <
          0 ||
      rpc_write(conn, &hGraphExec, sizeof(CUgraphExec)) < 0 ||
      rpc_write(conn, &hNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, &nodeParams, sizeof(const CUDA_KERNEL_NODE_PARAMS *)) <
          0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphExecMemcpyNodeSetParams(CUgraphExec hGraphExec,
                                        CUgraphNode hNode,
                                        const CUDA_MEMCPY3D *copyParams,
                                        CUcontext ctx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)copyParams, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ctx, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphExecMemcpyNodeSetParams) < 0 ||
      rpc_write(conn, &hGraphExec, sizeof(CUgraphExec)) < 0 ||
      rpc_write(conn, &hNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, &copyParams, sizeof(const CUDA_MEMCPY3D *)) < 0 ||
      rpc_write(conn, &ctx, sizeof(CUcontext)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)copyParams, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ctx, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult
cuGraphExecMemsetNodeSetParams(CUgraphExec hGraphExec, CUgraphNode hNode,
                               const CUDA_MEMSET_NODE_PARAMS *memsetParams,
                               CUcontext ctx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)memsetParams,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ctx, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphExecMemsetNodeSetParams) < 0 ||
      rpc_write(conn, &hGraphExec, sizeof(CUgraphExec)) < 0 ||
      rpc_write(conn, &hNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, &memsetParams, sizeof(const CUDA_MEMSET_NODE_PARAMS *)) <
          0 ||
      rpc_write(conn, &ctx, sizeof(CUcontext)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)memsetParams,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&ctx, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphExecHostNodeSetParams(CUgraphExec hGraphExec, CUgraphNode hNode,
                                      const CUDA_HOST_NODE_PARAMS *nodeParams) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphExecHostNodeSetParams) < 0 ||
      rpc_write(conn, &hGraphExec, sizeof(CUgraphExec)) < 0 ||
      rpc_write(conn, &hNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, &nodeParams, sizeof(const CUDA_HOST_NODE_PARAMS *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphExecChildGraphNodeSetParams(CUgraphExec hGraphExec,
                                            CUgraphNode hNode,
                                            CUgraph childGraph) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&childGraph,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphExecChildGraphNodeSetParams) <
          0 ||
      rpc_write(conn, &hGraphExec, sizeof(CUgraphExec)) < 0 ||
      rpc_write(conn, &hNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, &childGraph, sizeof(CUgraph)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&childGraph,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphExecEventRecordNodeSetEvent(CUgraphExec hGraphExec,
                                            CUgraphNode hNode, CUevent event) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&event, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphExecEventRecordNodeSetEvent) <
          0 ||
      rpc_write(conn, &hGraphExec, sizeof(CUgraphExec)) < 0 ||
      rpc_write(conn, &hNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, &event, sizeof(CUevent)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&event, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphExecEventWaitNodeSetEvent(CUgraphExec hGraphExec,
                                          CUgraphNode hNode, CUevent event) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&event, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphExecEventWaitNodeSetEvent) < 0 ||
      rpc_write(conn, &hGraphExec, sizeof(CUgraphExec)) < 0 ||
      rpc_write(conn, &hNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, &event, sizeof(CUevent)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&event, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphExecExternalSemaphoresSignalNodeSetParams(
    CUgraphExec hGraphExec, CUgraphNode hNode,
    const CUDA_EXT_SEM_SIGNAL_NODE_PARAMS *nodeParams) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(
          conn, RPC_cuGraphExecExternalSemaphoresSignalNodeSetParams) < 0 ||
      rpc_write(conn, &hGraphExec, sizeof(CUgraphExec)) < 0 ||
      rpc_write(conn, &hNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, &nodeParams,
                sizeof(const CUDA_EXT_SEM_SIGNAL_NODE_PARAMS *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphExecExternalSemaphoresWaitNodeSetParams(
    CUgraphExec hGraphExec, CUgraphNode hNode,
    const CUDA_EXT_SEM_WAIT_NODE_PARAMS *nodeParams) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(
          conn, RPC_cuGraphExecExternalSemaphoresWaitNodeSetParams) < 0 ||
      rpc_write(conn, &hGraphExec, sizeof(CUgraphExec)) < 0 ||
      rpc_write(conn, &hNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, &nodeParams,
                sizeof(const CUDA_EXT_SEM_WAIT_NODE_PARAMS *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphNodeSetEnabled(CUgraphExec hGraphExec, CUgraphNode hNode,
                               unsigned int isEnabled) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&isEnabled, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphNodeSetEnabled) < 0 ||
      rpc_write(conn, &hGraphExec, sizeof(CUgraphExec)) < 0 ||
      rpc_write(conn, &hNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, &isEnabled, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&isEnabled, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphNodeGetEnabled(CUgraphExec hGraphExec, CUgraphNode hNode,
                               unsigned int *isEnabled) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)isEnabled, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphNodeGetEnabled) < 0 ||
      rpc_write(conn, &hGraphExec, sizeof(CUgraphExec)) < 0 ||
      rpc_write(conn, &hNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, isEnabled, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, isEnabled, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)isEnabled, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphUpload(CUgraphExec hGraphExec, CUstream hStream) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphUpload) < 0 ||
      rpc_write(conn, &hGraphExec, sizeof(CUgraphExec)) < 0 ||
      rpc_write(conn, &hStream, sizeof(CUstream)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphLaunch(CUgraphExec hGraphExec, CUstream hStream) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphLaunch) < 0 ||
      rpc_write(conn, &hGraphExec, sizeof(CUgraphExec)) < 0 ||
      rpc_write(conn, &hStream, sizeof(CUstream)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphExecDestroy(CUgraphExec hGraphExec) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphExecDestroy) < 0 ||
      rpc_write(conn, &hGraphExec, sizeof(CUgraphExec)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphDestroy(CUgraph hGraph) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hGraph, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphDestroy) < 0 ||
      rpc_write(conn, &hGraph, sizeof(CUgraph)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraph, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphExecUpdate_v2(CUgraphExec hGraphExec, CUgraph hGraph,
                              CUgraphExecUpdateResultInfo *resultInfo) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraph, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)resultInfo, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphExecUpdate_v2) < 0 ||
      rpc_write(conn, &hGraphExec, sizeof(CUgraphExec)) < 0 ||
      rpc_write(conn, &hGraph, sizeof(CUgraph)) < 0 ||
      rpc_write(conn, resultInfo, sizeof(CUgraphExecUpdateResultInfo)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, resultInfo, sizeof(CUgraphExecUpdateResultInfo)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraph, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)resultInfo, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphKernelNodeCopyAttributes(CUgraphNode dst, CUgraphNode src) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&dst, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&src, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphKernelNodeCopyAttributes) < 0 ||
      rpc_write(conn, &dst, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, &src, sizeof(CUgraphNode)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dst, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&src, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphKernelNodeGetAttribute(CUgraphNode hNode,
                                       CUkernelNodeAttrID attr,
                                       CUkernelNodeAttrValue *value_out) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&attr, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)value_out, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphKernelNodeGetAttribute) < 0 ||
      rpc_write(conn, &hNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, &attr, sizeof(CUkernelNodeAttrID)) < 0 ||
      rpc_write(conn, value_out, sizeof(CUkernelNodeAttrValue)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, value_out, sizeof(CUkernelNodeAttrValue)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&attr, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)value_out, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphKernelNodeSetAttribute(CUgraphNode hNode,
                                       CUkernelNodeAttrID attr,
                                       const CUkernelNodeAttrValue *value) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&attr, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)value, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphKernelNodeSetAttribute) < 0 ||
      rpc_write(conn, &hNode, sizeof(CUgraphNode)) < 0 ||
      rpc_write(conn, &attr, sizeof(CUkernelNodeAttrID)) < 0 ||
      rpc_write(conn, &value, sizeof(const CUkernelNodeAttrValue *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&attr, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)value, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphDebugDotPrint(CUgraph hGraph, const char *path,
                              unsigned int flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hGraph, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)path, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphDebugDotPrint) < 0 ||
      rpc_write(conn, &hGraph, sizeof(CUgraph)) < 0 ||
      rpc_write(conn, &path, sizeof(const char *)) < 0 ||
      rpc_write(conn, &flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hGraph, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)path, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuUserObjectRetain(CUuserObject object, unsigned int count) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&object, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuUserObjectRetain) < 0 ||
      rpc_write(conn, &object, sizeof(CUuserObject)) < 0 ||
      rpc_write(conn, &count, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&object, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuUserObjectRelease(CUuserObject object, unsigned int count) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&object, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuUserObjectRelease) < 0 ||
      rpc_write(conn, &object, sizeof(CUuserObject)) < 0 ||
      rpc_write(conn, &count, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&object, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphRetainUserObject(CUgraph graph, CUuserObject object,
                                 unsigned int count, unsigned int flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&graph, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&object, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphRetainUserObject) < 0 ||
      rpc_write(conn, &graph, sizeof(CUgraph)) < 0 ||
      rpc_write(conn, &object, sizeof(CUuserObject)) < 0 ||
      rpc_write(conn, &count, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&graph, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&object, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphReleaseUserObject(CUgraph graph, CUuserObject object,
                                  unsigned int count) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&graph, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&object, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphReleaseUserObject) < 0 ||
      rpc_write(conn, &graph, sizeof(CUgraph)) < 0 ||
      rpc_write(conn, &object, sizeof(CUuserObject)) < 0 ||
      rpc_write(conn, &count, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&graph, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&object, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuOccupancyMaxActiveBlocksPerMultiprocessor(int *numBlocks,
                                                     CUfunction func,
                                                     int blockSize,
                                                     size_t dynamicSMemSize) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)numBlocks, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&func, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&blockSize, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dynamicSMemSize,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(
          conn, RPC_cuOccupancyMaxActiveBlocksPerMultiprocessor) < 0 ||
      rpc_write(conn, numBlocks, sizeof(int)) < 0 ||
      rpc_write(conn, &func, sizeof(CUfunction)) < 0 ||
      rpc_write(conn, &blockSize, sizeof(int)) < 0 ||
      rpc_write(conn, &dynamicSMemSize, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, numBlocks, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)numBlocks, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&func, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&blockSize, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dynamicSMemSize,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuOccupancyMaxActiveBlocksPerMultiprocessorWithFlags(
    int *numBlocks, CUfunction func, int blockSize, size_t dynamicSMemSize,
    unsigned int flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)numBlocks, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&func, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&blockSize, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dynamicSMemSize,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(
          conn, RPC_cuOccupancyMaxActiveBlocksPerMultiprocessorWithFlags) < 0 ||
      rpc_write(conn, numBlocks, sizeof(int)) < 0 ||
      rpc_write(conn, &func, sizeof(CUfunction)) < 0 ||
      rpc_write(conn, &blockSize, sizeof(int)) < 0 ||
      rpc_write(conn, &dynamicSMemSize, sizeof(size_t)) < 0 ||
      rpc_write(conn, &flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, numBlocks, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)numBlocks, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&func, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&blockSize, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dynamicSMemSize,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuOccupancyAvailableDynamicSMemPerBlock(size_t *dynamicSmemSize,
                                                 CUfunction func, int numBlocks,
                                                 int blockSize) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)dynamicSmemSize,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&func, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numBlocks, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&blockSize, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(
          conn, RPC_cuOccupancyAvailableDynamicSMemPerBlock) < 0 ||
      rpc_write(conn, dynamicSmemSize, sizeof(size_t)) < 0 ||
      rpc_write(conn, &func, sizeof(CUfunction)) < 0 ||
      rpc_write(conn, &numBlocks, sizeof(int)) < 0 ||
      rpc_write(conn, &blockSize, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, dynamicSmemSize, sizeof(size_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)dynamicSmemSize,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&func, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&numBlocks, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&blockSize, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuOccupancyMaxPotentialClusterSize(int *clusterSize, CUfunction func,
                                            const CUlaunchConfig *config) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)clusterSize,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&func, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)config, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuOccupancyMaxPotentialClusterSize) <
          0 ||
      rpc_write(conn, clusterSize, sizeof(int)) < 0 ||
      rpc_write(conn, &func, sizeof(CUfunction)) < 0 ||
      rpc_write(conn, &config, sizeof(const CUlaunchConfig *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, clusterSize, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)clusterSize,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&func, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)config, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuOccupancyMaxActiveClusters(int *numClusters, CUfunction func,
                                      const CUlaunchConfig *config) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)numClusters,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&func, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)config, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuOccupancyMaxActiveClusters) < 0 ||
      rpc_write(conn, numClusters, sizeof(int)) < 0 ||
      rpc_write(conn, &func, sizeof(CUfunction)) < 0 ||
      rpc_write(conn, &config, sizeof(const CUlaunchConfig *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, numClusters, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)numClusters,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&func, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)config, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuTexRefSetArray(CUtexref hTexRef, CUarray hArray,
                          unsigned int Flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hArray, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Flags, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuTexRefSetArray) < 0 ||
      rpc_write(conn, &hTexRef, sizeof(CUtexref)) < 0 ||
      rpc_write(conn, &hArray, sizeof(CUarray)) < 0 ||
      rpc_write(conn, &Flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hArray, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Flags, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuTexRefSetMipmappedArray(CUtexref hTexRef,
                                   CUmipmappedArray hMipmappedArray,
                                   unsigned int Flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hMipmappedArray,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Flags, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuTexRefSetMipmappedArray) < 0 ||
      rpc_write(conn, &hTexRef, sizeof(CUtexref)) < 0 ||
      rpc_write(conn, &hMipmappedArray, sizeof(CUmipmappedArray)) < 0 ||
      rpc_write(conn, &Flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hMipmappedArray,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Flags, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuTexRefSetAddress_v2(size_t *ByteOffset, CUtexref hTexRef,
                               CUdeviceptr dptr, size_t bytes) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)ByteOffset, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dptr, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&bytes, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuTexRefSetAddress_v2) < 0 ||
      rpc_write(conn, ByteOffset, sizeof(size_t)) < 0 ||
      rpc_write(conn, &hTexRef, sizeof(CUtexref)) < 0 ||
      rpc_write(conn, &dptr, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &bytes, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, ByteOffset, sizeof(size_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)ByteOffset, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dptr, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&bytes, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuTexRefSetAddress2D_v3(CUtexref hTexRef,
                                 const CUDA_ARRAY_DESCRIPTOR *desc,
                                 CUdeviceptr dptr, size_t Pitch) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)desc, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dptr, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Pitch, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuTexRefSetAddress2D_v3) < 0 ||
      rpc_write(conn, &hTexRef, sizeof(CUtexref)) < 0 ||
      rpc_write(conn, &desc, sizeof(const CUDA_ARRAY_DESCRIPTOR *)) < 0 ||
      rpc_write(conn, &dptr, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &Pitch, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)desc, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dptr, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Pitch, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuTexRefSetFormat(CUtexref hTexRef, CUarray_format fmt,
                           int NumPackedComponents) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&fmt, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&NumPackedComponents,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuTexRefSetFormat) < 0 ||
      rpc_write(conn, &hTexRef, sizeof(CUtexref)) < 0 ||
      rpc_write(conn, &fmt, sizeof(CUarray_format)) < 0 ||
      rpc_write(conn, &NumPackedComponents, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&fmt, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&NumPackedComponents,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuTexRefSetAddressMode(CUtexref hTexRef, int dim, CUaddress_mode am) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dim, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&am, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuTexRefSetAddressMode) < 0 ||
      rpc_write(conn, &hTexRef, sizeof(CUtexref)) < 0 ||
      rpc_write(conn, &dim, sizeof(int)) < 0 ||
      rpc_write(conn, &am, sizeof(CUaddress_mode)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dim, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&am, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuTexRefSetFilterMode(CUtexref hTexRef, CUfilter_mode fm) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&fm, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuTexRefSetFilterMode) < 0 ||
      rpc_write(conn, &hTexRef, sizeof(CUtexref)) < 0 ||
      rpc_write(conn, &fm, sizeof(CUfilter_mode)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&fm, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuTexRefSetMipmapFilterMode(CUtexref hTexRef, CUfilter_mode fm) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&fm, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuTexRefSetMipmapFilterMode) < 0 ||
      rpc_write(conn, &hTexRef, sizeof(CUtexref)) < 0 ||
      rpc_write(conn, &fm, sizeof(CUfilter_mode)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&fm, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuTexRefSetMipmapLevelBias(CUtexref hTexRef, float bias) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&bias, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuTexRefSetMipmapLevelBias) < 0 ||
      rpc_write(conn, &hTexRef, sizeof(CUtexref)) < 0 ||
      rpc_write(conn, &bias, sizeof(float)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&bias, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuTexRefSetMipmapLevelClamp(CUtexref hTexRef,
                                     float minMipmapLevelClamp,
                                     float maxMipmapLevelClamp) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&minMipmapLevelClamp,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&maxMipmapLevelClamp,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuTexRefSetMipmapLevelClamp) < 0 ||
      rpc_write(conn, &hTexRef, sizeof(CUtexref)) < 0 ||
      rpc_write(conn, &minMipmapLevelClamp, sizeof(float)) < 0 ||
      rpc_write(conn, &maxMipmapLevelClamp, sizeof(float)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&minMipmapLevelClamp,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&maxMipmapLevelClamp,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuTexRefSetMaxAnisotropy(CUtexref hTexRef, unsigned int maxAniso) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&maxAniso, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuTexRefSetMaxAnisotropy) < 0 ||
      rpc_write(conn, &hTexRef, sizeof(CUtexref)) < 0 ||
      rpc_write(conn, &maxAniso, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&maxAniso, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuTexRefSetBorderColor(CUtexref hTexRef, float *pBorderColor) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pBorderColor,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuTexRefSetBorderColor) < 0 ||
      rpc_write(conn, &hTexRef, sizeof(CUtexref)) < 0 ||
      rpc_write(conn, pBorderColor, sizeof(float)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pBorderColor, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pBorderColor,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuTexRefSetFlags(CUtexref hTexRef, unsigned int Flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Flags, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuTexRefSetFlags) < 0 ||
      rpc_write(conn, &hTexRef, sizeof(CUtexref)) < 0 ||
      rpc_write(conn, &Flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Flags, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuTexRefGetAddress_v2(CUdeviceptr *pdptr, CUtexref hTexRef) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pdptr, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuTexRefGetAddress_v2) < 0 ||
      rpc_write(conn, pdptr, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, &hTexRef, sizeof(CUtexref)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pdptr, sizeof(CUdeviceptr)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pdptr, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuTexRefGetArray(CUarray *phArray, CUtexref hTexRef) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)phArray, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuTexRefGetArray) < 0 ||
      rpc_write(conn, phArray, sizeof(CUarray)) < 0 ||
      rpc_write(conn, &hTexRef, sizeof(CUtexref)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, phArray, sizeof(CUarray)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)phArray, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuTexRefGetMipmappedArray(CUmipmappedArray *phMipmappedArray,
                                   CUtexref hTexRef) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)phMipmappedArray,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuTexRefGetMipmappedArray) < 0 ||
      rpc_write(conn, phMipmappedArray, sizeof(CUmipmappedArray)) < 0 ||
      rpc_write(conn, &hTexRef, sizeof(CUtexref)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, phMipmappedArray, sizeof(CUmipmappedArray)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)phMipmappedArray,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuTexRefGetAddressMode(CUaddress_mode *pam, CUtexref hTexRef,
                                int dim) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pam, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dim, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuTexRefGetAddressMode) < 0 ||
      rpc_write(conn, pam, sizeof(CUaddress_mode)) < 0 ||
      rpc_write(conn, &hTexRef, sizeof(CUtexref)) < 0 ||
      rpc_write(conn, &dim, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pam, sizeof(CUaddress_mode)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pam, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dim, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuTexRefGetFilterMode(CUfilter_mode *pfm, CUtexref hTexRef) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pfm, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuTexRefGetFilterMode) < 0 ||
      rpc_write(conn, pfm, sizeof(CUfilter_mode)) < 0 ||
      rpc_write(conn, &hTexRef, sizeof(CUtexref)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pfm, sizeof(CUfilter_mode)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pfm, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuTexRefGetFormat(CUarray_format *pFormat, int *pNumChannels,
                           CUtexref hTexRef) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pFormat, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pNumChannels,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuTexRefGetFormat) < 0 ||
      rpc_write(conn, pFormat, sizeof(CUarray_format)) < 0 ||
      rpc_write(conn, pNumChannels, sizeof(int)) < 0 ||
      rpc_write(conn, &hTexRef, sizeof(CUtexref)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pFormat, sizeof(CUarray_format)) < 0 ||
      rpc_read(conn, pNumChannels, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pFormat, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pNumChannels,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuTexRefGetMipmapFilterMode(CUfilter_mode *pfm, CUtexref hTexRef) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pfm, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuTexRefGetMipmapFilterMode) < 0 ||
      rpc_write(conn, pfm, sizeof(CUfilter_mode)) < 0 ||
      rpc_write(conn, &hTexRef, sizeof(CUtexref)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pfm, sizeof(CUfilter_mode)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pfm, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuTexRefGetMipmapLevelBias(float *pbias, CUtexref hTexRef) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pbias, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuTexRefGetMipmapLevelBias) < 0 ||
      rpc_write(conn, pbias, sizeof(float)) < 0 ||
      rpc_write(conn, &hTexRef, sizeof(CUtexref)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pbias, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pbias, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuTexRefGetMipmapLevelClamp(float *pminMipmapLevelClamp,
                                     float *pmaxMipmapLevelClamp,
                                     CUtexref hTexRef) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pminMipmapLevelClamp,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pmaxMipmapLevelClamp,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuTexRefGetMipmapLevelClamp) < 0 ||
      rpc_write(conn, pminMipmapLevelClamp, sizeof(float)) < 0 ||
      rpc_write(conn, pmaxMipmapLevelClamp, sizeof(float)) < 0 ||
      rpc_write(conn, &hTexRef, sizeof(CUtexref)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pminMipmapLevelClamp, sizeof(float)) < 0 ||
      rpc_read(conn, pmaxMipmapLevelClamp, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pminMipmapLevelClamp,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pmaxMipmapLevelClamp,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuTexRefGetMaxAnisotropy(int *pmaxAniso, CUtexref hTexRef) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pmaxAniso, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuTexRefGetMaxAnisotropy) < 0 ||
      rpc_write(conn, pmaxAniso, sizeof(int)) < 0 ||
      rpc_write(conn, &hTexRef, sizeof(CUtexref)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pmaxAniso, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pmaxAniso, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuTexRefGetBorderColor(float *pBorderColor, CUtexref hTexRef) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pBorderColor,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuTexRefGetBorderColor) < 0 ||
      rpc_write(conn, pBorderColor, sizeof(float)) < 0 ||
      rpc_write(conn, &hTexRef, sizeof(CUtexref)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pBorderColor, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pBorderColor,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuTexRefGetFlags(unsigned int *pFlags, CUtexref hTexRef) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pFlags, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuTexRefGetFlags) < 0 ||
      rpc_write(conn, pFlags, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &hTexRef, sizeof(CUtexref)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pFlags, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pFlags, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuTexRefCreate(CUtexref *pTexRef) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pTexRef, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuTexRefCreate) < 0 ||
      rpc_write(conn, pTexRef, sizeof(CUtexref)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pTexRef, sizeof(CUtexref)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pTexRef, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuTexRefDestroy(CUtexref hTexRef) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuTexRefDestroy) < 0 ||
      rpc_write(conn, &hTexRef, sizeof(CUtexref)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hTexRef, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuSurfRefSetArray(CUsurfref hSurfRef, CUarray hArray,
                           unsigned int Flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hSurfRef, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hArray, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Flags, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuSurfRefSetArray) < 0 ||
      rpc_write(conn, &hSurfRef, sizeof(CUsurfref)) < 0 ||
      rpc_write(conn, &hArray, sizeof(CUarray)) < 0 ||
      rpc_write(conn, &Flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hSurfRef, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hArray, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Flags, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuSurfRefGetArray(CUarray *phArray, CUsurfref hSurfRef) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)phArray, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hSurfRef, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuSurfRefGetArray) < 0 ||
      rpc_write(conn, phArray, sizeof(CUarray)) < 0 ||
      rpc_write(conn, &hSurfRef, sizeof(CUsurfref)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, phArray, sizeof(CUarray)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)phArray, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hSurfRef, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuTexObjectCreate(CUtexObject *pTexObject,
                           const CUDA_RESOURCE_DESC *pResDesc,
                           const CUDA_TEXTURE_DESC *pTexDesc,
                           const CUDA_RESOURCE_VIEW_DESC *pResViewDesc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pTexObject, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pResDesc, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pTexDesc, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pResViewDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuTexObjectCreate) < 0 ||
      rpc_write(conn, pTexObject, sizeof(CUtexObject)) < 0 ||
      rpc_write(conn, &pResDesc, sizeof(const CUDA_RESOURCE_DESC *)) < 0 ||
      rpc_write(conn, &pTexDesc, sizeof(const CUDA_TEXTURE_DESC *)) < 0 ||
      rpc_write(conn, &pResViewDesc, sizeof(const CUDA_RESOURCE_VIEW_DESC *)) <
          0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pTexObject, sizeof(CUtexObject)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pTexObject, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pResDesc, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pTexDesc, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pResViewDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuTexObjectDestroy(CUtexObject texObject) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&texObject, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuTexObjectDestroy) < 0 ||
      rpc_write(conn, &texObject, sizeof(CUtexObject)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&texObject, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuTexObjectGetResourceDesc(CUDA_RESOURCE_DESC *pResDesc,
                                    CUtexObject texObject) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pResDesc, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&texObject, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuTexObjectGetResourceDesc) < 0 ||
      rpc_write(conn, pResDesc, sizeof(CUDA_RESOURCE_DESC)) < 0 ||
      rpc_write(conn, &texObject, sizeof(CUtexObject)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pResDesc, sizeof(CUDA_RESOURCE_DESC)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pResDesc, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&texObject, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuTexObjectGetTextureDesc(CUDA_TEXTURE_DESC *pTexDesc,
                                   CUtexObject texObject) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pTexDesc, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&texObject, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuTexObjectGetTextureDesc) < 0 ||
      rpc_write(conn, pTexDesc, sizeof(CUDA_TEXTURE_DESC)) < 0 ||
      rpc_write(conn, &texObject, sizeof(CUtexObject)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pTexDesc, sizeof(CUDA_TEXTURE_DESC)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pTexDesc, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&texObject, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuTexObjectGetResourceViewDesc(CUDA_RESOURCE_VIEW_DESC *pResViewDesc,
                                        CUtexObject texObject) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pResViewDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&texObject, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuTexObjectGetResourceViewDesc) < 0 ||
      rpc_write(conn, pResViewDesc, sizeof(CUDA_RESOURCE_VIEW_DESC)) < 0 ||
      rpc_write(conn, &texObject, sizeof(CUtexObject)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pResViewDesc, sizeof(CUDA_RESOURCE_VIEW_DESC)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pResViewDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&texObject, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuSurfObjectCreate(CUsurfObject *pSurfObject,
                            const CUDA_RESOURCE_DESC *pResDesc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pSurfObject,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pResDesc, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuSurfObjectCreate) < 0 ||
      rpc_write(conn, pSurfObject, sizeof(CUsurfObject)) < 0 ||
      rpc_write(conn, &pResDesc, sizeof(const CUDA_RESOURCE_DESC *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pSurfObject, sizeof(CUsurfObject)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pSurfObject,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pResDesc, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuSurfObjectDestroy(CUsurfObject surfObject) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&surfObject,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuSurfObjectDestroy) < 0 ||
      rpc_write(conn, &surfObject, sizeof(CUsurfObject)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&surfObject,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuSurfObjectGetResourceDesc(CUDA_RESOURCE_DESC *pResDesc,
                                     CUsurfObject surfObject) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pResDesc, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&surfObject,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuSurfObjectGetResourceDesc) < 0 ||
      rpc_write(conn, pResDesc, sizeof(CUDA_RESOURCE_DESC)) < 0 ||
      rpc_write(conn, &surfObject, sizeof(CUsurfObject)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pResDesc, sizeof(CUDA_RESOURCE_DESC)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pResDesc, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&surfObject,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuDeviceCanAccessPeer(int *canAccessPeer, CUdevice dev,
                               CUdevice peerDev) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)canAccessPeer,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dev, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&peerDev, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuDeviceCanAccessPeer) < 0 ||
      rpc_write(conn, canAccessPeer, sizeof(int)) < 0 ||
      rpc_write(conn, &dev, sizeof(CUdevice)) < 0 ||
      rpc_write(conn, &peerDev, sizeof(CUdevice)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, canAccessPeer, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)canAccessPeer,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dev, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&peerDev, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuCtxEnablePeerAccess(CUcontext peerContext, unsigned int Flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&peerContext,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Flags, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuCtxEnablePeerAccess) < 0 ||
      rpc_write(conn, &peerContext, sizeof(CUcontext)) < 0 ||
      rpc_write(conn, &Flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&peerContext,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&Flags, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuCtxDisablePeerAccess(CUcontext peerContext) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&peerContext,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuCtxDisablePeerAccess) < 0 ||
      rpc_write(conn, &peerContext, sizeof(CUcontext)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&peerContext,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuDeviceGetP2PAttribute(int *value, CUdevice_P2PAttribute attrib,
                                 CUdevice srcDevice, CUdevice dstDevice) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)value, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&attrib, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&srcDevice, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dstDevice, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuDeviceGetP2PAttribute) < 0 ||
      rpc_write(conn, value, sizeof(int)) < 0 ||
      rpc_write(conn, &attrib, sizeof(CUdevice_P2PAttribute)) < 0 ||
      rpc_write(conn, &srcDevice, sizeof(CUdevice)) < 0 ||
      rpc_write(conn, &dstDevice, sizeof(CUdevice)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, value, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)value, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&attrib, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&srcDevice, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&dstDevice, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphicsUnregisterResource(CUgraphicsResource resource) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&resource, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphicsUnregisterResource) < 0 ||
      rpc_write(conn, &resource, sizeof(CUgraphicsResource)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&resource, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphicsSubResourceGetMappedArray(CUarray *pArray,
                                             CUgraphicsResource resource,
                                             unsigned int arrayIndex,
                                             unsigned int mipLevel) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pArray, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&resource, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&arrayIndex,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&mipLevel, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphicsSubResourceGetMappedArray) <
          0 ||
      rpc_write(conn, pArray, sizeof(CUarray)) < 0 ||
      rpc_write(conn, &resource, sizeof(CUgraphicsResource)) < 0 ||
      rpc_write(conn, &arrayIndex, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &mipLevel, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pArray, sizeof(CUarray)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pArray, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&resource, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&arrayIndex,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&mipLevel, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult
cuGraphicsResourceGetMappedMipmappedArray(CUmipmappedArray *pMipmappedArray,
                                          CUgraphicsResource resource) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pMipmappedArray,
                             cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&resource, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(
          conn, RPC_cuGraphicsResourceGetMappedMipmappedArray) < 0 ||
      rpc_write(conn, pMipmappedArray, sizeof(CUmipmappedArray)) < 0 ||
      rpc_write(conn, &resource, sizeof(CUgraphicsResource)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pMipmappedArray, sizeof(CUmipmappedArray)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pMipmappedArray,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&resource, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphicsResourceGetMappedPointer_v2(CUdeviceptr *pDevPtr,
                                               size_t *pSize,
                                               CUgraphicsResource resource) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pDevPtr, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pSize, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&resource, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphicsResourceGetMappedPointer_v2) <
          0 ||
      rpc_write(conn, pDevPtr, sizeof(CUdeviceptr)) < 0 ||
      rpc_write(conn, pSize, sizeof(size_t)) < 0 ||
      rpc_write(conn, &resource, sizeof(CUgraphicsResource)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pDevPtr, sizeof(CUdeviceptr)) < 0 ||
      rpc_read(conn, pSize, sizeof(size_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pDevPtr, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)pSize, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&resource, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphicsResourceSetMapFlags_v2(CUgraphicsResource resource,
                                          unsigned int flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&resource, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphicsResourceSetMapFlags_v2) < 0 ||
      rpc_write(conn, &resource, sizeof(CUgraphicsResource)) < 0 ||
      rpc_write(conn, &flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&resource, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphicsMapResources(unsigned int count,
                                CUgraphicsResource *resources,
                                CUstream hStream) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)resources, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphicsMapResources) < 0 ||
      rpc_write(conn, &count, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, resources, sizeof(CUgraphicsResource)) < 0 ||
      rpc_write(conn, &hStream, sizeof(CUstream)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, resources, sizeof(CUgraphicsResource)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)resources, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

CUresult cuGraphicsUnmapResources(unsigned int count,
                                  CUgraphicsResource *resources,
                                  CUstream hStream) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyHostToDevice) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)resources, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyHostToDevice) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  CUresult return_value;
  if (rpc_write_start_request(conn, RPC_cuGraphicsUnmapResources) < 0 ||
      rpc_write(conn, &count, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, resources, sizeof(CUgraphicsResource)) < 0 ||
      rpc_write(conn, &hStream, sizeof(CUstream)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, resources, sizeof(CUgraphicsResource)) < 0 ||
      rpc_read(conn, &return_value, sizeof(CUresult)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyDeviceToHost) < 0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)resources, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyDeviceToHost) <
      0)
    return CUDA_ERROR_DEVICE_UNAVAILABLE;
  return return_value;
}

cudaError_t cudaDeviceReset() {
  conn_t *conn = rpc_client_get_connection(0);
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaDeviceReset) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaDeviceSynchronize() {
  conn_t *conn = rpc_client_get_connection(0);
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaDeviceSynchronize) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaDeviceSetLimit(enum cudaLimit limit, size_t value) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&limit, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&value, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaDeviceSetLimit) < 0 ||
      rpc_write(conn, &limit, sizeof(enum cudaLimit)) < 0 ||
      rpc_write(conn, &value, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&limit, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&value, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaDeviceGetLimit(size_t *pValue, enum cudaLimit limit) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pValue, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&limit, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaDeviceGetLimit) < 0 ||
      rpc_write(conn, pValue, sizeof(size_t)) < 0 ||
      rpc_write(conn, &limit, sizeof(enum cudaLimit)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pValue, sizeof(size_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pValue, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&limit, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaDeviceGetTexture1DLinearMaxWidth(
    size_t *maxWidthInElements, const struct cudaChannelFormatDesc *fmtDesc,
    int device) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)maxWidthInElements,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)fmtDesc, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaDeviceGetTexture1DLinearMaxWidth) <
          0 ||
      rpc_write(conn, maxWidthInElements, sizeof(size_t)) < 0 ||
      rpc_write(conn, &fmtDesc, sizeof(const struct cudaChannelFormatDesc *)) <
          0 ||
      rpc_write(conn, &device, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, maxWidthInElements, sizeof(size_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)maxWidthInElements,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)fmtDesc, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaDeviceGetCacheConfig(enum cudaFuncCache *pCacheConfig) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pCacheConfig,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaDeviceGetCacheConfig) < 0 ||
      rpc_write(conn, pCacheConfig, sizeof(enum cudaFuncCache)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pCacheConfig, sizeof(enum cudaFuncCache)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pCacheConfig,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaDeviceGetStreamPriorityRange(int *leastPriority,
                                             int *greatestPriority) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)leastPriority,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)greatestPriority,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaDeviceGetStreamPriorityRange) < 0 ||
      rpc_write(conn, leastPriority, sizeof(int)) < 0 ||
      rpc_write(conn, greatestPriority, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, leastPriority, sizeof(int)) < 0 ||
      rpc_read(conn, greatestPriority, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)leastPriority,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)greatestPriority,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaDeviceSetCacheConfig(enum cudaFuncCache cacheConfig) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&cacheConfig,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaDeviceSetCacheConfig) < 0 ||
      rpc_write(conn, &cacheConfig, sizeof(enum cudaFuncCache)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&cacheConfig,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaDeviceGetSharedMemConfig(enum cudaSharedMemConfig *pConfig) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pConfig, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaDeviceGetSharedMemConfig) < 0 ||
      rpc_write(conn, pConfig, sizeof(enum cudaSharedMemConfig)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pConfig, sizeof(enum cudaSharedMemConfig)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pConfig, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaDeviceSetSharedMemConfig(enum cudaSharedMemConfig config) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&config, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaDeviceSetSharedMemConfig) < 0 ||
      rpc_write(conn, &config, sizeof(enum cudaSharedMemConfig)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&config, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaDeviceGetByPCIBusId(int *device, const char *pciBusId) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)device, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pciBusId, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaDeviceGetByPCIBusId) < 0 ||
      rpc_write(conn, device, sizeof(int)) < 0 ||
      rpc_write(conn, &pciBusId, sizeof(const char *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, device, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)device, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pciBusId, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaDeviceGetPCIBusId(char *pciBusId, int len, int device) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pciBusId, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&len, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaDeviceGetPCIBusId) < 0 ||
      rpc_write(conn, pciBusId, sizeof(char)) < 0 ||
      rpc_write(conn, &len, sizeof(int)) < 0 ||
      rpc_write(conn, &device, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pciBusId, sizeof(char)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pciBusId, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&len, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaIpcGetEventHandle(cudaIpcEventHandle_t *handle,
                                  cudaEvent_t event) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)handle, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&event, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaIpcGetEventHandle) < 0 ||
      rpc_write(conn, handle, sizeof(cudaIpcEventHandle_t)) < 0 ||
      rpc_write(conn, &event, sizeof(cudaEvent_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, handle, sizeof(cudaIpcEventHandle_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)handle, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&event, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaIpcOpenEventHandle(cudaEvent_t *event,
                                   cudaIpcEventHandle_t handle) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)event, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaIpcOpenEventHandle) < 0 ||
      rpc_write(conn, event, sizeof(cudaEvent_t)) < 0 ||
      rpc_write(conn, &handle, sizeof(cudaIpcEventHandle_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, event, sizeof(cudaEvent_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)event, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaIpcOpenMemHandle(void **devPtr, cudaIpcMemHandle_t handle,
                                 unsigned int flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)devPtr, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaIpcOpenMemHandle) < 0 ||
      rpc_write(conn, devPtr, sizeof(void *)) < 0 ||
      rpc_write(conn, &handle, sizeof(cudaIpcMemHandle_t)) < 0 ||
      rpc_write(conn, &flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, devPtr, sizeof(void *)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)devPtr, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaDeviceFlushGPUDirectRDMAWrites(
    enum cudaFlushGPUDirectRDMAWritesTarget target,
    enum cudaFlushGPUDirectRDMAWritesScope scope) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&target, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&scope, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaDeviceFlushGPUDirectRDMAWrites) <
          0 ||
      rpc_write(conn, &target,
                sizeof(enum cudaFlushGPUDirectRDMAWritesTarget)) < 0 ||
      rpc_write(conn, &scope, sizeof(enum cudaFlushGPUDirectRDMAWritesScope)) <
          0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&target, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&scope, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaThreadExit() {
  conn_t *conn = rpc_client_get_connection(0);
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaThreadExit) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaThreadSynchronize() {
  conn_t *conn = rpc_client_get_connection(0);
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaThreadSynchronize) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaThreadSetLimit(enum cudaLimit limit, size_t value) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&limit, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&value, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaThreadSetLimit) < 0 ||
      rpc_write(conn, &limit, sizeof(enum cudaLimit)) < 0 ||
      rpc_write(conn, &value, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&limit, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&value, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaThreadGetLimit(size_t *pValue, enum cudaLimit limit) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pValue, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&limit, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaThreadGetLimit) < 0 ||
      rpc_write(conn, pValue, sizeof(size_t)) < 0 ||
      rpc_write(conn, &limit, sizeof(enum cudaLimit)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pValue, sizeof(size_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pValue, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&limit, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaThreadGetCacheConfig(enum cudaFuncCache *pCacheConfig) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pCacheConfig,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaThreadGetCacheConfig) < 0 ||
      rpc_write(conn, pCacheConfig, sizeof(enum cudaFuncCache)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pCacheConfig, sizeof(enum cudaFuncCache)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pCacheConfig,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaThreadSetCacheConfig(enum cudaFuncCache cacheConfig) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&cacheConfig,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaThreadSetCacheConfig) < 0 ||
      rpc_write(conn, &cacheConfig, sizeof(enum cudaFuncCache)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&cacheConfig,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGetLastError() {
  conn_t *conn = rpc_client_get_connection(0);
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGetLastError) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaPeekAtLastError() {
  conn_t *conn = rpc_client_get_connection(0);
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaPeekAtLastError) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGetDeviceCount(int *count) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)count, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGetDeviceCount) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, count, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)count, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGetDeviceProperties_v2(struct cudaDeviceProp *prop,
                                       int device) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)prop, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGetDeviceProperties_v2) < 0 ||
      rpc_write(conn, &device, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, prop, sizeof(struct cudaDeviceProp)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)prop, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaDeviceGetAttribute(int *value, enum cudaDeviceAttr attr,
                                   int device) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)value, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&attr, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaDeviceGetAttribute) < 0 ||
      rpc_write(conn, value, sizeof(int)) < 0 ||
      rpc_write(conn, &attr, sizeof(enum cudaDeviceAttr)) < 0 ||
      rpc_write(conn, &device, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, value, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)value, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&attr, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaDeviceGetDefaultMemPool(cudaMemPool_t *memPool, int device) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)memPool, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaDeviceGetDefaultMemPool) < 0 ||
      rpc_write(conn, memPool, sizeof(cudaMemPool_t)) < 0 ||
      rpc_write(conn, &device, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, memPool, sizeof(cudaMemPool_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)memPool, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaDeviceSetMemPool(int device, cudaMemPool_t memPool) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&memPool, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaDeviceSetMemPool) < 0 ||
      rpc_write(conn, &device, sizeof(int)) < 0 ||
      rpc_write(conn, &memPool, sizeof(cudaMemPool_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&memPool, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaDeviceGetMemPool(cudaMemPool_t *memPool, int device) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)memPool, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaDeviceGetMemPool) < 0 ||
      rpc_write(conn, memPool, sizeof(cudaMemPool_t)) < 0 ||
      rpc_write(conn, &device, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, memPool, sizeof(cudaMemPool_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)memPool, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaDeviceGetP2PAttribute(int *value, enum cudaDeviceP2PAttr attr,
                                      int srcDevice, int dstDevice) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)value, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&attr, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&srcDevice, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&dstDevice, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaDeviceGetP2PAttribute) < 0 ||
      rpc_write(conn, value, sizeof(int)) < 0 ||
      rpc_write(conn, &attr, sizeof(enum cudaDeviceP2PAttr)) < 0 ||
      rpc_write(conn, &srcDevice, sizeof(int)) < 0 ||
      rpc_write(conn, &dstDevice, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, value, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)value, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&attr, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&srcDevice, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&dstDevice, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaChooseDevice(int *device, const struct cudaDeviceProp *prop) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)device, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)prop, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaChooseDevice) < 0 ||
      rpc_write(conn, device, sizeof(int)) < 0 ||
      rpc_write(conn, &prop, sizeof(const struct cudaDeviceProp *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, device, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)device, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)prop, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaInitDevice(int device, unsigned int deviceFlags,
                           unsigned int flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&deviceFlags,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaInitDevice) < 0 ||
      rpc_write(conn, &device, sizeof(int)) < 0 ||
      rpc_write(conn, &deviceFlags, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&deviceFlags,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaSetDevice(int device) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaSetDevice) < 0 ||
      rpc_write(conn, &device, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGetDevice(int *device) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)device, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGetDevice) < 0 ||
      rpc_write(conn, device, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, device, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)device, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaSetValidDevices(int *device_arr, int len) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)device_arr, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&len, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaSetValidDevices) < 0 ||
      rpc_write(conn, device_arr, sizeof(int)) < 0 ||
      rpc_write(conn, &len, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, device_arr, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)device_arr, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&len, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaSetDeviceFlags(unsigned int flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaSetDeviceFlags) < 0 ||
      rpc_write(conn, &flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGetDeviceFlags(unsigned int *flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)flags, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGetDeviceFlags) < 0 ||
      rpc_write(conn, flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, flags, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)flags, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaStreamCreate(cudaStream_t *pStream) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pStream, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaStreamCreate) < 0 ||
      rpc_write(conn, pStream, sizeof(cudaStream_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pStream, sizeof(cudaStream_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pStream, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaStreamCreateWithFlags(cudaStream_t *pStream,
                                      unsigned int flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pStream, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaStreamCreateWithFlags) < 0 ||
      rpc_write(conn, pStream, sizeof(cudaStream_t)) < 0 ||
      rpc_write(conn, &flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pStream, sizeof(cudaStream_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pStream, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaStreamCreateWithPriority(cudaStream_t *pStream,
                                         unsigned int flags, int priority) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pStream, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&priority, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaStreamCreateWithPriority) < 0 ||
      rpc_write(conn, pStream, sizeof(cudaStream_t)) < 0 ||
      rpc_write(conn, &flags, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &priority, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pStream, sizeof(cudaStream_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pStream, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&priority, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaStreamGetPriority(cudaStream_t hStream, int *priority) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)priority, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaStreamGetPriority) < 0 ||
      rpc_write(conn, &hStream, sizeof(cudaStream_t)) < 0 ||
      rpc_write(conn, priority, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, priority, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)priority, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaStreamGetFlags(cudaStream_t hStream, unsigned int *flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)flags, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaStreamGetFlags) < 0 ||
      rpc_write(conn, &hStream, sizeof(cudaStream_t)) < 0 ||
      rpc_write(conn, flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, flags, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)flags, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaStreamGetId(cudaStream_t hStream,
                            unsigned long long *streamId) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)streamId, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaStreamGetId) < 0 ||
      rpc_write(conn, &hStream, sizeof(cudaStream_t)) < 0 ||
      rpc_write(conn, streamId, sizeof(unsigned long long)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, streamId, sizeof(unsigned long long)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)streamId, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaCtxResetPersistingL2Cache() {
  conn_t *conn = rpc_client_get_connection(0);
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaCtxResetPersistingL2Cache) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaStreamCopyAttributes(cudaStream_t dst, cudaStream_t src) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&dst, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&src, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaStreamCopyAttributes) < 0 ||
      rpc_write(conn, &dst, sizeof(cudaStream_t)) < 0 ||
      rpc_write(conn, &src, sizeof(cudaStream_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&dst, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&src, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaStreamGetAttribute(cudaStream_t hStream,
                                   cudaLaunchAttributeID attr,
                                   cudaLaunchAttributeValue *value_out) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&attr, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)value_out, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaStreamGetAttribute) < 0 ||
      rpc_write(conn, &hStream, sizeof(cudaStream_t)) < 0 ||
      rpc_write(conn, &attr, sizeof(cudaLaunchAttributeID)) < 0 ||
      rpc_write(conn, value_out, sizeof(cudaLaunchAttributeValue)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, value_out, sizeof(cudaLaunchAttributeValue)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&attr, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)value_out, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaStreamSetAttribute(cudaStream_t hStream,
                                   cudaLaunchAttributeID attr,
                                   const cudaLaunchAttributeValue *value) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&attr, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)value, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaStreamSetAttribute) < 0 ||
      rpc_write(conn, &hStream, sizeof(cudaStream_t)) < 0 ||
      rpc_write(conn, &attr, sizeof(cudaLaunchAttributeID)) < 0 ||
      rpc_write(conn, &value, sizeof(const cudaLaunchAttributeValue *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&attr, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)value, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaStreamDestroy(cudaStream_t stream) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaStreamDestroy) < 0 ||
      rpc_write(conn, &stream, sizeof(cudaStream_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaStreamWaitEvent(cudaStream_t stream, cudaEvent_t event,
                                unsigned int flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&event, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaStreamWaitEvent) < 0 ||
      rpc_write(conn, &stream, sizeof(cudaStream_t)) < 0 ||
      rpc_write(conn, &event, sizeof(cudaEvent_t)) < 0 ||
      rpc_write(conn, &flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&event, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaStreamSynchronize(cudaStream_t stream) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaStreamSynchronize) < 0 ||
      rpc_write(conn, &stream, sizeof(cudaStream_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaStreamQuery(cudaStream_t stream) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaStreamQuery) < 0 ||
      rpc_write(conn, &stream, sizeof(cudaStream_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaStreamBeginCapture(cudaStream_t stream,
                                   enum cudaStreamCaptureMode mode) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaStreamBeginCapture) < 0 ||
      rpc_write(conn, &stream, sizeof(cudaStream_t)) < 0 ||
      rpc_write(conn, &mode, sizeof(enum cudaStreamCaptureMode)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t
cudaThreadExchangeStreamCaptureMode(enum cudaStreamCaptureMode *mode) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)mode, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaThreadExchangeStreamCaptureMode) <
          0 ||
      rpc_write(conn, mode, sizeof(enum cudaStreamCaptureMode)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, mode, sizeof(enum cudaStreamCaptureMode)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)mode, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaStreamEndCapture(cudaStream_t stream, cudaGraph_t *pGraph) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pGraph, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaStreamEndCapture) < 0 ||
      rpc_write(conn, &stream, sizeof(cudaStream_t)) < 0 ||
      rpc_write(conn, pGraph, sizeof(cudaGraph_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pGraph, sizeof(cudaGraph_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pGraph, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t
cudaStreamIsCapturing(cudaStream_t stream,
                      enum cudaStreamCaptureStatus *pCaptureStatus) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pCaptureStatus,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaStreamIsCapturing) < 0 ||
      rpc_write(conn, &stream, sizeof(cudaStream_t)) < 0 ||
      rpc_write(conn, pCaptureStatus, sizeof(enum cudaStreamCaptureStatus)) <
          0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pCaptureStatus, sizeof(enum cudaStreamCaptureStatus)) <
          0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pCaptureStatus,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaStreamGetCaptureInfo_v2(
    cudaStream_t stream, enum cudaStreamCaptureStatus *captureStatus_out,
    unsigned long long *id_out, cudaGraph_t *graph_out,
    const cudaGraphNode_t **dependencies_out, size_t *numDependencies_out) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)captureStatus_out,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)id_out, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)graph_out, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)numDependencies_out,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)dependencies_out,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  for (int i = 0; i < static_cast<int>(*numDependencies_out) &&
                  is_unified_pointer(conn, (void *)dependencies_out);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&dependencies_out[i],
                               cudaMemcpyHostToDevice) < 0)
      return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaStreamGetCaptureInfo_v2) < 0 ||
      rpc_write(conn, &stream, sizeof(cudaStream_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, captureStatus_out, sizeof(enum cudaStreamCaptureStatus)) <
          0 ||
      rpc_read(conn, id_out, sizeof(unsigned long long)) < 0 ||
      rpc_read(conn, graph_out, sizeof(cudaGraph_t)) < 0 ||
      rpc_read(conn, numDependencies_out, sizeof(size_t)) < 0 ||
      rpc_read(conn, dependencies_out,
               *numDependencies_out * sizeof(const cudaGraphNode_t *)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)captureStatus_out,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)id_out, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)graph_out, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)numDependencies_out,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)dependencies_out,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  for (int i = 0; i < static_cast<int>(*numDependencies_out) &&
                  is_unified_pointer(conn, (void *)dependencies_out);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&dependencies_out[i],
                               cudaMemcpyDeviceToHost) < 0)
      return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaStreamUpdateCaptureDependencies(cudaStream_t stream,
                                                cudaGraphNode_t *dependencies,
                                                size_t numDependencies,
                                                unsigned int flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)dependencies,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  for (int i = 0; i < static_cast<int>(numDependencies) &&
                  is_unified_pointer(conn, (void *)dependencies);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&dependencies[i],
                               cudaMemcpyHostToDevice) < 0)
      return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaStreamUpdateCaptureDependencies) <
          0 ||
      rpc_write(conn, &stream, sizeof(cudaStream_t)) < 0 ||
      rpc_write(conn, &numDependencies, sizeof(size_t)) < 0 ||
      rpc_write(conn, dependencies, numDependencies * sizeof(cudaGraphNode_t)) <
          0 ||
      rpc_write(conn, &flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)dependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  for (int i = 0; i < static_cast<int>(numDependencies) &&
                  is_unified_pointer(conn, (void *)dependencies);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&dependencies[i],
                               cudaMemcpyDeviceToHost) < 0)
      return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaEventCreate(cudaEvent_t *event) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)event, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaEventCreate) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, event, sizeof(cudaEvent_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)event, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaEventCreateWithFlags(cudaEvent_t *event, unsigned int flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)event, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaEventCreateWithFlags) < 0 ||
      rpc_write(conn, &flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, event, sizeof(cudaEvent_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)event, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaEventRecord(cudaEvent_t event, cudaStream_t stream) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&event, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaEventRecord) < 0 ||
      rpc_write(conn, &event, sizeof(cudaEvent_t)) < 0 ||
      rpc_write(conn, &stream, sizeof(cudaStream_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&event, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaEventRecordWithFlags(cudaEvent_t event, cudaStream_t stream,
                                     unsigned int flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&event, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaEventRecordWithFlags) < 0 ||
      rpc_write(conn, &event, sizeof(cudaEvent_t)) < 0 ||
      rpc_write(conn, &stream, sizeof(cudaStream_t)) < 0 ||
      rpc_write(conn, &flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&event, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaEventQuery(cudaEvent_t event) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&event, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaEventQuery) < 0 ||
      rpc_write(conn, &event, sizeof(cudaEvent_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&event, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaEventSynchronize(cudaEvent_t event) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&event, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaEventSynchronize) < 0 ||
      rpc_write(conn, &event, sizeof(cudaEvent_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&event, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaEventDestroy(cudaEvent_t event) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&event, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaEventDestroy) < 0 ||
      rpc_write(conn, &event, sizeof(cudaEvent_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&event, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaEventElapsedTime(float *ms, cudaEvent_t start,
                                 cudaEvent_t end) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)ms, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&start, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&end, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaEventElapsedTime) < 0 ||
      rpc_write(conn, &start, sizeof(cudaEvent_t)) < 0 ||
      rpc_write(conn, &end, sizeof(cudaEvent_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, ms, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)ms, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&start, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&end, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaExternalMemoryGetMappedBuffer(
    void **devPtr, cudaExternalMemory_t extMem,
    const struct cudaExternalMemoryBufferDesc *bufferDesc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)devPtr, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&extMem, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)bufferDesc, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaExternalMemoryGetMappedBuffer) <
          0 ||
      rpc_write(conn, devPtr, sizeof(void *)) < 0 ||
      rpc_write(conn, &extMem, sizeof(cudaExternalMemory_t)) < 0 ||
      rpc_write(conn, &bufferDesc,
                sizeof(const struct cudaExternalMemoryBufferDesc *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, devPtr, sizeof(void *)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)devPtr, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&extMem, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)bufferDesc, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaExternalMemoryGetMappedMipmappedArray(
    cudaMipmappedArray_t *mipmap, cudaExternalMemory_t extMem,
    const struct cudaExternalMemoryMipmappedArrayDesc *mipmapDesc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)mipmap, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&extMem, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)mipmapDesc, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(
          conn, RPC_cudaExternalMemoryGetMappedMipmappedArray) < 0 ||
      rpc_write(conn, mipmap, sizeof(cudaMipmappedArray_t)) < 0 ||
      rpc_write(conn, &extMem, sizeof(cudaExternalMemory_t)) < 0 ||
      rpc_write(conn, &mipmapDesc,
                sizeof(const struct cudaExternalMemoryMipmappedArrayDesc *)) <
          0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, mipmap, sizeof(cudaMipmappedArray_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)mipmap, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&extMem, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)mipmapDesc, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaDestroyExternalMemory(cudaExternalMemory_t extMem) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&extMem, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaDestroyExternalMemory) < 0 ||
      rpc_write(conn, &extMem, sizeof(cudaExternalMemory_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&extMem, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaImportExternalSemaphore(
    cudaExternalSemaphore_t *extSem_out,
    const struct cudaExternalSemaphoreHandleDesc *semHandleDesc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)extSem_out, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)semHandleDesc,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaImportExternalSemaphore) < 0 ||
      rpc_write(conn, extSem_out, sizeof(cudaExternalSemaphore_t)) < 0 ||
      rpc_write(conn, &semHandleDesc,
                sizeof(const struct cudaExternalSemaphoreHandleDesc *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, extSem_out, sizeof(cudaExternalSemaphore_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)extSem_out, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)semHandleDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaSignalExternalSemaphoresAsync_v2(
    const cudaExternalSemaphore_t *extSemArray,
    const struct cudaExternalSemaphoreSignalParams *paramsArray,
    unsigned int numExtSems, cudaStream_t stream) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)extSemArray,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)paramsArray,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&numExtSems,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaSignalExternalSemaphoresAsync_v2) <
          0 ||
      rpc_write(conn, &extSemArray, sizeof(const cudaExternalSemaphore_t *)) <
          0 ||
      rpc_write(conn, &paramsArray,
                sizeof(const struct cudaExternalSemaphoreSignalParams *)) < 0 ||
      rpc_write(conn, &numExtSems, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &stream, sizeof(cudaStream_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)extSemArray,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)paramsArray,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&numExtSems,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaWaitExternalSemaphoresAsync_v2(
    const cudaExternalSemaphore_t *extSemArray,
    const struct cudaExternalSemaphoreWaitParams *paramsArray,
    unsigned int numExtSems, cudaStream_t stream) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)extSemArray,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)paramsArray,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&numExtSems,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaWaitExternalSemaphoresAsync_v2) <
          0 ||
      rpc_write(conn, &extSemArray, sizeof(const cudaExternalSemaphore_t *)) <
          0 ||
      rpc_write(conn, &paramsArray,
                sizeof(const struct cudaExternalSemaphoreWaitParams *)) < 0 ||
      rpc_write(conn, &numExtSems, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &stream, sizeof(cudaStream_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)extSemArray,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)paramsArray,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&numExtSems,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaDestroyExternalSemaphore(cudaExternalSemaphore_t extSem) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&extSem, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaDestroyExternalSemaphore) < 0 ||
      rpc_write(conn, &extSem, sizeof(cudaExternalSemaphore_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&extSem, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaLaunchKernelExC(const cudaLaunchConfig_t *config,
                                const void *func, void **args) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)config, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)func, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)args, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaLaunchKernelExC) < 0 ||
      rpc_write(conn, &config, sizeof(const cudaLaunchConfig_t *)) < 0 ||
      rpc_write(conn, &func, sizeof(const void *)) < 0 ||
      rpc_write(conn, args, sizeof(void *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, args, sizeof(void *)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)config, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)func, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)args, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaLaunchCooperativeKernel(const void *func, dim3 gridDim,
                                        dim3 blockDim, void **args,
                                        size_t sharedMem, cudaStream_t stream) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)func, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&gridDim, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&blockDim, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)args, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&sharedMem, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaLaunchCooperativeKernel) < 0 ||
      rpc_write(conn, &func, sizeof(const void *)) < 0 ||
      rpc_write(conn, &gridDim, sizeof(dim3)) < 0 ||
      rpc_write(conn, &blockDim, sizeof(dim3)) < 0 ||
      rpc_write(conn, args, sizeof(void *)) < 0 ||
      rpc_write(conn, &sharedMem, sizeof(size_t)) < 0 ||
      rpc_write(conn, &stream, sizeof(cudaStream_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, args, sizeof(void *)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)func, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&gridDim, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&blockDim, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)args, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&sharedMem, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaLaunchCooperativeKernelMultiDevice(
    struct cudaLaunchParams *launchParamsList, unsigned int numDevices,
    unsigned int flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)launchParamsList,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&numDevices,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn,
                              RPC_cudaLaunchCooperativeKernelMultiDevice) < 0 ||
      rpc_write(conn, launchParamsList, sizeof(struct cudaLaunchParams)) < 0 ||
      rpc_write(conn, &numDevices, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, launchParamsList, sizeof(struct cudaLaunchParams)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)launchParamsList,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&numDevices,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaFuncSetCacheConfig(const void *func,
                                   enum cudaFuncCache cacheConfig) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)func, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&cacheConfig,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaFuncSetCacheConfig) < 0 ||
      rpc_write(conn, &func, sizeof(const void *)) < 0 ||
      rpc_write(conn, &cacheConfig, sizeof(enum cudaFuncCache)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)func, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&cacheConfig,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaFuncSetSharedMemConfig(const void *func,
                                       enum cudaSharedMemConfig config) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)func, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&config, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaFuncSetSharedMemConfig) < 0 ||
      rpc_write(conn, &func, sizeof(const void *)) < 0 ||
      rpc_write(conn, &config, sizeof(enum cudaSharedMemConfig)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)func, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&config, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaFuncGetAttributes(struct cudaFuncAttributes *attr,
                                  const void *func) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)attr, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)func, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaFuncGetAttributes) < 0 ||
      rpc_write(conn, attr, sizeof(struct cudaFuncAttributes)) < 0 ||
      rpc_write(conn, &func, sizeof(const void *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, attr, sizeof(struct cudaFuncAttributes)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)attr, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)func, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaFuncSetAttribute(const void *func, enum cudaFuncAttribute attr,
                                 int value) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)func, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&attr, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&value, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaFuncSetAttribute) < 0 ||
      rpc_write(conn, &func, sizeof(const void *)) < 0 ||
      rpc_write(conn, &attr, sizeof(enum cudaFuncAttribute)) < 0 ||
      rpc_write(conn, &value, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)func, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&attr, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&value, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaSetDoubleForDevice(double *d) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)d, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaSetDoubleForDevice) < 0 ||
      rpc_write(conn, d, sizeof(double)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, d, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)d, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaSetDoubleForHost(double *d) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)d, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaSetDoubleForHost) < 0 ||
      rpc_write(conn, d, sizeof(double)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, d, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)d, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaOccupancyMaxActiveBlocksPerMultiprocessor(
    int *numBlocks, const void *func, int blockSize, size_t dynamicSMemSize) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)numBlocks, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)func, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&blockSize, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&dynamicSMemSize,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(
          conn, RPC_cudaOccupancyMaxActiveBlocksPerMultiprocessor) < 0 ||
      rpc_write(conn, numBlocks, sizeof(int)) < 0 ||
      rpc_write(conn, &func, sizeof(const void *)) < 0 ||
      rpc_write(conn, &blockSize, sizeof(int)) < 0 ||
      rpc_write(conn, &dynamicSMemSize, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, numBlocks, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)numBlocks, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)func, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&blockSize, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&dynamicSMemSize,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaOccupancyAvailableDynamicSMemPerBlock(size_t *dynamicSmemSize,
                                                      const void *func,
                                                      int numBlocks,
                                                      int blockSize) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)dynamicSmemSize,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)func, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&numBlocks, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&blockSize, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(
          conn, RPC_cudaOccupancyAvailableDynamicSMemPerBlock) < 0 ||
      rpc_write(conn, dynamicSmemSize, sizeof(size_t)) < 0 ||
      rpc_write(conn, &func, sizeof(const void *)) < 0 ||
      rpc_write(conn, &numBlocks, sizeof(int)) < 0 ||
      rpc_write(conn, &blockSize, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, dynamicSmemSize, sizeof(size_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)dynamicSmemSize,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)func, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&numBlocks, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&blockSize, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags(
    int *numBlocks, const void *func, int blockSize, size_t dynamicSMemSize,
    unsigned int flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)numBlocks, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)func, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&blockSize, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&dynamicSMemSize,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(
          conn, RPC_cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags) <
          0 ||
      rpc_write(conn, numBlocks, sizeof(int)) < 0 ||
      rpc_write(conn, &func, sizeof(const void *)) < 0 ||
      rpc_write(conn, &blockSize, sizeof(int)) < 0 ||
      rpc_write(conn, &dynamicSMemSize, sizeof(size_t)) < 0 ||
      rpc_write(conn, &flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, numBlocks, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)numBlocks, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)func, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&blockSize, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&dynamicSMemSize,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t
cudaOccupancyMaxPotentialClusterSize(int *clusterSize, const void *func,
                                     const cudaLaunchConfig_t *launchConfig) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)clusterSize,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)func, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)launchConfig,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaOccupancyMaxPotentialClusterSize) <
          0 ||
      rpc_write(conn, clusterSize, sizeof(int)) < 0 ||
      rpc_write(conn, &func, sizeof(const void *)) < 0 ||
      rpc_write(conn, &launchConfig, sizeof(const cudaLaunchConfig_t *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, clusterSize, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)clusterSize,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)func, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)launchConfig,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t
cudaOccupancyMaxActiveClusters(int *numClusters, const void *func,
                               const cudaLaunchConfig_t *launchConfig) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)numClusters,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)func, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)launchConfig,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaOccupancyMaxActiveClusters) < 0 ||
      rpc_write(conn, numClusters, sizeof(int)) < 0 ||
      rpc_write(conn, &func, sizeof(const void *)) < 0 ||
      rpc_write(conn, &launchConfig, sizeof(const cudaLaunchConfig_t *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, numClusters, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)numClusters,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)func, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)launchConfig,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaMalloc(void **devPtr, size_t size) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)devPtr, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&size, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaMalloc) < 0 ||
      rpc_write(conn, &size, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, devPtr, sizeof(void *)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)devPtr, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&size, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaMallocPitch(void **devPtr, size_t *pitch, size_t width,
                            size_t height) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)devPtr, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pitch, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&width, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&height, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaMallocPitch) < 0 ||
      rpc_write(conn, devPtr, sizeof(void *)) < 0 ||
      rpc_write(conn, pitch, sizeof(size_t)) < 0 ||
      rpc_write(conn, &width, sizeof(size_t)) < 0 ||
      rpc_write(conn, &height, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, devPtr, sizeof(void *)) < 0 ||
      rpc_read(conn, pitch, sizeof(size_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)devPtr, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pitch, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&width, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&height, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaMallocArray(cudaArray_t *array,
                            const struct cudaChannelFormatDesc *desc,
                            size_t width, size_t height, unsigned int flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)array, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)desc, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&width, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&height, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaMallocArray) < 0 ||
      rpc_write(conn, array, sizeof(cudaArray_t)) < 0 ||
      rpc_write(conn, &desc, sizeof(const struct cudaChannelFormatDesc *)) <
          0 ||
      rpc_write(conn, &width, sizeof(size_t)) < 0 ||
      rpc_write(conn, &height, sizeof(size_t)) < 0 ||
      rpc_write(conn, &flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, array, sizeof(cudaArray_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)array, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)desc, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&width, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&height, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaFreeHost(void *ptr) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)ptr, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaFreeHost) < 0 ||
      rpc_write(conn, &ptr, sizeof(void *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)ptr, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaFreeArray(cudaArray_t array) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&array, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaFreeArray) < 0 ||
      rpc_write(conn, &array, sizeof(cudaArray_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&array, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaFreeMipmappedArray(cudaMipmappedArray_t mipmappedArray) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&mipmappedArray,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaFreeMipmappedArray) < 0 ||
      rpc_write(conn, &mipmappedArray, sizeof(cudaMipmappedArray_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&mipmappedArray,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaHostAlloc(void **pHost, size_t size, unsigned int flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pHost, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&size, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaHostAlloc) < 0 ||
      rpc_write(conn, pHost, sizeof(void *)) < 0 ||
      rpc_write(conn, &size, sizeof(size_t)) < 0 ||
      rpc_write(conn, &flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pHost, sizeof(void *)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pHost, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&size, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaMalloc3D(struct cudaPitchedPtr *pitchedDevPtr,
                         struct cudaExtent extent) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pitchedDevPtr,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&extent, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaMalloc3D) < 0 ||
      rpc_write(conn, pitchedDevPtr, sizeof(struct cudaPitchedPtr)) < 0 ||
      rpc_write(conn, &extent, sizeof(struct cudaExtent)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pitchedDevPtr, sizeof(struct cudaPitchedPtr)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pitchedDevPtr,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&extent, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaMalloc3DArray(cudaArray_t *array,
                              const struct cudaChannelFormatDesc *desc,
                              struct cudaExtent extent, unsigned int flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)array, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)desc, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&extent, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaMalloc3DArray) < 0 ||
      rpc_write(conn, array, sizeof(cudaArray_t)) < 0 ||
      rpc_write(conn, &desc, sizeof(const struct cudaChannelFormatDesc *)) <
          0 ||
      rpc_write(conn, &extent, sizeof(struct cudaExtent)) < 0 ||
      rpc_write(conn, &flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, array, sizeof(cudaArray_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)array, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)desc, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&extent, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaMallocMipmappedArray(cudaMipmappedArray_t *mipmappedArray,
                                     const struct cudaChannelFormatDesc *desc,
                                     struct cudaExtent extent,
                                     unsigned int numLevels,
                                     unsigned int flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)mipmappedArray,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)desc, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&extent, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&numLevels, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaMallocMipmappedArray) < 0 ||
      rpc_write(conn, mipmappedArray, sizeof(cudaMipmappedArray_t)) < 0 ||
      rpc_write(conn, &desc, sizeof(const struct cudaChannelFormatDesc *)) <
          0 ||
      rpc_write(conn, &extent, sizeof(struct cudaExtent)) < 0 ||
      rpc_write(conn, &numLevels, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, mipmappedArray, sizeof(cudaMipmappedArray_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)mipmappedArray,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)desc, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&extent, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&numLevels, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t
cudaGetMipmappedArrayLevel(cudaArray_t *levelArray,
                           cudaMipmappedArray_const_t mipmappedArray,
                           unsigned int level) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)levelArray, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&mipmappedArray,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&level, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGetMipmappedArrayLevel) < 0 ||
      rpc_write(conn, levelArray, sizeof(cudaArray_t)) < 0 ||
      rpc_write(conn, &mipmappedArray, sizeof(cudaMipmappedArray_const_t)) <
          0 ||
      rpc_write(conn, &level, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, levelArray, sizeof(cudaArray_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)levelArray, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&mipmappedArray,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&level, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaMemcpy3D(const struct cudaMemcpy3DParms *p) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)p, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaMemcpy3D) < 0 ||
      rpc_write(conn, &p, sizeof(const struct cudaMemcpy3DParms *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)p, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaMemcpy3DPeer(const struct cudaMemcpy3DPeerParms *p) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)p, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaMemcpy3DPeer) < 0 ||
      rpc_write(conn, &p, sizeof(const struct cudaMemcpy3DPeerParms *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)p, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaMemcpy3DAsync(const struct cudaMemcpy3DParms *p,
                              cudaStream_t stream) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)p, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaMemcpy3DAsync) < 0 ||
      rpc_write(conn, &p, sizeof(const struct cudaMemcpy3DParms *)) < 0 ||
      rpc_write(conn, &stream, sizeof(cudaStream_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)p, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaMemcpy3DPeerAsync(const struct cudaMemcpy3DPeerParms *p,
                                  cudaStream_t stream) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)p, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaMemcpy3DPeerAsync) < 0 ||
      rpc_write(conn, &p, sizeof(const struct cudaMemcpy3DPeerParms *)) < 0 ||
      rpc_write(conn, &stream, sizeof(cudaStream_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)p, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaMemGetInfo(size_t *free, size_t *total) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)free, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)total, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaMemGetInfo) < 0 ||
      rpc_write(conn, free, sizeof(size_t)) < 0 ||
      rpc_write(conn, total, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, free, sizeof(size_t)) < 0 ||
      rpc_read(conn, total, sizeof(size_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)free, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)total, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaArrayGetInfo(struct cudaChannelFormatDesc *desc,
                             struct cudaExtent *extent, unsigned int *flags,
                             cudaArray_t array) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)desc, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)extent, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)flags, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&array, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaArrayGetInfo) < 0 ||
      rpc_write(conn, desc, sizeof(struct cudaChannelFormatDesc)) < 0 ||
      rpc_write(conn, extent, sizeof(struct cudaExtent)) < 0 ||
      rpc_write(conn, flags, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &array, sizeof(cudaArray_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, desc, sizeof(struct cudaChannelFormatDesc)) < 0 ||
      rpc_read(conn, extent, sizeof(struct cudaExtent)) < 0 ||
      rpc_read(conn, flags, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)desc, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)extent, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)flags, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&array, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaArrayGetPlane(cudaArray_t *pPlaneArray, cudaArray_t hArray,
                              unsigned int planeIdx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pPlaneArray,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hArray, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&planeIdx, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaArrayGetPlane) < 0 ||
      rpc_write(conn, pPlaneArray, sizeof(cudaArray_t)) < 0 ||
      rpc_write(conn, &hArray, sizeof(cudaArray_t)) < 0 ||
      rpc_write(conn, &planeIdx, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pPlaneArray, sizeof(cudaArray_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pPlaneArray,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hArray, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&planeIdx, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaArrayGetMemoryRequirements(
    struct cudaArrayMemoryRequirements *memoryRequirements, cudaArray_t array,
    int device) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)memoryRequirements,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&array, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaArrayGetMemoryRequirements) < 0 ||
      rpc_write(conn, memoryRequirements,
                sizeof(struct cudaArrayMemoryRequirements)) < 0 ||
      rpc_write(conn, &array, sizeof(cudaArray_t)) < 0 ||
      rpc_write(conn, &device, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, memoryRequirements,
               sizeof(struct cudaArrayMemoryRequirements)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)memoryRequirements,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&array, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaMipmappedArrayGetMemoryRequirements(
    struct cudaArrayMemoryRequirements *memoryRequirements,
    cudaMipmappedArray_t mipmap, int device) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)memoryRequirements,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&mipmap, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(
          conn, RPC_cudaMipmappedArrayGetMemoryRequirements) < 0 ||
      rpc_write(conn, memoryRequirements,
                sizeof(struct cudaArrayMemoryRequirements)) < 0 ||
      rpc_write(conn, &mipmap, sizeof(cudaMipmappedArray_t)) < 0 ||
      rpc_write(conn, &device, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, memoryRequirements,
               sizeof(struct cudaArrayMemoryRequirements)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)memoryRequirements,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&mipmap, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t
cudaArrayGetSparseProperties(struct cudaArraySparseProperties *sparseProperties,
                             cudaArray_t array) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)sparseProperties,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&array, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaArrayGetSparseProperties) < 0 ||
      rpc_write(conn, sparseProperties,
                sizeof(struct cudaArraySparseProperties)) < 0 ||
      rpc_write(conn, &array, sizeof(cudaArray_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, sparseProperties,
               sizeof(struct cudaArraySparseProperties)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)sparseProperties,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&array, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaMipmappedArrayGetSparseProperties(
    struct cudaArraySparseProperties *sparseProperties,
    cudaMipmappedArray_t mipmap) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)sparseProperties,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&mipmap, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaMipmappedArrayGetSparseProperties) <
          0 ||
      rpc_write(conn, sparseProperties,
                sizeof(struct cudaArraySparseProperties)) < 0 ||
      rpc_write(conn, &mipmap, sizeof(cudaMipmappedArray_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, sparseProperties,
               sizeof(struct cudaArraySparseProperties)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)sparseProperties,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&mipmap, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaMemcpy2DToArray(cudaArray_t dst, size_t wOffset, size_t hOffset,
                                const void *src, size_t spitch, size_t width,
                                size_t height, enum cudaMemcpyKind kind) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&dst, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&wOffset, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hOffset, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)src, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&spitch, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&width, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&height, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&kind, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaMemcpy2DToArray) < 0 ||
      rpc_write(conn, &dst, sizeof(cudaArray_t)) < 0 ||
      rpc_write(conn, &wOffset, sizeof(size_t)) < 0 ||
      rpc_write(conn, &hOffset, sizeof(size_t)) < 0 ||
      rpc_write(conn, &src, sizeof(const void *)) < 0 ||
      rpc_write(conn, &spitch, sizeof(size_t)) < 0 ||
      rpc_write(conn, &width, sizeof(size_t)) < 0 ||
      rpc_write(conn, &height, sizeof(size_t)) < 0 ||
      rpc_write(conn, &kind, sizeof(enum cudaMemcpyKind)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&dst, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&wOffset, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hOffset, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)src, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&spitch, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&width, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&height, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&kind, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaMemcpy2DArrayToArray(cudaArray_t dst, size_t wOffsetDst,
                                     size_t hOffsetDst, cudaArray_const_t src,
                                     size_t wOffsetSrc, size_t hOffsetSrc,
                                     size_t width, size_t height,
                                     enum cudaMemcpyKind kind) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&dst, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&wOffsetDst,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hOffsetDst,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&src, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&wOffsetSrc,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hOffsetSrc,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&width, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&height, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&kind, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaMemcpy2DArrayToArray) < 0 ||
      rpc_write(conn, &dst, sizeof(cudaArray_t)) < 0 ||
      rpc_write(conn, &wOffsetDst, sizeof(size_t)) < 0 ||
      rpc_write(conn, &hOffsetDst, sizeof(size_t)) < 0 ||
      rpc_write(conn, &src, sizeof(cudaArray_const_t)) < 0 ||
      rpc_write(conn, &wOffsetSrc, sizeof(size_t)) < 0 ||
      rpc_write(conn, &hOffsetSrc, sizeof(size_t)) < 0 ||
      rpc_write(conn, &width, sizeof(size_t)) < 0 ||
      rpc_write(conn, &height, sizeof(size_t)) < 0 ||
      rpc_write(conn, &kind, sizeof(enum cudaMemcpyKind)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&dst, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&wOffsetDst,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hOffsetDst,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&src, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&wOffsetSrc,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hOffsetSrc,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&width, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&height, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&kind, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaMemcpyToSymbol(const void *symbol, const void *src,
                               size_t count, size_t offset,
                               enum cudaMemcpyKind kind) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)symbol, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)src, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&offset, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&kind, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaMemcpyToSymbol) < 0 ||
      rpc_write(conn, &symbol, sizeof(const void *)) < 0 ||
      rpc_write(conn, &src, sizeof(const void *)) < 0 ||
      rpc_write(conn, &count, sizeof(size_t)) < 0 ||
      rpc_write(conn, &offset, sizeof(size_t)) < 0 ||
      rpc_write(conn, &kind, sizeof(enum cudaMemcpyKind)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)symbol, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)src, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&offset, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&kind, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaMemcpy2DToArrayAsync(cudaArray_t dst, size_t wOffset,
                                     size_t hOffset, const void *src,
                                     size_t spitch, size_t width, size_t height,
                                     enum cudaMemcpyKind kind,
                                     cudaStream_t stream) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&dst, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&wOffset, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hOffset, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)src, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&spitch, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&width, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&height, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&kind, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaMemcpy2DToArrayAsync) < 0 ||
      rpc_write(conn, &dst, sizeof(cudaArray_t)) < 0 ||
      rpc_write(conn, &wOffset, sizeof(size_t)) < 0 ||
      rpc_write(conn, &hOffset, sizeof(size_t)) < 0 ||
      rpc_write(conn, &src, sizeof(const void *)) < 0 ||
      rpc_write(conn, &spitch, sizeof(size_t)) < 0 ||
      rpc_write(conn, &width, sizeof(size_t)) < 0 ||
      rpc_write(conn, &height, sizeof(size_t)) < 0 ||
      rpc_write(conn, &kind, sizeof(enum cudaMemcpyKind)) < 0 ||
      rpc_write(conn, &stream, sizeof(cudaStream_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&dst, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&wOffset, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hOffset, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)src, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&spitch, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&width, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&height, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&kind, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaMemcpyToSymbolAsync(const void *symbol, const void *src,
                                    size_t count, size_t offset,
                                    enum cudaMemcpyKind kind,
                                    cudaStream_t stream) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)symbol, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)src, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&offset, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&kind, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaMemcpyToSymbolAsync) < 0 ||
      rpc_write(conn, &symbol, sizeof(const void *)) < 0 ||
      rpc_write(conn, &src, sizeof(const void *)) < 0 ||
      rpc_write(conn, &count, sizeof(size_t)) < 0 ||
      rpc_write(conn, &offset, sizeof(size_t)) < 0 ||
      rpc_write(conn, &kind, sizeof(enum cudaMemcpyKind)) < 0 ||
      rpc_write(conn, &stream, sizeof(cudaStream_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)symbol, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)src, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&offset, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&kind, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaMemset(void *devPtr, int value, size_t count) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)devPtr, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&value, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaMemset) < 0 ||
      rpc_write(conn, &devPtr, sizeof(void *)) < 0 ||
      rpc_write(conn, &value, sizeof(int)) < 0 ||
      rpc_write(conn, &count, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)devPtr, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&value, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaMemset2D(void *devPtr, size_t pitch, int value, size_t width,
                         size_t height) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)devPtr, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&pitch, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&value, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&width, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&height, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaMemset2D) < 0 ||
      rpc_write(conn, &devPtr, sizeof(void *)) < 0 ||
      rpc_write(conn, &pitch, sizeof(size_t)) < 0 ||
      rpc_write(conn, &value, sizeof(int)) < 0 ||
      rpc_write(conn, &width, sizeof(size_t)) < 0 ||
      rpc_write(conn, &height, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)devPtr, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&pitch, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&value, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&width, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&height, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaMemset3D(struct cudaPitchedPtr pitchedDevPtr, int value,
                         struct cudaExtent extent) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&pitchedDevPtr,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&value, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&extent, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaMemset3D) < 0 ||
      rpc_write(conn, &pitchedDevPtr, sizeof(struct cudaPitchedPtr)) < 0 ||
      rpc_write(conn, &value, sizeof(int)) < 0 ||
      rpc_write(conn, &extent, sizeof(struct cudaExtent)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&pitchedDevPtr,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&value, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&extent, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaMemsetAsync(void *devPtr, int value, size_t count,
                            cudaStream_t stream) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)devPtr, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&value, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaMemsetAsync) < 0 ||
      rpc_write(conn, &devPtr, sizeof(void *)) < 0 ||
      rpc_write(conn, &value, sizeof(int)) < 0 ||
      rpc_write(conn, &count, sizeof(size_t)) < 0 ||
      rpc_write(conn, &stream, sizeof(cudaStream_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)devPtr, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&value, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaMemset2DAsync(void *devPtr, size_t pitch, int value,
                              size_t width, size_t height,
                              cudaStream_t stream) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)devPtr, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&pitch, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&value, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&width, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&height, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaMemset2DAsync) < 0 ||
      rpc_write(conn, &devPtr, sizeof(void *)) < 0 ||
      rpc_write(conn, &pitch, sizeof(size_t)) < 0 ||
      rpc_write(conn, &value, sizeof(int)) < 0 ||
      rpc_write(conn, &width, sizeof(size_t)) < 0 ||
      rpc_write(conn, &height, sizeof(size_t)) < 0 ||
      rpc_write(conn, &stream, sizeof(cudaStream_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)devPtr, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&pitch, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&value, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&width, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&height, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaMemset3DAsync(struct cudaPitchedPtr pitchedDevPtr, int value,
                              struct cudaExtent extent, cudaStream_t stream) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&pitchedDevPtr,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&value, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&extent, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaMemset3DAsync) < 0 ||
      rpc_write(conn, &pitchedDevPtr, sizeof(struct cudaPitchedPtr)) < 0 ||
      rpc_write(conn, &value, sizeof(int)) < 0 ||
      rpc_write(conn, &extent, sizeof(struct cudaExtent)) < 0 ||
      rpc_write(conn, &stream, sizeof(cudaStream_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&pitchedDevPtr,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&value, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&extent, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGetSymbolAddress(void **devPtr, const void *symbol) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)devPtr, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)symbol, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGetSymbolAddress) < 0 ||
      rpc_write(conn, devPtr, sizeof(void *)) < 0 ||
      rpc_write(conn, &symbol, sizeof(const void *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, devPtr, sizeof(void *)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)devPtr, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)symbol, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGetSymbolSize(size_t *size, const void *symbol) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)size, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)symbol, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGetSymbolSize) < 0 ||
      rpc_write(conn, size, sizeof(size_t)) < 0 ||
      rpc_write(conn, &symbol, sizeof(const void *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, size, sizeof(size_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)size, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)symbol, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaMemPrefetchAsync(const void *devPtr, size_t count,
                                 int dstDevice, cudaStream_t stream) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)devPtr, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&dstDevice, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaMemPrefetchAsync) < 0 ||
      rpc_write(conn, &devPtr, sizeof(const void *)) < 0 ||
      rpc_write(conn, &count, sizeof(size_t)) < 0 ||
      rpc_write(conn, &dstDevice, sizeof(int)) < 0 ||
      rpc_write(conn, &stream, sizeof(cudaStream_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)devPtr, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&dstDevice, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaMemAdvise(const void *devPtr, size_t count,
                          enum cudaMemoryAdvise advice, int device) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)devPtr, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&advice, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaMemAdvise) < 0 ||
      rpc_write(conn, &devPtr, sizeof(const void *)) < 0 ||
      rpc_write(conn, &count, sizeof(size_t)) < 0 ||
      rpc_write(conn, &advice, sizeof(enum cudaMemoryAdvise)) < 0 ||
      rpc_write(conn, &device, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)devPtr, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&advice, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaMemRangeGetAttributes(void **data, size_t *dataSizes,
                                      enum cudaMemRangeAttribute *attributes,
                                      size_t numAttributes, const void *devPtr,
                                      size_t count) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)data, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)dataSizes, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)attributes, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&numAttributes,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)devPtr, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaMemRangeGetAttributes) < 0 ||
      rpc_write(conn, data, sizeof(void *)) < 0 ||
      rpc_write(conn, dataSizes, sizeof(size_t)) < 0 ||
      rpc_write(conn, attributes, sizeof(enum cudaMemRangeAttribute)) < 0 ||
      rpc_write(conn, &numAttributes, sizeof(size_t)) < 0 ||
      rpc_write(conn, &devPtr, sizeof(const void *)) < 0 ||
      rpc_write(conn, &count, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, data, sizeof(void *)) < 0 ||
      rpc_read(conn, dataSizes, sizeof(size_t)) < 0 ||
      rpc_read(conn, attributes, sizeof(enum cudaMemRangeAttribute)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)data, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)dataSizes, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)attributes, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&numAttributes,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)devPtr, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaMemcpyToArray(cudaArray_t dst, size_t wOffset, size_t hOffset,
                              const void *src, size_t count,
                              enum cudaMemcpyKind kind) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&dst, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&wOffset, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hOffset, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)src, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&kind, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaMemcpyToArray) < 0 ||
      rpc_write(conn, &dst, sizeof(cudaArray_t)) < 0 ||
      rpc_write(conn, &wOffset, sizeof(size_t)) < 0 ||
      rpc_write(conn, &hOffset, sizeof(size_t)) < 0 ||
      rpc_write(conn, &src, sizeof(const void *)) < 0 ||
      rpc_write(conn, &count, sizeof(size_t)) < 0 ||
      rpc_write(conn, &kind, sizeof(enum cudaMemcpyKind)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&dst, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&wOffset, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hOffset, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)src, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&kind, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaMemcpyArrayToArray(cudaArray_t dst, size_t wOffsetDst,
                                   size_t hOffsetDst, cudaArray_const_t src,
                                   size_t wOffsetSrc, size_t hOffsetSrc,
                                   size_t count, enum cudaMemcpyKind kind) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&dst, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&wOffsetDst,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hOffsetDst,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&src, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&wOffsetSrc,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hOffsetSrc,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&kind, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaMemcpyArrayToArray) < 0 ||
      rpc_write(conn, &dst, sizeof(cudaArray_t)) < 0 ||
      rpc_write(conn, &wOffsetDst, sizeof(size_t)) < 0 ||
      rpc_write(conn, &hOffsetDst, sizeof(size_t)) < 0 ||
      rpc_write(conn, &src, sizeof(cudaArray_const_t)) < 0 ||
      rpc_write(conn, &wOffsetSrc, sizeof(size_t)) < 0 ||
      rpc_write(conn, &hOffsetSrc, sizeof(size_t)) < 0 ||
      rpc_write(conn, &count, sizeof(size_t)) < 0 ||
      rpc_write(conn, &kind, sizeof(enum cudaMemcpyKind)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&dst, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&wOffsetDst,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hOffsetDst,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&src, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&wOffsetSrc,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hOffsetSrc,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&kind, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaMemcpyToArrayAsync(cudaArray_t dst, size_t wOffset,
                                   size_t hOffset, const void *src,
                                   size_t count, enum cudaMemcpyKind kind,
                                   cudaStream_t stream) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&dst, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&wOffset, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hOffset, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)src, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&kind, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaMemcpyToArrayAsync) < 0 ||
      rpc_write(conn, &dst, sizeof(cudaArray_t)) < 0 ||
      rpc_write(conn, &wOffset, sizeof(size_t)) < 0 ||
      rpc_write(conn, &hOffset, sizeof(size_t)) < 0 ||
      rpc_write(conn, &src, sizeof(const void *)) < 0 ||
      rpc_write(conn, &count, sizeof(size_t)) < 0 ||
      rpc_write(conn, &kind, sizeof(enum cudaMemcpyKind)) < 0 ||
      rpc_write(conn, &stream, sizeof(cudaStream_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&dst, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&wOffset, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hOffset, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)src, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&kind, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaMallocAsync(void **devPtr, size_t size, cudaStream_t hStream) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)devPtr, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&size, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaMallocAsync) < 0 ||
      rpc_write(conn, devPtr, sizeof(void *)) < 0 ||
      rpc_write(conn, &size, sizeof(size_t)) < 0 ||
      rpc_write(conn, &hStream, sizeof(cudaStream_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, devPtr, sizeof(void *)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)devPtr, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&size, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hStream, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaMemPoolTrimTo(cudaMemPool_t memPool, size_t minBytesToKeep) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&memPool, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&minBytesToKeep,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaMemPoolTrimTo) < 0 ||
      rpc_write(conn, &memPool, sizeof(cudaMemPool_t)) < 0 ||
      rpc_write(conn, &minBytesToKeep, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&memPool, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&minBytesToKeep,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaMemPoolSetAccess(cudaMemPool_t memPool,
                                 const struct cudaMemAccessDesc *descList,
                                 size_t count) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&memPool, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)descList, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaMemPoolSetAccess) < 0 ||
      rpc_write(conn, &memPool, sizeof(cudaMemPool_t)) < 0 ||
      rpc_write(conn, &descList, sizeof(const struct cudaMemAccessDesc *)) <
          0 ||
      rpc_write(conn, &count, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&memPool, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)descList, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaMemPoolGetAccess(enum cudaMemAccessFlags *flags,
                                 cudaMemPool_t memPool,
                                 struct cudaMemLocation *location) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)flags, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&memPool, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)location, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaMemPoolGetAccess) < 0 ||
      rpc_write(conn, flags, sizeof(enum cudaMemAccessFlags)) < 0 ||
      rpc_write(conn, &memPool, sizeof(cudaMemPool_t)) < 0 ||
      rpc_write(conn, location, sizeof(struct cudaMemLocation)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, flags, sizeof(enum cudaMemAccessFlags)) < 0 ||
      rpc_read(conn, location, sizeof(struct cudaMemLocation)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)flags, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&memPool, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)location, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaMemPoolCreate(cudaMemPool_t *memPool,
                              const struct cudaMemPoolProps *poolProps) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)memPool, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)poolProps, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaMemPoolCreate) < 0 ||
      rpc_write(conn, memPool, sizeof(cudaMemPool_t)) < 0 ||
      rpc_write(conn, &poolProps, sizeof(const struct cudaMemPoolProps *)) <
          0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, memPool, sizeof(cudaMemPool_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)memPool, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)poolProps, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaMemPoolDestroy(cudaMemPool_t memPool) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&memPool, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaMemPoolDestroy) < 0 ||
      rpc_write(conn, &memPool, sizeof(cudaMemPool_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&memPool, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaMallocFromPoolAsync(void **ptr, size_t size,
                                    cudaMemPool_t memPool,
                                    cudaStream_t stream) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)ptr, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&size, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&memPool, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaMallocFromPoolAsync) < 0 ||
      rpc_write(conn, ptr, sizeof(void *)) < 0 ||
      rpc_write(conn, &size, sizeof(size_t)) < 0 ||
      rpc_write(conn, &memPool, sizeof(cudaMemPool_t)) < 0 ||
      rpc_write(conn, &stream, sizeof(cudaStream_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, ptr, sizeof(void *)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)ptr, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&size, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&memPool, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t
cudaMemPoolImportPointer(void **ptr, cudaMemPool_t memPool,
                         struct cudaMemPoolPtrExportData *exportData) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)ptr, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&memPool, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)exportData, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaMemPoolImportPointer) < 0 ||
      rpc_write(conn, ptr, sizeof(void *)) < 0 ||
      rpc_write(conn, &memPool, sizeof(cudaMemPool_t)) < 0 ||
      rpc_write(conn, exportData, sizeof(struct cudaMemPoolPtrExportData)) <
          0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, ptr, sizeof(void *)) < 0 ||
      rpc_read(conn, exportData, sizeof(struct cudaMemPoolPtrExportData)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)ptr, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&memPool, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)exportData, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaPointerGetAttributes(struct cudaPointerAttributes *attributes,
                                     const void *ptr) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)attributes, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)ptr, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaPointerGetAttributes) < 0 ||
      rpc_write(conn, attributes, sizeof(struct cudaPointerAttributes)) < 0 ||
      rpc_write(conn, &ptr, sizeof(const void *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, attributes, sizeof(struct cudaPointerAttributes)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)attributes, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)ptr, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaDeviceCanAccessPeer(int *canAccessPeer, int device,
                                    int peerDevice) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)canAccessPeer,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&peerDevice,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaDeviceCanAccessPeer) < 0 ||
      rpc_write(conn, canAccessPeer, sizeof(int)) < 0 ||
      rpc_write(conn, &device, sizeof(int)) < 0 ||
      rpc_write(conn, &peerDevice, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, canAccessPeer, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)canAccessPeer,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&peerDevice,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaDeviceEnablePeerAccess(int peerDevice, unsigned int flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&peerDevice,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaDeviceEnablePeerAccess) < 0 ||
      rpc_write(conn, &peerDevice, sizeof(int)) < 0 ||
      rpc_write(conn, &flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&peerDevice,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaDeviceDisablePeerAccess(int peerDevice) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&peerDevice,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaDeviceDisablePeerAccess) < 0 ||
      rpc_write(conn, &peerDevice, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&peerDevice,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphicsUnregisterResource(cudaGraphicsResource_t resource) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&resource, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphicsUnregisterResource) < 0 ||
      rpc_write(conn, &resource, sizeof(cudaGraphicsResource_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&resource, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphicsResourceSetMapFlags(cudaGraphicsResource_t resource,
                                            unsigned int flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&resource, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphicsResourceSetMapFlags) < 0 ||
      rpc_write(conn, &resource, sizeof(cudaGraphicsResource_t)) < 0 ||
      rpc_write(conn, &flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&resource, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphicsMapResources(int count,
                                     cudaGraphicsResource_t *resources,
                                     cudaStream_t stream) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)resources, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphicsMapResources) < 0 ||
      rpc_write(conn, &count, sizeof(int)) < 0 ||
      rpc_write(conn, resources, sizeof(cudaGraphicsResource_t)) < 0 ||
      rpc_write(conn, &stream, sizeof(cudaStream_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, resources, sizeof(cudaGraphicsResource_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)resources, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphicsUnmapResources(int count,
                                       cudaGraphicsResource_t *resources,
                                       cudaStream_t stream) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)resources, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphicsUnmapResources) < 0 ||
      rpc_write(conn, &count, sizeof(int)) < 0 ||
      rpc_write(conn, resources, sizeof(cudaGraphicsResource_t)) < 0 ||
      rpc_write(conn, &stream, sizeof(cudaStream_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, resources, sizeof(cudaGraphicsResource_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)resources, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t
cudaGraphicsResourceGetMappedPointer(void **devPtr, size_t *size,
                                     cudaGraphicsResource_t resource) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)devPtr, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)size, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&resource, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphicsResourceGetMappedPointer) <
          0 ||
      rpc_write(conn, devPtr, sizeof(void *)) < 0 ||
      rpc_write(conn, size, sizeof(size_t)) < 0 ||
      rpc_write(conn, &resource, sizeof(cudaGraphicsResource_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, devPtr, sizeof(void *)) < 0 ||
      rpc_read(conn, size, sizeof(size_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)devPtr, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)size, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&resource, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphicsSubResourceGetMappedArray(
    cudaArray_t *array, cudaGraphicsResource_t resource,
    unsigned int arrayIndex, unsigned int mipLevel) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)array, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&resource, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&arrayIndex,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&mipLevel, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphicsSubResourceGetMappedArray) <
          0 ||
      rpc_write(conn, array, sizeof(cudaArray_t)) < 0 ||
      rpc_write(conn, &resource, sizeof(cudaGraphicsResource_t)) < 0 ||
      rpc_write(conn, &arrayIndex, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &mipLevel, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, array, sizeof(cudaArray_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)array, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&resource, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&arrayIndex,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&mipLevel, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphicsResourceGetMappedMipmappedArray(
    cudaMipmappedArray_t *mipmappedArray, cudaGraphicsResource_t resource) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)mipmappedArray,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&resource, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(
          conn, RPC_cudaGraphicsResourceGetMappedMipmappedArray) < 0 ||
      rpc_write(conn, mipmappedArray, sizeof(cudaMipmappedArray_t)) < 0 ||
      rpc_write(conn, &resource, sizeof(cudaGraphicsResource_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, mipmappedArray, sizeof(cudaMipmappedArray_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)mipmappedArray,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&resource, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGetChannelDesc(struct cudaChannelFormatDesc *desc,
                               cudaArray_const_t array) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)desc, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&array, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGetChannelDesc) < 0 ||
      rpc_write(conn, desc, sizeof(struct cudaChannelFormatDesc)) < 0 ||
      rpc_write(conn, &array, sizeof(cudaArray_const_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, desc, sizeof(struct cudaChannelFormatDesc)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)desc, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&array, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t
cudaCreateTextureObject(cudaTextureObject_t *pTexObject,
                        const struct cudaResourceDesc *pResDesc,
                        const struct cudaTextureDesc *pTexDesc,
                        const struct cudaResourceViewDesc *pResViewDesc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pTexObject, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pResDesc, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pTexDesc, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pResViewDesc,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaCreateTextureObject) < 0 ||
      rpc_write(conn, pTexObject, sizeof(cudaTextureObject_t)) < 0 ||
      rpc_write(conn, &pResDesc, sizeof(const struct cudaResourceDesc *)) < 0 ||
      rpc_write(conn, &pTexDesc, sizeof(const struct cudaTextureDesc *)) < 0 ||
      rpc_write(conn, &pResViewDesc,
                sizeof(const struct cudaResourceViewDesc *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pTexObject, sizeof(cudaTextureObject_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pTexObject, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pResDesc, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pTexDesc, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pResViewDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaDestroyTextureObject(cudaTextureObject_t texObject) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&texObject, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaDestroyTextureObject) < 0 ||
      rpc_write(conn, &texObject, sizeof(cudaTextureObject_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&texObject, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGetTextureObjectResourceDesc(struct cudaResourceDesc *pResDesc,
                                             cudaTextureObject_t texObject) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pResDesc, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&texObject, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGetTextureObjectResourceDesc) < 0 ||
      rpc_write(conn, pResDesc, sizeof(struct cudaResourceDesc)) < 0 ||
      rpc_write(conn, &texObject, sizeof(cudaTextureObject_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pResDesc, sizeof(struct cudaResourceDesc)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pResDesc, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&texObject, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGetTextureObjectTextureDesc(struct cudaTextureDesc *pTexDesc,
                                            cudaTextureObject_t texObject) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pTexDesc, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&texObject, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGetTextureObjectTextureDesc) < 0 ||
      rpc_write(conn, pTexDesc, sizeof(struct cudaTextureDesc)) < 0 ||
      rpc_write(conn, &texObject, sizeof(cudaTextureObject_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pTexDesc, sizeof(struct cudaTextureDesc)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pTexDesc, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&texObject, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t
cudaGetTextureObjectResourceViewDesc(struct cudaResourceViewDesc *pResViewDesc,
                                     cudaTextureObject_t texObject) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pResViewDesc,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&texObject, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGetTextureObjectResourceViewDesc) <
          0 ||
      rpc_write(conn, pResViewDesc, sizeof(struct cudaResourceViewDesc)) < 0 ||
      rpc_write(conn, &texObject, sizeof(cudaTextureObject_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pResViewDesc, sizeof(struct cudaResourceViewDesc)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pResViewDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&texObject, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaCreateSurfaceObject(cudaSurfaceObject_t *pSurfObject,
                                    const struct cudaResourceDesc *pResDesc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pSurfObject,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pResDesc, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaCreateSurfaceObject) < 0 ||
      rpc_write(conn, pSurfObject, sizeof(cudaSurfaceObject_t)) < 0 ||
      rpc_write(conn, &pResDesc, sizeof(const struct cudaResourceDesc *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pSurfObject, sizeof(cudaSurfaceObject_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pSurfObject,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pResDesc, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaDestroySurfaceObject(cudaSurfaceObject_t surfObject) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&surfObject,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaDestroySurfaceObject) < 0 ||
      rpc_write(conn, &surfObject, sizeof(cudaSurfaceObject_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&surfObject,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGetSurfaceObjectResourceDesc(struct cudaResourceDesc *pResDesc,
                                             cudaSurfaceObject_t surfObject) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pResDesc, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&surfObject,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGetSurfaceObjectResourceDesc) < 0 ||
      rpc_write(conn, pResDesc, sizeof(struct cudaResourceDesc)) < 0 ||
      rpc_write(conn, &surfObject, sizeof(cudaSurfaceObject_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pResDesc, sizeof(struct cudaResourceDesc)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pResDesc, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&surfObject,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaDriverGetVersion(int *driverVersion) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)driverVersion,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaDriverGetVersion) < 0 ||
      rpc_write(conn, driverVersion, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, driverVersion, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)driverVersion,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaRuntimeGetVersion(int *runtimeVersion) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)runtimeVersion,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaRuntimeGetVersion) < 0 ||
      rpc_write(conn, runtimeVersion, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, runtimeVersion, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)runtimeVersion,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphCreate(cudaGraph_t *pGraph, unsigned int flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pGraph, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphCreate) < 0 ||
      rpc_write(conn, pGraph, sizeof(cudaGraph_t)) < 0 ||
      rpc_write(conn, &flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pGraph, sizeof(cudaGraph_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pGraph, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t
cudaGraphKernelNodeGetParams(cudaGraphNode_t node,
                             struct cudaKernelNodeParams *pNodeParams) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&node, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pNodeParams,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphKernelNodeGetParams) < 0 ||
      rpc_write(conn, &node, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_write(conn, pNodeParams, sizeof(struct cudaKernelNodeParams)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pNodeParams, sizeof(struct cudaKernelNodeParams)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&node, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pNodeParams,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t
cudaGraphKernelNodeSetParams(cudaGraphNode_t node,
                             const struct cudaKernelNodeParams *pNodeParams) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&node, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pNodeParams,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphKernelNodeSetParams) < 0 ||
      rpc_write(conn, &node, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_write(conn, &pNodeParams,
                sizeof(const struct cudaKernelNodeParams *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&node, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pNodeParams,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphKernelNodeCopyAttributes(cudaGraphNode_t hSrc,
                                              cudaGraphNode_t hDst) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hSrc, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hDst, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphKernelNodeCopyAttributes) <
          0 ||
      rpc_write(conn, &hSrc, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_write(conn, &hDst, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hSrc, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hDst, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t
cudaGraphKernelNodeGetAttribute(cudaGraphNode_t hNode,
                                cudaLaunchAttributeID attr,
                                cudaLaunchAttributeValue *value_out) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&attr, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)value_out, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphKernelNodeGetAttribute) < 0 ||
      rpc_write(conn, &hNode, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_write(conn, &attr, sizeof(cudaLaunchAttributeID)) < 0 ||
      rpc_write(conn, value_out, sizeof(cudaLaunchAttributeValue)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, value_out, sizeof(cudaLaunchAttributeValue)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&attr, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)value_out, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t
cudaGraphKernelNodeSetAttribute(cudaGraphNode_t hNode,
                                cudaLaunchAttributeID attr,
                                const cudaLaunchAttributeValue *value) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&attr, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)value, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphKernelNodeSetAttribute) < 0 ||
      rpc_write(conn, &hNode, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_write(conn, &attr, sizeof(cudaLaunchAttributeID)) < 0 ||
      rpc_write(conn, &value, sizeof(const cudaLaunchAttributeValue *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&attr, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)value, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphAddMemcpyNodeToSymbol(cudaGraphNode_t *pGraphNode,
                                           cudaGraph_t graph,
                                           const cudaGraphNode_t *pDependencies,
                                           size_t numDependencies,
                                           const void *symbol, const void *src,
                                           size_t count, size_t offset,
                                           enum cudaMemcpyKind kind) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pGraphNode, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&graph, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pDependencies,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  for (int i = 0; i < static_cast<int>(numDependencies) &&
                  is_unified_pointer(conn, (void *)pDependencies);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&pDependencies[i],
                               cudaMemcpyHostToDevice) < 0)
      return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)symbol, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)src, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&offset, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&kind, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphAddMemcpyNodeToSymbol) < 0 ||
          rpc_write(conn, &numDependencies, sizeof(size_t)) < 0 ||
          rpc_write(conn, pGraphNode, sizeof(cudaGraphNode_t)) < 0 ||
          rpc_write(conn, &graph, sizeof(cudaGraph_t)) < 0 ||
          [=]() -> bool {
        if (numDependencies == 1) {
          if (rpc_write(0, &pDependencies, sizeof(const cudaGraphNode_t)) < 0) {
            printf("Failed to write Dependency\n");
            return false;
          }
          return true;
        }

        for (size_t i = 0; i < numDependencies; ++i) {
          if (rpc_write(0, &pDependencies[i], sizeof(const cudaGraphNode_t)) <
              0) {
            printf("Failed to write Dependency[%zu]\n", i);
            return false;
          }
        }
        return true;
      }() == false || rpc_write(conn, &symbol, sizeof(const void *)) < 0 ||
                       rpc_write(conn, &src, sizeof(const void *)) < 0 ||
                       rpc_write(conn, &count, sizeof(size_t)) < 0 ||
                       rpc_write(conn, &offset, sizeof(size_t)) < 0 ||
                       rpc_write(conn, &kind, sizeof(enum cudaMemcpyKind)) <
                           0 ||
                       rpc_wait_for_response(conn) < 0 ||
                       rpc_read(conn, pGraphNode, sizeof(cudaGraphNode_t)) <
                           0 ||
                       rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
                       rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pGraphNode, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&graph, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pDependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  for (int i = 0; i < static_cast<int>(numDependencies) &&
                  is_unified_pointer(conn, (void *)pDependencies);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&pDependencies[i],
                               cudaMemcpyDeviceToHost) < 0)
      return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)symbol, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)src, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&offset, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&kind, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t
cudaGraphMemcpyNodeGetParams(cudaGraphNode_t node,
                             struct cudaMemcpy3DParms *pNodeParams) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&node, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pNodeParams,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphMemcpyNodeGetParams) < 0 ||
      rpc_write(conn, &node, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_write(conn, pNodeParams, sizeof(struct cudaMemcpy3DParms)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pNodeParams, sizeof(struct cudaMemcpy3DParms)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&node, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pNodeParams,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t
cudaGraphMemcpyNodeSetParams(cudaGraphNode_t node,
                             const struct cudaMemcpy3DParms *pNodeParams) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&node, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pNodeParams,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphMemcpyNodeSetParams) < 0 ||
      rpc_write(conn, &node, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_write(conn, &pNodeParams, sizeof(const struct cudaMemcpy3DParms *)) <
          0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&node, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pNodeParams,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphMemcpyNodeSetParamsToSymbol(cudaGraphNode_t node,
                                                 const void *symbol,
                                                 const void *src, size_t count,
                                                 size_t offset,
                                                 enum cudaMemcpyKind kind) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&node, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)symbol, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)src, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&offset, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&kind, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphMemcpyNodeSetParamsToSymbol) <
          0 ||
      rpc_write(conn, &node, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_write(conn, &symbol, sizeof(const void *)) < 0 ||
      rpc_write(conn, &src, sizeof(const void *)) < 0 ||
      rpc_write(conn, &count, sizeof(size_t)) < 0 ||
      rpc_write(conn, &offset, sizeof(size_t)) < 0 ||
      rpc_write(conn, &kind, sizeof(enum cudaMemcpyKind)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&node, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)symbol, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)src, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&offset, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&kind, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t
cudaGraphAddMemsetNode(cudaGraphNode_t *pGraphNode, cudaGraph_t graph,
                       const cudaGraphNode_t *pDependencies,
                       size_t numDependencies,
                       const struct cudaMemsetParams *pMemsetParams) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pGraphNode, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&graph, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pDependencies,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  for (int i = 0; i < static_cast<int>(numDependencies) &&
                  is_unified_pointer(conn, (void *)pDependencies);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&pDependencies[i],
                               cudaMemcpyHostToDevice) < 0)
      return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pMemsetParams,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphAddMemsetNode) < 0 ||
          rpc_write(conn, &numDependencies, sizeof(size_t)) < 0 ||
          rpc_write(conn, &graph, sizeof(cudaGraph_t)) < 0 ||
          [=]() -> bool {
        if (numDependencies == 1) {
          if (rpc_write(0, &pDependencies, sizeof(const cudaGraphNode_t)) < 0) {
            printf("Failed to write Dependency\n");
            return false;
          }
          return true;
        }

        for (size_t i = 0; i < numDependencies; ++i) {
          if (rpc_write(0, &pDependencies[i], sizeof(const cudaGraphNode_t)) <
              0) {
            printf("Failed to write Dependency[%zu]\n", i);
            return false;
          }
        }
        return true;
      }() == false ||
                       rpc_write(conn, &pMemsetParams,
                                 sizeof(const struct cudaMemsetParams *)) < 0 ||
                       (pMemsetParams != nullptr &&
                        rpc_write(conn, pMemsetParams,
                                  sizeof(const struct cudaMemsetParams)) < 0) ||
                       rpc_wait_for_response(conn) < 0 ||
                       rpc_read(conn, pGraphNode, sizeof(cudaGraphNode_t)) <
                           0 ||
                       rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
                       rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pGraphNode, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&graph, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pDependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  for (int i = 0; i < static_cast<int>(numDependencies) &&
                  is_unified_pointer(conn, (void *)pDependencies);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&pDependencies[i],
                               cudaMemcpyDeviceToHost) < 0)
      return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pMemsetParams,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphMemsetNodeGetParams(cudaGraphNode_t node,
                                         struct cudaMemsetParams *pNodeParams) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&node, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pNodeParams,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphMemsetNodeGetParams) < 0 ||
      rpc_write(conn, &node, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_write(conn, pNodeParams, sizeof(struct cudaMemsetParams)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pNodeParams, sizeof(struct cudaMemsetParams)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&node, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pNodeParams,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t
cudaGraphMemsetNodeSetParams(cudaGraphNode_t node,
                             const struct cudaMemsetParams *pNodeParams) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&node, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pNodeParams,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphMemsetNodeSetParams) < 0 ||
      rpc_write(conn, &node, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_write(conn, &pNodeParams, sizeof(const struct cudaMemsetParams *)) <
          0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&node, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pNodeParams,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphHostNodeGetParams(cudaGraphNode_t node,
                                       struct cudaHostNodeParams *pNodeParams) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&node, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pNodeParams,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphHostNodeGetParams) < 0 ||
      rpc_write(conn, &node, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_write(conn, pNodeParams, sizeof(struct cudaHostNodeParams)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pNodeParams, sizeof(struct cudaHostNodeParams)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&node, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pNodeParams,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t
cudaGraphHostNodeSetParams(cudaGraphNode_t node,
                           const struct cudaHostNodeParams *pNodeParams) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&node, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pNodeParams,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphHostNodeSetParams) < 0 ||
      rpc_write(conn, &node, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_write(conn, &pNodeParams, sizeof(const struct cudaHostNodeParams *)) <
          0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&node, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pNodeParams,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphAddChildGraphNode(cudaGraphNode_t *pGraphNode,
                                       cudaGraph_t graph,
                                       const cudaGraphNode_t *pDependencies,
                                       size_t numDependencies,
                                       cudaGraph_t childGraph) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pGraphNode, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&graph, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pDependencies,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  for (int i = 0; i < static_cast<int>(numDependencies) &&
                  is_unified_pointer(conn, (void *)pDependencies);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&pDependencies[i],
                               cudaMemcpyHostToDevice) < 0)
      return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&childGraph,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphAddChildGraphNode) < 0 ||
          rpc_write(conn, &numDependencies, sizeof(size_t)) < 0 ||
          rpc_write(conn, pGraphNode, sizeof(cudaGraphNode_t)) < 0 ||
          rpc_write(conn, &graph, sizeof(cudaGraph_t)) < 0 ||
          [=]() -> bool {
        if (numDependencies == 1) {
          if (rpc_write(0, &pDependencies, sizeof(const cudaGraphNode_t)) < 0) {
            printf("Failed to write Dependency\n");
            return false;
          }
          return true;
        }

        for (size_t i = 0; i < numDependencies; ++i) {
          if (rpc_write(0, &pDependencies[i], sizeof(const cudaGraphNode_t)) <
              0) {
            printf("Failed to write Dependency[%zu]\n", i);
            return false;
          }
        }
        return true;
      }() == false || rpc_write(conn, &childGraph, sizeof(cudaGraph_t)) < 0 ||
                       rpc_wait_for_response(conn) < 0 ||
                       rpc_read(conn, pGraphNode, sizeof(cudaGraphNode_t)) <
                           0 ||
                       rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
                       rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pGraphNode, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&graph, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pDependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  for (int i = 0; i < static_cast<int>(numDependencies) &&
                  is_unified_pointer(conn, (void *)pDependencies);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&pDependencies[i],
                               cudaMemcpyDeviceToHost) < 0)
      return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&childGraph,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphChildGraphNodeGetGraph(cudaGraphNode_t node,
                                            cudaGraph_t *pGraph) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&node, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pGraph, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphChildGraphNodeGetGraph) < 0 ||
      rpc_write(conn, &node, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_write(conn, pGraph, sizeof(cudaGraph_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pGraph, sizeof(cudaGraph_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&node, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pGraph, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphAddEmptyNode(cudaGraphNode_t *pGraphNode,
                                  cudaGraph_t graph,
                                  const cudaGraphNode_t *pDependencies,
                                  size_t numDependencies) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pGraphNode, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&graph, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pDependencies,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  for (int i = 0; i < static_cast<int>(numDependencies) &&
                  is_unified_pointer(conn, (void *)pDependencies);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&pDependencies[i],
                               cudaMemcpyHostToDevice) < 0)
      return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphAddEmptyNode) < 0 ||
          rpc_write(conn, &numDependencies, sizeof(size_t)) < 0 ||
          rpc_write(conn, pGraphNode, sizeof(cudaGraphNode_t)) < 0 ||
          rpc_write(conn, &graph, sizeof(cudaGraph_t)) < 0 ||
          [=]() -> bool {
        if (numDependencies == 1) {
          if (rpc_write(0, &pDependencies, sizeof(const cudaGraphNode_t)) < 0) {
            printf("Failed to write Dependency\n");
            return false;
          }
          return true;
        }

        for (size_t i = 0; i < numDependencies; ++i) {
          if (rpc_write(0, &pDependencies[i], sizeof(const cudaGraphNode_t)) <
              0) {
            printf("Failed to write Dependency[%zu]\n", i);
            return false;
          }
        }
        return true;
      }() == false || rpc_wait_for_response(conn) < 0 ||
                       rpc_read(conn, pGraphNode, sizeof(cudaGraphNode_t)) <
                           0 ||
                       rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
                       rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pGraphNode, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&graph, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pDependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  for (int i = 0; i < static_cast<int>(numDependencies) &&
                  is_unified_pointer(conn, (void *)pDependencies);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&pDependencies[i],
                               cudaMemcpyDeviceToHost) < 0)
      return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphAddEventRecordNode(cudaGraphNode_t *pGraphNode,
                                        cudaGraph_t graph,
                                        const cudaGraphNode_t *pDependencies,
                                        size_t numDependencies,
                                        cudaEvent_t event) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pGraphNode, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&graph, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pDependencies,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  for (int i = 0; i < static_cast<int>(numDependencies) &&
                  is_unified_pointer(conn, (void *)pDependencies);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&pDependencies[i],
                               cudaMemcpyHostToDevice) < 0)
      return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&event, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphAddEventRecordNode) < 0 ||
          rpc_write(conn, &numDependencies, sizeof(size_t)) < 0 ||
          rpc_write(conn, pGraphNode, sizeof(cudaGraphNode_t)) < 0 ||
          rpc_write(conn, &graph, sizeof(cudaGraph_t)) < 0 ||
          [=]() -> bool {
        if (numDependencies == 1) {
          if (rpc_write(0, &pDependencies, sizeof(const cudaGraphNode_t)) < 0) {
            printf("Failed to write Dependency\n");
            return false;
          }
          return true;
        }

        for (size_t i = 0; i < numDependencies; ++i) {
          if (rpc_write(0, &pDependencies[i], sizeof(const cudaGraphNode_t)) <
              0) {
            printf("Failed to write Dependency[%zu]\n", i);
            return false;
          }
        }
        return true;
      }() == false || rpc_write(conn, &event, sizeof(cudaEvent_t)) < 0 ||
                       rpc_wait_for_response(conn) < 0 ||
                       rpc_read(conn, pGraphNode, sizeof(cudaGraphNode_t)) <
                           0 ||
                       rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
                       rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pGraphNode, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&graph, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pDependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  for (int i = 0; i < static_cast<int>(numDependencies) &&
                  is_unified_pointer(conn, (void *)pDependencies);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&pDependencies[i],
                               cudaMemcpyDeviceToHost) < 0)
      return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&event, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphEventRecordNodeGetEvent(cudaGraphNode_t node,
                                             cudaEvent_t *event_out) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&node, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)event_out, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphEventRecordNodeGetEvent) < 0 ||
      rpc_write(conn, &node, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_write(conn, event_out, sizeof(cudaEvent_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, event_out, sizeof(cudaEvent_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&node, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)event_out, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphEventRecordNodeSetEvent(cudaGraphNode_t node,
                                             cudaEvent_t event) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&node, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&event, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphEventRecordNodeSetEvent) < 0 ||
      rpc_write(conn, &node, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_write(conn, &event, sizeof(cudaEvent_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&node, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&event, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphAddEventWaitNode(cudaGraphNode_t *pGraphNode,
                                      cudaGraph_t graph,
                                      const cudaGraphNode_t *pDependencies,
                                      size_t numDependencies,
                                      cudaEvent_t event) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pGraphNode, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&graph, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pDependencies,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  for (int i = 0; i < static_cast<int>(numDependencies) &&
                  is_unified_pointer(conn, (void *)pDependencies);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&pDependencies[i],
                               cudaMemcpyHostToDevice) < 0)
      return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&event, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphAddEventWaitNode) < 0 ||
          rpc_write(conn, &numDependencies, sizeof(size_t)) < 0 ||
          rpc_write(conn, pGraphNode, sizeof(cudaGraphNode_t)) < 0 ||
          rpc_write(conn, &graph, sizeof(cudaGraph_t)) < 0 ||
          [=]() -> bool {
        if (numDependencies == 1) {
          if (rpc_write(0, &pDependencies, sizeof(const cudaGraphNode_t)) < 0) {
            printf("Failed to write Dependency\n");
            return false;
          }
          return true;
        }

        for (size_t i = 0; i < numDependencies; ++i) {
          if (rpc_write(0, &pDependencies[i], sizeof(const cudaGraphNode_t)) <
              0) {
            printf("Failed to write Dependency[%zu]\n", i);
            return false;
          }
        }
        return true;
      }() == false || rpc_write(conn, &event, sizeof(cudaEvent_t)) < 0 ||
                       rpc_wait_for_response(conn) < 0 ||
                       rpc_read(conn, pGraphNode, sizeof(cudaGraphNode_t)) <
                           0 ||
                       rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
                       rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pGraphNode, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&graph, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pDependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  for (int i = 0; i < static_cast<int>(numDependencies) &&
                  is_unified_pointer(conn, (void *)pDependencies);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&pDependencies[i],
                               cudaMemcpyDeviceToHost) < 0)
      return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&event, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphEventWaitNodeGetEvent(cudaGraphNode_t node,
                                           cudaEvent_t *event_out) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&node, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)event_out, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphEventWaitNodeGetEvent) < 0 ||
      rpc_write(conn, &node, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_write(conn, event_out, sizeof(cudaEvent_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, event_out, sizeof(cudaEvent_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&node, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)event_out, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphEventWaitNodeSetEvent(cudaGraphNode_t node,
                                           cudaEvent_t event) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&node, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&event, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphEventWaitNodeSetEvent) < 0 ||
      rpc_write(conn, &node, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_write(conn, &event, sizeof(cudaEvent_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&node, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&event, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphAddExternalSemaphoresSignalNode(
    cudaGraphNode_t *pGraphNode, cudaGraph_t graph,
    const cudaGraphNode_t *pDependencies, size_t numDependencies,
    const struct cudaExternalSemaphoreSignalNodeParams *nodeParams) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pGraphNode, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&graph, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pDependencies,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  for (int i = 0; i < static_cast<int>(numDependencies) &&
                  is_unified_pointer(conn, (void *)pDependencies);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&pDependencies[i],
                               cudaMemcpyHostToDevice) < 0)
      return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(
          conn, RPC_cudaGraphAddExternalSemaphoresSignalNode) < 0 ||
          rpc_write(conn, &numDependencies, sizeof(size_t)) < 0 ||
          rpc_write(conn, pGraphNode, sizeof(cudaGraphNode_t)) < 0 ||
          rpc_write(conn, &graph, sizeof(cudaGraph_t)) < 0 || [=]()
          -> bool {
        if (numDependencies == 1) {
          if (rpc_write(0, &pDependencies, sizeof(const cudaGraphNode_t)) < 0) {
            printf("Failed to write Dependency\n");
            return false;
          }
          return true;
        }

        for (size_t i = 0; i < numDependencies; ++i) {
          if (rpc_write(0, &pDependencies[i], sizeof(const cudaGraphNode_t)) <
              0) {
            printf("Failed to write Dependency[%zu]\n", i);
            return false;
          }
        }
        return true;
      }() == false ||
                 rpc_write(
                     conn, &nodeParams,
                     sizeof(const struct cudaExternalSemaphoreSignalNodeParams
                                *)) < 0 ||
                 (nodeParams != nullptr &&
                  rpc_write(
                      conn, nodeParams,
                      sizeof(
                          const struct cudaExternalSemaphoreSignalNodeParams)) <
                      0) ||
                 rpc_wait_for_response(conn) < 0 ||
                 rpc_read(conn, pGraphNode, sizeof(cudaGraphNode_t)) < 0 ||
                 rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
                 rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pGraphNode, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&graph, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pDependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  for (int i = 0; i < static_cast<int>(numDependencies) &&
                  is_unified_pointer(conn, (void *)pDependencies);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&pDependencies[i],
                               cudaMemcpyDeviceToHost) < 0)
      return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphExternalSemaphoresSignalNodeGetParams(
    cudaGraphNode_t hNode,
    struct cudaExternalSemaphoreSignalNodeParams *params_out) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)params_out, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(
          conn, RPC_cudaGraphExternalSemaphoresSignalNodeGetParams) < 0 ||
      rpc_write(conn, &hNode, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_write(conn, params_out,
                sizeof(struct cudaExternalSemaphoreSignalNodeParams)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, params_out,
               sizeof(struct cudaExternalSemaphoreSignalNodeParams)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)params_out, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphExternalSemaphoresSignalNodeSetParams(
    cudaGraphNode_t hNode,
    const struct cudaExternalSemaphoreSignalNodeParams *nodeParams) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(
          conn, RPC_cudaGraphExternalSemaphoresSignalNodeSetParams) < 0 ||
      rpc_write(conn, &hNode, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_write(conn, &nodeParams,
                sizeof(const struct cudaExternalSemaphoreSignalNodeParams *)) <
          0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphAddExternalSemaphoresWaitNode(
    cudaGraphNode_t *pGraphNode, cudaGraph_t graph,
    const cudaGraphNode_t *pDependencies, size_t numDependencies,
    const struct cudaExternalSemaphoreWaitNodeParams *nodeParams) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pGraphNode, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&graph, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pDependencies,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  for (int i = 0; i < static_cast<int>(numDependencies) &&
                  is_unified_pointer(conn, (void *)pDependencies);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&pDependencies[i],
                               cudaMemcpyHostToDevice) < 0)
      return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn,
                              RPC_cudaGraphAddExternalSemaphoresWaitNode) < 0 ||
          rpc_write(conn, &numDependencies, sizeof(size_t)) < 0 ||
          rpc_write(conn, pGraphNode, sizeof(cudaGraphNode_t)) < 0 ||
          rpc_write(conn, &graph, sizeof(cudaGraph_t)) < 0 || [=]()
          -> bool {
        if (numDependencies == 1) {
          if (rpc_write(0, &pDependencies, sizeof(const cudaGraphNode_t)) < 0) {
            printf("Failed to write Dependency\n");
            return false;
          }
          return true;
        }

        for (size_t i = 0; i < numDependencies; ++i) {
          if (rpc_write(0, &pDependencies[i], sizeof(const cudaGraphNode_t)) <
              0) {
            printf("Failed to write Dependency[%zu]\n", i);
            return false;
          }
        }
        return true;
      }() == false ||
                 rpc_write(
                     conn, &nodeParams,
                     sizeof(
                         const struct cudaExternalSemaphoreWaitNodeParams *)) <
                     0 ||
                 (nodeParams != nullptr &&
                  rpc_write(
                      conn, nodeParams,
                      sizeof(
                          const struct cudaExternalSemaphoreWaitNodeParams)) <
                      0) ||
                 rpc_wait_for_response(conn) < 0 ||
                 rpc_read(conn, pGraphNode, sizeof(cudaGraphNode_t)) < 0 ||
                 rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
                 rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pGraphNode, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&graph, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pDependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  for (int i = 0; i < static_cast<int>(numDependencies) &&
                  is_unified_pointer(conn, (void *)pDependencies);
       i++)
    if (maybe_copy_unified_arg(conn, (void *)&pDependencies[i],
                               cudaMemcpyDeviceToHost) < 0)
      return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphExternalSemaphoresWaitNodeGetParams(
    cudaGraphNode_t hNode,
    struct cudaExternalSemaphoreWaitNodeParams *params_out) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)params_out, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(
          conn, RPC_cudaGraphExternalSemaphoresWaitNodeGetParams) < 0 ||
      rpc_write(conn, &hNode, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_write(conn, params_out,
                sizeof(struct cudaExternalSemaphoreWaitNodeParams)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, params_out,
               sizeof(struct cudaExternalSemaphoreWaitNodeParams)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)params_out, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphExternalSemaphoresWaitNodeSetParams(
    cudaGraphNode_t hNode,
    const struct cudaExternalSemaphoreWaitNodeParams *nodeParams) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(
          conn, RPC_cudaGraphExternalSemaphoresWaitNodeSetParams) < 0 ||
      rpc_write(conn, &hNode, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_write(conn, &nodeParams,
                sizeof(const struct cudaExternalSemaphoreWaitNodeParams *)) <
          0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t
cudaGraphMemAllocNodeGetParams(cudaGraphNode_t node,
                               struct cudaMemAllocNodeParams *params_out) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&node, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)params_out, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphMemAllocNodeGetParams) < 0 ||
      rpc_write(conn, &node, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_write(conn, params_out, sizeof(struct cudaMemAllocNodeParams)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, params_out, sizeof(struct cudaMemAllocNodeParams)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&node, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)params_out, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaDeviceGraphMemTrim(int device) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaDeviceGraphMemTrim) < 0 ||
      rpc_write(conn, &device, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&device, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphClone(cudaGraph_t *pGraphClone,
                           cudaGraph_t originalGraph) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pGraphClone,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&originalGraph,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphClone) < 0 ||
      rpc_write(conn, pGraphClone, sizeof(cudaGraph_t)) < 0 ||
      rpc_write(conn, &originalGraph, sizeof(cudaGraph_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pGraphClone, sizeof(cudaGraph_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pGraphClone,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&originalGraph,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphNodeFindInClone(cudaGraphNode_t *pNode,
                                     cudaGraphNode_t originalNode,
                                     cudaGraph_t clonedGraph) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pNode, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&originalNode,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&clonedGraph,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphNodeFindInClone) < 0 ||
      rpc_write(conn, pNode, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_write(conn, &originalNode, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_write(conn, &clonedGraph, sizeof(cudaGraph_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pNode, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pNode, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&originalNode,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&clonedGraph,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphNodeGetType(cudaGraphNode_t node,
                                 enum cudaGraphNodeType *pType) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&node, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pType, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphNodeGetType) < 0 ||
      rpc_write(conn, &node, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_write(conn, pType, sizeof(enum cudaGraphNodeType)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pType, sizeof(enum cudaGraphNodeType)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&node, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pType, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphGetRootNodes(cudaGraph_t graph,
                                  cudaGraphNode_t *pRootNodes,
                                  size_t *pNumRootNodes) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&graph, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pRootNodes, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pNumRootNodes,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphGetRootNodes) < 0 ||
      rpc_write(conn, &graph, sizeof(cudaGraph_t)) < 0 ||
      rpc_write(conn, pRootNodes, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_write(conn, pNumRootNodes, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pRootNodes, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_read(conn, pNumRootNodes, sizeof(size_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&graph, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pRootNodes, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pNumRootNodes,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphGetEdges(cudaGraph_t graph, cudaGraphNode_t *from,
                              cudaGraphNode_t *to, size_t *numEdges) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&graph, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)from, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)to, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)numEdges, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphGetEdges) < 0 ||
      rpc_write(conn, &graph, sizeof(cudaGraph_t)) < 0 ||
      rpc_write(conn, from, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_write(conn, to, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_write(conn, numEdges, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, from, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_read(conn, to, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_read(conn, numEdges, sizeof(size_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&graph, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)from, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)to, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)numEdges, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphNodeGetDependencies(cudaGraphNode_t node,
                                         cudaGraphNode_t *pDependencies,
                                         size_t *pNumDependencies) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&node, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pDependencies,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pNumDependencies,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphNodeGetDependencies) < 0 ||
      rpc_write(conn, &node, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_write(conn, pDependencies, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_write(conn, pNumDependencies, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pDependencies, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_read(conn, pNumDependencies, sizeof(size_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&node, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pDependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pNumDependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphNodeGetDependentNodes(cudaGraphNode_t node,
                                           cudaGraphNode_t *pDependentNodes,
                                           size_t *pNumDependentNodes) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&node, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pDependentNodes,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pNumDependentNodes,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphNodeGetDependentNodes) < 0 ||
      rpc_write(conn, &node, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_write(conn, pDependentNodes, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_write(conn, pNumDependentNodes, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pDependentNodes, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_read(conn, pNumDependentNodes, sizeof(size_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&node, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pDependentNodes,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pNumDependentNodes,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphAddDependencies(cudaGraph_t graph,
                                     const cudaGraphNode_t *from,
                                     const cudaGraphNode_t *to,
                                     size_t numDependencies) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&graph, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)from, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)to, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphAddDependencies) < 0 ||
      rpc_write(conn, &graph, sizeof(cudaGraph_t)) < 0 ||
      rpc_write(conn, &from, sizeof(const cudaGraphNode_t *)) < 0 ||
      rpc_write(conn, &to, sizeof(const cudaGraphNode_t *)) < 0 ||
      rpc_write(conn, &numDependencies, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&graph, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)from, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)to, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphRemoveDependencies(cudaGraph_t graph,
                                        const cudaGraphNode_t *from,
                                        const cudaGraphNode_t *to,
                                        size_t numDependencies) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&graph, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)from, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)to, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphRemoveDependencies) < 0 ||
      rpc_write(conn, &graph, sizeof(cudaGraph_t)) < 0 ||
      rpc_write(conn, &from, sizeof(const cudaGraphNode_t *)) < 0 ||
      rpc_write(conn, &to, sizeof(const cudaGraphNode_t *)) < 0 ||
      rpc_write(conn, &numDependencies, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&graph, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)from, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)to, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&numDependencies,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphDestroyNode(cudaGraphNode_t node) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&node, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphDestroyNode) < 0 ||
      rpc_write(conn, &node, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&node, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphInstantiate(cudaGraphExec_t *pGraphExec, cudaGraph_t graph,
                                 unsigned long long flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pGraphExec, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&graph, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphInstantiate) < 0 ||
      rpc_write(conn, pGraphExec, sizeof(cudaGraphExec_t)) < 0 ||
      rpc_write(conn, &graph, sizeof(cudaGraph_t)) < 0 ||
      rpc_write(conn, &flags, sizeof(unsigned long long)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pGraphExec, sizeof(cudaGraphExec_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pGraphExec, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&graph, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphInstantiateWithFlags(cudaGraphExec_t *pGraphExec,
                                          cudaGraph_t graph,
                                          unsigned long long flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pGraphExec, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&graph, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphInstantiateWithFlags) < 0 ||
      rpc_write(conn, pGraphExec, sizeof(cudaGraphExec_t)) < 0 ||
      rpc_write(conn, &graph, sizeof(cudaGraph_t)) < 0 ||
      rpc_write(conn, &flags, sizeof(unsigned long long)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pGraphExec, sizeof(cudaGraphExec_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pGraphExec, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&graph, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t
cudaGraphInstantiateWithParams(cudaGraphExec_t *pGraphExec, cudaGraph_t graph,
                               cudaGraphInstantiateParams *instantiateParams) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)pGraphExec, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&graph, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)instantiateParams,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphInstantiateWithParams) < 0 ||
      rpc_write(conn, pGraphExec, sizeof(cudaGraphExec_t)) < 0 ||
      rpc_write(conn, &graph, sizeof(cudaGraph_t)) < 0 ||
      rpc_write(conn, instantiateParams, sizeof(cudaGraphInstantiateParams)) <
          0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, pGraphExec, sizeof(cudaGraphExec_t)) < 0 ||
      rpc_read(conn, instantiateParams, sizeof(cudaGraphInstantiateParams)) <
          0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pGraphExec, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&graph, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)instantiateParams,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphExecGetFlags(cudaGraphExec_t graphExec,
                                  unsigned long long *flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&graphExec, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)flags, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphExecGetFlags) < 0 ||
      rpc_write(conn, &graphExec, sizeof(cudaGraphExec_t)) < 0 ||
      rpc_write(conn, flags, sizeof(unsigned long long)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, flags, sizeof(unsigned long long)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&graphExec, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)flags, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphExecKernelNodeSetParams(
    cudaGraphExec_t hGraphExec, cudaGraphNode_t node,
    const struct cudaKernelNodeParams *pNodeParams) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&node, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pNodeParams,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphExecKernelNodeSetParams) < 0 ||
      rpc_write(conn, &hGraphExec, sizeof(cudaGraphExec_t)) < 0 ||
      rpc_write(conn, &node, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_write(conn, &pNodeParams,
                sizeof(const struct cudaKernelNodeParams *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&node, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pNodeParams,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t
cudaGraphExecMemcpyNodeSetParams(cudaGraphExec_t hGraphExec,
                                 cudaGraphNode_t node,
                                 const struct cudaMemcpy3DParms *pNodeParams) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&node, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pNodeParams,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphExecMemcpyNodeSetParams) < 0 ||
      rpc_write(conn, &hGraphExec, sizeof(cudaGraphExec_t)) < 0 ||
      rpc_write(conn, &node, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_write(conn, &pNodeParams, sizeof(const struct cudaMemcpy3DParms *)) <
          0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&node, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pNodeParams,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphExecMemcpyNodeSetParamsToSymbol(
    cudaGraphExec_t hGraphExec, cudaGraphNode_t node, const void *symbol,
    const void *src, size_t count, size_t offset, enum cudaMemcpyKind kind) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&node, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)symbol, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)src, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&offset, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&kind, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(
          conn, RPC_cudaGraphExecMemcpyNodeSetParamsToSymbol) < 0 ||
      rpc_write(conn, &hGraphExec, sizeof(cudaGraphExec_t)) < 0 ||
      rpc_write(conn, &node, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_write(conn, &symbol, sizeof(const void *)) < 0 ||
      rpc_write(conn, &src, sizeof(const void *)) < 0 ||
      rpc_write(conn, &count, sizeof(size_t)) < 0 ||
      rpc_write(conn, &offset, sizeof(size_t)) < 0 ||
      rpc_write(conn, &kind, sizeof(enum cudaMemcpyKind)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&node, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)symbol, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)src, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&offset, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&kind, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t
cudaGraphExecMemsetNodeSetParams(cudaGraphExec_t hGraphExec,
                                 cudaGraphNode_t node,
                                 const struct cudaMemsetParams *pNodeParams) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&node, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pNodeParams,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphExecMemsetNodeSetParams) < 0 ||
      rpc_write(conn, &hGraphExec, sizeof(cudaGraphExec_t)) < 0 ||
      rpc_write(conn, &node, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_write(conn, &pNodeParams, sizeof(const struct cudaMemsetParams *)) <
          0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&node, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pNodeParams,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t
cudaGraphExecHostNodeSetParams(cudaGraphExec_t hGraphExec, cudaGraphNode_t node,
                               const struct cudaHostNodeParams *pNodeParams) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&node, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pNodeParams,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphExecHostNodeSetParams) < 0 ||
      rpc_write(conn, &hGraphExec, sizeof(cudaGraphExec_t)) < 0 ||
      rpc_write(conn, &node, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_write(conn, &pNodeParams, sizeof(const struct cudaHostNodeParams *)) <
          0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&node, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pNodeParams,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphExecChildGraphNodeSetParams(cudaGraphExec_t hGraphExec,
                                                 cudaGraphNode_t node,
                                                 cudaGraph_t childGraph) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&node, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&childGraph,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphExecChildGraphNodeSetParams) <
          0 ||
      rpc_write(conn, &hGraphExec, sizeof(cudaGraphExec_t)) < 0 ||
      rpc_write(conn, &node, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_write(conn, &childGraph, sizeof(cudaGraph_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&node, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&childGraph,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphExecEventRecordNodeSetEvent(cudaGraphExec_t hGraphExec,
                                                 cudaGraphNode_t hNode,
                                                 cudaEvent_t event) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&event, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphExecEventRecordNodeSetEvent) <
          0 ||
      rpc_write(conn, &hGraphExec, sizeof(cudaGraphExec_t)) < 0 ||
      rpc_write(conn, &hNode, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_write(conn, &event, sizeof(cudaEvent_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&event, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphExecEventWaitNodeSetEvent(cudaGraphExec_t hGraphExec,
                                               cudaGraphNode_t hNode,
                                               cudaEvent_t event) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&event, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphExecEventWaitNodeSetEvent) <
          0 ||
      rpc_write(conn, &hGraphExec, sizeof(cudaGraphExec_t)) < 0 ||
      rpc_write(conn, &hNode, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_write(conn, &event, sizeof(cudaEvent_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&event, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphExecExternalSemaphoresSignalNodeSetParams(
    cudaGraphExec_t hGraphExec, cudaGraphNode_t hNode,
    const struct cudaExternalSemaphoreSignalNodeParams *nodeParams) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(
          conn, RPC_cudaGraphExecExternalSemaphoresSignalNodeSetParams) < 0 ||
      rpc_write(conn, &hGraphExec, sizeof(cudaGraphExec_t)) < 0 ||
      rpc_write(conn, &hNode, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_write(conn, &nodeParams,
                sizeof(const struct cudaExternalSemaphoreSignalNodeParams *)) <
          0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphExecExternalSemaphoresWaitNodeSetParams(
    cudaGraphExec_t hGraphExec, cudaGraphNode_t hNode,
    const struct cudaExternalSemaphoreWaitNodeParams *nodeParams) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(
          conn, RPC_cudaGraphExecExternalSemaphoresWaitNodeSetParams) < 0 ||
      rpc_write(conn, &hGraphExec, sizeof(cudaGraphExec_t)) < 0 ||
      rpc_write(conn, &hNode, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_write(conn, &nodeParams,
                sizeof(const struct cudaExternalSemaphoreWaitNodeParams *)) <
          0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)nodeParams, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphNodeSetEnabled(cudaGraphExec_t hGraphExec,
                                    cudaGraphNode_t hNode,
                                    unsigned int isEnabled) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&isEnabled, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphNodeSetEnabled) < 0 ||
      rpc_write(conn, &hGraphExec, sizeof(cudaGraphExec_t)) < 0 ||
      rpc_write(conn, &hNode, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_write(conn, &isEnabled, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&isEnabled, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphNodeGetEnabled(cudaGraphExec_t hGraphExec,
                                    cudaGraphNode_t hNode,
                                    unsigned int *isEnabled) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)isEnabled, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphNodeGetEnabled) < 0 ||
      rpc_write(conn, &hGraphExec, sizeof(cudaGraphExec_t)) < 0 ||
      rpc_write(conn, &hNode, sizeof(cudaGraphNode_t)) < 0 ||
      rpc_write(conn, isEnabled, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, isEnabled, sizeof(unsigned int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hNode, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)isEnabled, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphExecUpdate(cudaGraphExec_t hGraphExec, cudaGraph_t hGraph,
                                cudaGraphExecUpdateResultInfo *resultInfo) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hGraph, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)resultInfo, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphExecUpdate) < 0 ||
      rpc_write(conn, &hGraphExec, sizeof(cudaGraphExec_t)) < 0 ||
      rpc_write(conn, &hGraph, sizeof(cudaGraph_t)) < 0 ||
      rpc_write(conn, resultInfo, sizeof(cudaGraphExecUpdateResultInfo)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, resultInfo, sizeof(cudaGraphExecUpdateResultInfo)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hGraphExec,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&hGraph, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)resultInfo, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphUpload(cudaGraphExec_t graphExec, cudaStream_t stream) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&graphExec, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphUpload) < 0 ||
      rpc_write(conn, &graphExec, sizeof(cudaGraphExec_t)) < 0 ||
      rpc_write(conn, &stream, sizeof(cudaStream_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&graphExec, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphLaunch(cudaGraphExec_t graphExec, cudaStream_t stream) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&graphExec, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphLaunch) < 0 ||
      rpc_write(conn, &graphExec, sizeof(cudaGraphExec_t)) < 0 ||
      rpc_write(conn, &stream, sizeof(cudaStream_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&graphExec, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&stream, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphExecDestroy(cudaGraphExec_t graphExec) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&graphExec, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphExecDestroy) < 0 ||
      rpc_write(conn, &graphExec, sizeof(cudaGraphExec_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&graphExec, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphDebugDotPrint(cudaGraph_t graph, const char *path,
                                   unsigned int flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&graph, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)path, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphDebugDotPrint) < 0 ||
      rpc_write(conn, &graph, sizeof(cudaGraph_t)) < 0 ||
      rpc_write(conn, &path, sizeof(const char *)) < 0 ||
      rpc_write(conn, &flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&graph, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)path, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaUserObjectRetain(cudaUserObject_t object, unsigned int count) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&object, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaUserObjectRetain) < 0 ||
      rpc_write(conn, &object, sizeof(cudaUserObject_t)) < 0 ||
      rpc_write(conn, &count, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&object, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaUserObjectRelease(cudaUserObject_t object, unsigned int count) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&object, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaUserObjectRelease) < 0 ||
      rpc_write(conn, &object, sizeof(cudaUserObject_t)) < 0 ||
      rpc_write(conn, &count, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&object, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphRetainUserObject(cudaGraph_t graph,
                                      cudaUserObject_t object,
                                      unsigned int count, unsigned int flags) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&graph, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&object, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphRetainUserObject) < 0 ||
      rpc_write(conn, &graph, sizeof(cudaGraph_t)) < 0 ||
      rpc_write(conn, &object, sizeof(cudaUserObject_t)) < 0 ||
      rpc_write(conn, &count, sizeof(unsigned int)) < 0 ||
      rpc_write(conn, &flags, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&graph, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&object, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGraphReleaseUserObject(cudaGraph_t graph,
                                       cudaUserObject_t object,
                                       unsigned int count) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&graph, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&object, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGraphReleaseUserObject) < 0 ||
      rpc_write(conn, &graph, sizeof(cudaGraph_t)) < 0 ||
      rpc_write(conn, &object, sizeof(cudaUserObject_t)) < 0 ||
      rpc_write(conn, &count, sizeof(unsigned int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&graph, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&object, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&count, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t
cudaGetDriverEntryPoint(const char *symbol, void **funcPtr,
                        unsigned long long flags,
                        enum cudaDriverEntryPointQueryResult *driverStatus) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)symbol, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)funcPtr, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)driverStatus,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGetDriverEntryPoint) < 0 ||
      rpc_write(conn, &symbol, sizeof(const char *)) < 0 ||
      rpc_write(conn, funcPtr, sizeof(void *)) < 0 ||
      rpc_write(conn, &flags, sizeof(unsigned long long)) < 0 ||
      rpc_write(conn, driverStatus,
                sizeof(enum cudaDriverEntryPointQueryResult)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, funcPtr, sizeof(void *)) < 0 ||
      rpc_read(conn, driverStatus,
               sizeof(enum cudaDriverEntryPointQueryResult)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)symbol, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)funcPtr, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)&flags, cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)driverStatus,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGetExportTable(const void **ppExportTable,
                               const cudaUUID_t *pExportTableId) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)ppExportTable,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pExportTableId,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGetExportTable) < 0 ||
      rpc_write(conn, ppExportTable, sizeof(const void *)) < 0 ||
      rpc_write(conn, &pExportTableId, sizeof(const cudaUUID_t *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, ppExportTable, sizeof(const void *)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)ppExportTable,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)pExportTableId,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cudaError_t cudaGetFuncBySymbol(cudaFunction_t *functionPtr,
                                const void *symbolPtr) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)functionPtr,
                             cudaMemcpyHostToDevice) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)symbolPtr, cudaMemcpyHostToDevice) <
      0)
    return cudaErrorDevicesUnavailable;
  cudaError_t return_value;
  if (rpc_write_start_request(conn, RPC_cudaGetFuncBySymbol) < 0 ||
      rpc_write(conn, functionPtr, sizeof(cudaFunction_t)) < 0 ||
      rpc_write(conn, &symbolPtr, sizeof(const void *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, functionPtr, sizeof(cudaFunction_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudaError_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)functionPtr,
                             cudaMemcpyDeviceToHost) < 0)
    return cudaErrorDevicesUnavailable;
  if (maybe_copy_unified_arg(conn, (void *)symbolPtr, cudaMemcpyDeviceToHost) <
      0)
    return cudaErrorDevicesUnavailable;
  return return_value;
}

cublasStatus_t cublasCreate_v2(cublasHandle_t *handle) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCreate_v2) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDestroy_v2(cublasHandle_t handle) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDestroy_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasGetVersion_v2(cublasHandle_t handle, int *version) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)version, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasGetVersion_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, version, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, version, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)version, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasGetProperty(libraryPropertyType type, int *value) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&type, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)value, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasGetProperty) < 0 ||
      rpc_write(conn, &type, sizeof(libraryPropertyType)) < 0 ||
      rpc_write(conn, value, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, value, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&type, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)value, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSetStream_v2(cublasHandle_t handle,
                                  cudaStream_t streamId) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&streamId, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSetStream_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &streamId, sizeof(cudaStream_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&streamId, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasGetStream_v2(cublasHandle_t handle,
                                  cudaStream_t *streamId) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)streamId, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasGetStream_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, streamId, sizeof(cudaStream_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, streamId, sizeof(cudaStream_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)streamId, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasGetPointerMode_v2(cublasHandle_t handle,
                                       cublasPointerMode_t *mode) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)mode, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasGetPointerMode_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, mode, sizeof(cublasPointerMode_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, mode, sizeof(cublasPointerMode_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)mode, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSetPointerMode_v2(cublasHandle_t handle,
                                       cublasPointerMode_t mode) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSetPointerMode_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &mode, sizeof(cublasPointerMode_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasGetAtomicsMode(cublasHandle_t handle,
                                    cublasAtomicsMode_t *mode) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)mode, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasGetAtomicsMode) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, mode, sizeof(cublasAtomicsMode_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, mode, sizeof(cublasAtomicsMode_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)mode, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSetAtomicsMode(cublasHandle_t handle,
                                    cublasAtomicsMode_t mode) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSetAtomicsMode) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &mode, sizeof(cublasAtomicsMode_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasGetMathMode(cublasHandle_t handle, cublasMath_t *mode) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)mode, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasGetMathMode) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, mode, sizeof(cublasMath_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, mode, sizeof(cublasMath_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)mode, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSetMathMode(cublasHandle_t handle, cublasMath_t mode) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSetMathMode) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &mode, sizeof(cublasMath_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasGetSmCountTarget(cublasHandle_t handle,
                                      int *smCountTarget) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)smCountTarget,
                             cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasGetSmCountTarget) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, smCountTarget, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, smCountTarget, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)smCountTarget,
                             cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSetSmCountTarget(cublasHandle_t handle,
                                      int smCountTarget) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&smCountTarget,
                             cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSetSmCountTarget) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &smCountTarget, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&smCountTarget,
                             cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasLoggerConfigure(int logIsOn, int logToStdOut,
                                     int logToStdErr, const char *logFileName) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&logIsOn, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&logToStdOut,
                             cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&logToStdErr,
                             cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)logFileName,
                             cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasLoggerConfigure) < 0 ||
      rpc_write(conn, &logIsOn, sizeof(int)) < 0 ||
      rpc_write(conn, &logToStdOut, sizeof(int)) < 0 ||
      rpc_write(conn, &logToStdErr, sizeof(int)) < 0 ||
      rpc_write(conn, &logFileName, sizeof(const char *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&logIsOn, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&logToStdOut,
                             cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&logToStdErr,
                             cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)logFileName,
                             cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSetLoggerCallback(cublasLogCallback userCallback) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&userCallback,
                             cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSetLoggerCallback) < 0 ||
      rpc_write(conn, &userCallback, sizeof(cublasLogCallback)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&userCallback,
                             cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasGetLoggerCallback(cublasLogCallback *userCallback) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)userCallback,
                             cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasGetLoggerCallback) < 0 ||
      rpc_write(conn, userCallback, sizeof(cublasLogCallback)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, userCallback, sizeof(cublasLogCallback)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)userCallback,
                             cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSnrm2_v2(cublasHandle_t handle, int n, const float *x,
                              int incx, float *result) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSnrm2_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &x, sizeof(const float *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, result, sizeof(float)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, result, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSnrm2_v2_64(cublasHandle_t handle, int64_t n,
                                 const float *x, int64_t incx, float *result) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSnrm2_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const float *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, result, sizeof(float)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, result, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDnrm2_v2(cublasHandle_t handle, int n, const double *x,
                              int incx, double *result) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDnrm2_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &x, sizeof(const double *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, result, sizeof(double)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, result, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDnrm2_v2_64(cublasHandle_t handle, int64_t n,
                                 const double *x, int64_t incx,
                                 double *result) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDnrm2_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const double *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, result, sizeof(double)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, result, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasScnrm2_v2(cublasHandle_t handle, int n, const cuComplex *x,
                               int incx, float *result) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasScnrm2_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, result, sizeof(float)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, result, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasScnrm2_v2_64(cublasHandle_t handle, int64_t n,
                                  const cuComplex *x, int64_t incx,
                                  float *result) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasScnrm2_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, result, sizeof(float)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, result, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDznrm2_v2(cublasHandle_t handle, int n,
                               const cuDoubleComplex *x, int incx,
                               double *result) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDznrm2_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, result, sizeof(double)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, result, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDznrm2_v2_64(cublasHandle_t handle, int64_t n,
                                  const cuDoubleComplex *x, int64_t incx,
                                  double *result) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDznrm2_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, result, sizeof(double)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, result, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSdot_v2(cublasHandle_t handle, int n, const float *x,
                             int incx, const float *y, int incy,
                             float *result) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSdot_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &x, sizeof(const float *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &y, sizeof(const float *)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_write(conn, result, sizeof(float)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, result, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSdot_v2_64(cublasHandle_t handle, int64_t n,
                                const float *x, int64_t incx, const float *y,
                                int64_t incy, float *result) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSdot_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const float *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &y, sizeof(const float *)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_write(conn, result, sizeof(float)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, result, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDdot_v2(cublasHandle_t handle, int n, const double *x,
                             int incx, const double *y, int incy,
                             double *result) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDdot_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &x, sizeof(const double *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &y, sizeof(const double *)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_write(conn, result, sizeof(double)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, result, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDdot_v2_64(cublasHandle_t handle, int64_t n,
                                const double *x, int64_t incx, const double *y,
                                int64_t incy, double *result) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDdot_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const double *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &y, sizeof(const double *)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_write(conn, result, sizeof(double)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, result, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCdotu_v2(cublasHandle_t handle, int n, const cuComplex *x,
                              int incx, const cuComplex *y, int incy,
                              cuComplex *result) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCdotu_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &y, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_write(conn, result, sizeof(cuComplex)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, result, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCdotu_v2_64(cublasHandle_t handle, int64_t n,
                                 const cuComplex *x, int64_t incx,
                                 const cuComplex *y, int64_t incy,
                                 cuComplex *result) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCdotu_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &y, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_write(conn, result, sizeof(cuComplex)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, result, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCdotc_v2(cublasHandle_t handle, int n, const cuComplex *x,
                              int incx, const cuComplex *y, int incy,
                              cuComplex *result) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCdotc_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &y, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_write(conn, result, sizeof(cuComplex)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, result, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCdotc_v2_64(cublasHandle_t handle, int64_t n,
                                 const cuComplex *x, int64_t incx,
                                 const cuComplex *y, int64_t incy,
                                 cuComplex *result) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCdotc_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &y, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_write(conn, result, sizeof(cuComplex)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, result, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZdotu_v2(cublasHandle_t handle, int n,
                              const cuDoubleComplex *x, int incx,
                              const cuDoubleComplex *y, int incy,
                              cuDoubleComplex *result) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZdotu_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &y, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_write(conn, result, sizeof(cuDoubleComplex)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, result, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZdotu_v2_64(cublasHandle_t handle, int64_t n,
                                 const cuDoubleComplex *x, int64_t incx,
                                 const cuDoubleComplex *y, int64_t incy,
                                 cuDoubleComplex *result) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZdotu_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &y, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_write(conn, result, sizeof(cuDoubleComplex)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, result, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZdotc_v2(cublasHandle_t handle, int n,
                              const cuDoubleComplex *x, int incx,
                              const cuDoubleComplex *y, int incy,
                              cuDoubleComplex *result) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZdotc_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &y, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_write(conn, result, sizeof(cuDoubleComplex)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, result, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZdotc_v2_64(cublasHandle_t handle, int64_t n,
                                 const cuDoubleComplex *x, int64_t incx,
                                 const cuDoubleComplex *y, int64_t incy,
                                 cuDoubleComplex *result) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZdotc_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &y, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_write(conn, result, sizeof(cuDoubleComplex)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, result, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSscal_v2(cublasHandle_t handle, int n, const float *alpha,
                              float *x, int incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSscal_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, x, sizeof(float)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, x, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSscal_v2_64(cublasHandle_t handle, int64_t n,
                                 const float *alpha, float *x, int64_t incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSscal_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, x, sizeof(float)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, x, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDscal_v2(cublasHandle_t handle, int n, const double *alpha,
                              double *x, int incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDscal_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      rpc_write(conn, x, sizeof(double)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDscal_v2_64(cublasHandle_t handle, int64_t n,
                                 const double *alpha, double *x, int64_t incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDscal_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      rpc_write(conn, x, sizeof(double)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCscal_v2(cublasHandle_t handle, int n,
                              const cuComplex *alpha, cuComplex *x, int incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCscal_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, x, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCscal_v2_64(cublasHandle_t handle, int64_t n,
                                 const cuComplex *alpha, cuComplex *x,
                                 int64_t incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCscal_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, x, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCsscal_v2(cublasHandle_t handle, int n, const float *alpha,
                               cuComplex *x, int incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCsscal_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, x, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCsscal_v2_64(cublasHandle_t handle, int64_t n,
                                  const float *alpha, cuComplex *x,
                                  int64_t incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCsscal_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, x, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZscal_v2(cublasHandle_t handle, int n,
                              const cuDoubleComplex *alpha, cuDoubleComplex *x,
                              int incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZscal_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, x, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZscal_v2_64(cublasHandle_t handle, int64_t n,
                                 const cuDoubleComplex *alpha,
                                 cuDoubleComplex *x, int64_t incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZscal_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, x, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZdscal_v2(cublasHandle_t handle, int n,
                               const double *alpha, cuDoubleComplex *x,
                               int incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZdscal_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      rpc_write(conn, x, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZdscal_v2_64(cublasHandle_t handle, int64_t n,
                                  const double *alpha, cuDoubleComplex *x,
                                  int64_t incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZdscal_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      rpc_write(conn, x, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSaxpy_v2(cublasHandle_t handle, int n, const float *alpha,
                              const float *x, int incx, float *y, int incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSaxpy_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &x, sizeof(const float *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, y, sizeof(float)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, y, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSaxpy_v2_64(cublasHandle_t handle, int64_t n,
                                 const float *alpha, const float *x,
                                 int64_t incx, float *y, int64_t incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSaxpy_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &x, sizeof(const float *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, y, sizeof(float)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, y, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDaxpy_v2(cublasHandle_t handle, int n, const double *alpha,
                              const double *x, int incx, double *y, int incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDaxpy_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      rpc_write(conn, &x, sizeof(const double *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, y, sizeof(double)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDaxpy_v2_64(cublasHandle_t handle, int64_t n,
                                 const double *alpha, const double *x,
                                 int64_t incx, double *y, int64_t incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDaxpy_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      rpc_write(conn, &x, sizeof(const double *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, y, sizeof(double)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCaxpy_v2(cublasHandle_t handle, int n,
                              const cuComplex *alpha, const cuComplex *x,
                              int incx, cuComplex *y, int incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCaxpy_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, y, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCaxpy_v2_64(cublasHandle_t handle, int64_t n,
                                 const cuComplex *alpha, const cuComplex *x,
                                 int64_t incx, cuComplex *y, int64_t incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCaxpy_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, y, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZaxpy_v2(cublasHandle_t handle, int n,
                              const cuDoubleComplex *alpha,
                              const cuDoubleComplex *x, int incx,
                              cuDoubleComplex *y, int incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZaxpy_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, y, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZaxpy_v2_64(cublasHandle_t handle, int64_t n,
                                 const cuDoubleComplex *alpha,
                                 const cuDoubleComplex *x, int64_t incx,
                                 cuDoubleComplex *y, int64_t incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZaxpy_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, y, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasScopy_v2(cublasHandle_t handle, int n, const float *x,
                              int incx, float *y, int incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasScopy_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &x, sizeof(const float *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, y, sizeof(float)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, y, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasScopy_v2_64(cublasHandle_t handle, int64_t n,
                                 const float *x, int64_t incx, float *y,
                                 int64_t incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasScopy_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const float *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, y, sizeof(float)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, y, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDcopy_v2(cublasHandle_t handle, int n, const double *x,
                              int incx, double *y, int incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDcopy_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &x, sizeof(const double *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, y, sizeof(double)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDcopy_v2_64(cublasHandle_t handle, int64_t n,
                                 const double *x, int64_t incx, double *y,
                                 int64_t incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDcopy_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const double *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, y, sizeof(double)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCcopy_v2(cublasHandle_t handle, int n, const cuComplex *x,
                              int incx, cuComplex *y, int incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCcopy_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, y, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCcopy_v2_64(cublasHandle_t handle, int64_t n,
                                 const cuComplex *x, int64_t incx, cuComplex *y,
                                 int64_t incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCcopy_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, y, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZcopy_v2(cublasHandle_t handle, int n,
                              const cuDoubleComplex *x, int incx,
                              cuDoubleComplex *y, int incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZcopy_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, y, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZcopy_v2_64(cublasHandle_t handle, int64_t n,
                                 const cuDoubleComplex *x, int64_t incx,
                                 cuDoubleComplex *y, int64_t incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZcopy_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, y, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSswap_v2(cublasHandle_t handle, int n, float *x, int incx,
                              float *y, int incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSswap_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, x, sizeof(float)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, y, sizeof(float)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, x, sizeof(float)) < 0 ||
      rpc_read(conn, y, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSswap_v2_64(cublasHandle_t handle, int64_t n, float *x,
                                 int64_t incx, float *y, int64_t incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSswap_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, x, sizeof(float)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, y, sizeof(float)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, x, sizeof(float)) < 0 ||
      rpc_read(conn, y, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDswap_v2(cublasHandle_t handle, int n, double *x, int incx,
                              double *y, int incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDswap_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, x, sizeof(double)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, y, sizeof(double)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(double)) < 0 ||
      rpc_read(conn, y, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDswap_v2_64(cublasHandle_t handle, int64_t n, double *x,
                                 int64_t incx, double *y, int64_t incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDswap_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, x, sizeof(double)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, y, sizeof(double)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(double)) < 0 ||
      rpc_read(conn, y, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCswap_v2(cublasHandle_t handle, int n, cuComplex *x,
                              int incx, cuComplex *y, int incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCswap_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, x, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, y, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, y, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCswap_v2_64(cublasHandle_t handle, int64_t n, cuComplex *x,
                                 int64_t incx, cuComplex *y, int64_t incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCswap_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, x, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, y, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, y, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZswap_v2(cublasHandle_t handle, int n, cuDoubleComplex *x,
                              int incx, cuDoubleComplex *y, int incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZswap_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, x, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, y, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, y, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZswap_v2_64(cublasHandle_t handle, int64_t n,
                                 cuDoubleComplex *x, int64_t incx,
                                 cuDoubleComplex *y, int64_t incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZswap_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, x, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, y, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, y, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasIsamax_v2(cublasHandle_t handle, int n, const float *x,
                               int incx, int *result) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasIsamax_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &x, sizeof(const float *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, result, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, result, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasIsamax_v2_64(cublasHandle_t handle, int64_t n,
                                  const float *x, int64_t incx,
                                  int64_t *result) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasIsamax_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const float *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, result, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, result, sizeof(int64_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasIdamax_v2(cublasHandle_t handle, int n, const double *x,
                               int incx, int *result) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasIdamax_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &x, sizeof(const double *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, result, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, result, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasIdamax_v2_64(cublasHandle_t handle, int64_t n,
                                  const double *x, int64_t incx,
                                  int64_t *result) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasIdamax_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const double *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, result, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, result, sizeof(int64_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasIcamax_v2(cublasHandle_t handle, int n, const cuComplex *x,
                               int incx, int *result) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasIcamax_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, result, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, result, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasIcamax_v2_64(cublasHandle_t handle, int64_t n,
                                  const cuComplex *x, int64_t incx,
                                  int64_t *result) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasIcamax_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, result, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, result, sizeof(int64_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasIzamax_v2(cublasHandle_t handle, int n,
                               const cuDoubleComplex *x, int incx,
                               int *result) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasIzamax_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, result, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, result, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasIzamax_v2_64(cublasHandle_t handle, int64_t n,
                                  const cuDoubleComplex *x, int64_t incx,
                                  int64_t *result) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasIzamax_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, result, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, result, sizeof(int64_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasIamaxEx(cublasHandle_t handle, int n, const void *x,
                             cudaDataType xType, int incx, int *result) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&xType, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasIamaxEx) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &x, sizeof(const void *)) < 0 ||
      rpc_write(conn, &xType, sizeof(cudaDataType)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, result, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, result, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&xType, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasIamaxEx_64(cublasHandle_t handle, int64_t n, const void *x,
                                cudaDataType xType, int64_t incx,
                                int64_t *result) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&xType, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasIamaxEx_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const void *)) < 0 ||
      rpc_write(conn, &xType, sizeof(cudaDataType)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, result, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, result, sizeof(int64_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&xType, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasIsamin_v2(cublasHandle_t handle, int n, const float *x,
                               int incx, int *result) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasIsamin_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &x, sizeof(const float *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, result, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, result, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasIsamin_v2_64(cublasHandle_t handle, int64_t n,
                                  const float *x, int64_t incx,
                                  int64_t *result) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasIsamin_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const float *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, result, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, result, sizeof(int64_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasIdamin_v2(cublasHandle_t handle, int n, const double *x,
                               int incx, int *result) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasIdamin_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &x, sizeof(const double *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, result, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, result, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasIdamin_v2_64(cublasHandle_t handle, int64_t n,
                                  const double *x, int64_t incx,
                                  int64_t *result) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasIdamin_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const double *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, result, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, result, sizeof(int64_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasIcamin_v2(cublasHandle_t handle, int n, const cuComplex *x,
                               int incx, int *result) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasIcamin_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, result, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, result, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasIcamin_v2_64(cublasHandle_t handle, int64_t n,
                                  const cuComplex *x, int64_t incx,
                                  int64_t *result) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasIcamin_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, result, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, result, sizeof(int64_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasIzamin_v2(cublasHandle_t handle, int n,
                               const cuDoubleComplex *x, int incx,
                               int *result) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasIzamin_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, result, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, result, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasIzamin_v2_64(cublasHandle_t handle, int64_t n,
                                  const cuDoubleComplex *x, int64_t incx,
                                  int64_t *result) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasIzamin_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, result, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, result, sizeof(int64_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasIaminEx(cublasHandle_t handle, int n, const void *x,
                             cudaDataType xType, int incx, int *result) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&xType, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasIaminEx) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &x, sizeof(const void *)) < 0 ||
      rpc_write(conn, &xType, sizeof(cudaDataType)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, result, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, result, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&xType, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasIaminEx_64(cublasHandle_t handle, int64_t n, const void *x,
                                cudaDataType xType, int64_t incx,
                                int64_t *result) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&xType, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasIaminEx_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const void *)) < 0 ||
      rpc_write(conn, &xType, sizeof(cudaDataType)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, result, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, result, sizeof(int64_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&xType, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSasum_v2(cublasHandle_t handle, int n, const float *x,
                              int incx, float *result) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSasum_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &x, sizeof(const float *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, result, sizeof(float)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, result, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSasum_v2_64(cublasHandle_t handle, int64_t n,
                                 const float *x, int64_t incx, float *result) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSasum_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const float *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, result, sizeof(float)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, result, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDasum_v2(cublasHandle_t handle, int n, const double *x,
                              int incx, double *result) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDasum_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &x, sizeof(const double *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, result, sizeof(double)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, result, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDasum_v2_64(cublasHandle_t handle, int64_t n,
                                 const double *x, int64_t incx,
                                 double *result) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDasum_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const double *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, result, sizeof(double)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, result, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasScasum_v2(cublasHandle_t handle, int n, const cuComplex *x,
                               int incx, float *result) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasScasum_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, result, sizeof(float)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, result, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasScasum_v2_64(cublasHandle_t handle, int64_t n,
                                  const cuComplex *x, int64_t incx,
                                  float *result) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasScasum_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, result, sizeof(float)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, result, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDzasum_v2(cublasHandle_t handle, int n,
                               const cuDoubleComplex *x, int incx,
                               double *result) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDzasum_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, result, sizeof(double)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, result, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDzasum_v2_64(cublasHandle_t handle, int64_t n,
                                  const cuDoubleComplex *x, int64_t incx,
                                  double *result) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDzasum_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, result, sizeof(double)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, result, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)result, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSrot_v2(cublasHandle_t handle, int n, float *x, int incx,
                             float *y, int incy, const float *c,
                             const float *s) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)c, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)s, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSrot_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, x, sizeof(float)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, y, sizeof(float)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_write(conn, &c, sizeof(const float *)) < 0 ||
      rpc_write(conn, &s, sizeof(const float *)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, x, sizeof(float)) < 0 ||
      rpc_read(conn, y, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)c, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)s, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSrot_v2_64(cublasHandle_t handle, int64_t n, float *x,
                                int64_t incx, float *y, int64_t incy,
                                const float *c, const float *s) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)c, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)s, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSrot_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, x, sizeof(float)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, y, sizeof(float)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &c, sizeof(const float *)) < 0 ||
      rpc_write(conn, &s, sizeof(const float *)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, x, sizeof(float)) < 0 ||
      rpc_read(conn, y, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)c, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)s, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDrot_v2(cublasHandle_t handle, int n, double *x, int incx,
                             double *y, int incy, const double *c,
                             const double *s) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)c, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)s, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDrot_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, x, sizeof(double)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, y, sizeof(double)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_write(conn, &c, sizeof(const double *)) < 0 ||
      rpc_write(conn, &s, sizeof(const double *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(double)) < 0 ||
      rpc_read(conn, y, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)c, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)s, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDrot_v2_64(cublasHandle_t handle, int64_t n, double *x,
                                int64_t incx, double *y, int64_t incy,
                                const double *c, const double *s) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)c, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)s, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDrot_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, x, sizeof(double)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, y, sizeof(double)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &c, sizeof(const double *)) < 0 ||
      rpc_write(conn, &s, sizeof(const double *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(double)) < 0 ||
      rpc_read(conn, y, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)c, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)s, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCrot_v2(cublasHandle_t handle, int n, cuComplex *x,
                             int incx, cuComplex *y, int incy, const float *c,
                             const cuComplex *s) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)c, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)s, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCrot_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, x, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, y, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_write(conn, &c, sizeof(const float *)) < 0 ||
      rpc_write(conn, &s, sizeof(const cuComplex *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, y, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)c, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)s, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCrot_v2_64(cublasHandle_t handle, int64_t n, cuComplex *x,
                                int64_t incx, cuComplex *y, int64_t incy,
                                const float *c, const cuComplex *s) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)c, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)s, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCrot_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, x, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, y, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &c, sizeof(const float *)) < 0 ||
      rpc_write(conn, &s, sizeof(const cuComplex *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, y, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)c, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)s, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCsrot_v2(cublasHandle_t handle, int n, cuComplex *x,
                              int incx, cuComplex *y, int incy, const float *c,
                              const float *s) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)c, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)s, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCsrot_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, x, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, y, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_write(conn, &c, sizeof(const float *)) < 0 ||
      rpc_write(conn, &s, sizeof(const float *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, y, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)c, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)s, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCsrot_v2_64(cublasHandle_t handle, int64_t n, cuComplex *x,
                                 int64_t incx, cuComplex *y, int64_t incy,
                                 const float *c, const float *s) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)c, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)s, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCsrot_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, x, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, y, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &c, sizeof(const float *)) < 0 ||
      rpc_write(conn, &s, sizeof(const float *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, y, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)c, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)s, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZrot_v2(cublasHandle_t handle, int n, cuDoubleComplex *x,
                             int incx, cuDoubleComplex *y, int incy,
                             const double *c, const cuDoubleComplex *s) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)c, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)s, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZrot_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, x, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, y, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_write(conn, &c, sizeof(const double *)) < 0 ||
      rpc_write(conn, &s, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, y, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)c, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)s, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZrot_v2_64(cublasHandle_t handle, int64_t n,
                                cuDoubleComplex *x, int64_t incx,
                                cuDoubleComplex *y, int64_t incy,
                                const double *c, const cuDoubleComplex *s) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)c, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)s, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZrot_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, x, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, y, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &c, sizeof(const double *)) < 0 ||
      rpc_write(conn, &s, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, y, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)c, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)s, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZdrot_v2(cublasHandle_t handle, int n, cuDoubleComplex *x,
                              int incx, cuDoubleComplex *y, int incy,
                              const double *c, const double *s) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)c, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)s, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZdrot_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, x, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, y, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_write(conn, &c, sizeof(const double *)) < 0 ||
      rpc_write(conn, &s, sizeof(const double *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, y, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)c, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)s, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZdrot_v2_64(cublasHandle_t handle, int64_t n,
                                 cuDoubleComplex *x, int64_t incx,
                                 cuDoubleComplex *y, int64_t incy,
                                 const double *c, const double *s) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)c, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)s, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZdrot_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, x, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, y, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &c, sizeof(const double *)) < 0 ||
      rpc_write(conn, &s, sizeof(const double *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, y, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)c, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)s, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSrotg_v2(cublasHandle_t handle, float *a, float *b,
                              float *c, float *s) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)a, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)b, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)c, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)s, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSrotg_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, a, sizeof(float)) < 0 ||
      rpc_write(conn, b, sizeof(float)) < 0 ||
      rpc_write(conn, c, sizeof(float)) < 0 ||
      rpc_write(conn, s, sizeof(float)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, a, sizeof(float)) < 0 ||
      rpc_read(conn, b, sizeof(float)) < 0 ||
      rpc_read(conn, c, sizeof(float)) < 0 ||
      rpc_read(conn, s, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)a, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)b, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)c, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)s, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDrotg_v2(cublasHandle_t handle, double *a, double *b,
                              double *c, double *s) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)a, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)b, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)c, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)s, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDrotg_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, a, sizeof(double)) < 0 ||
      rpc_write(conn, b, sizeof(double)) < 0 ||
      rpc_write(conn, c, sizeof(double)) < 0 ||
      rpc_write(conn, s, sizeof(double)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, a, sizeof(double)) < 0 ||
      rpc_read(conn, b, sizeof(double)) < 0 ||
      rpc_read(conn, c, sizeof(double)) < 0 ||
      rpc_read(conn, s, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)a, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)b, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)c, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)s, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCrotg_v2(cublasHandle_t handle, cuComplex *a, cuComplex *b,
                              float *c, cuComplex *s) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)a, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)b, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)c, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)s, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCrotg_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, a, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, b, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, c, sizeof(float)) < 0 ||
      rpc_write(conn, s, sizeof(cuComplex)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, a, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, b, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, c, sizeof(float)) < 0 ||
      rpc_read(conn, s, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)a, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)b, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)c, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)s, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZrotg_v2(cublasHandle_t handle, cuDoubleComplex *a,
                              cuDoubleComplex *b, double *c,
                              cuDoubleComplex *s) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)a, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)b, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)c, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)s, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZrotg_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, a, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, b, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, c, sizeof(double)) < 0 ||
      rpc_write(conn, s, sizeof(cuDoubleComplex)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, a, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, b, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, c, sizeof(double)) < 0 ||
      rpc_read(conn, s, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)a, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)b, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)c, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)s, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSrotm_v2(cublasHandle_t handle, int n, float *x, int incx,
                              float *y, int incy, const float *param) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)param, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSrotm_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, x, sizeof(float)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, y, sizeof(float)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_write(conn, &param, sizeof(const float *)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, x, sizeof(float)) < 0 ||
      rpc_read(conn, y, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)param, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSrotm_v2_64(cublasHandle_t handle, int64_t n, float *x,
                                 int64_t incx, float *y, int64_t incy,
                                 const float *param) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)param, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSrotm_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, x, sizeof(float)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, y, sizeof(float)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &param, sizeof(const float *)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, x, sizeof(float)) < 0 ||
      rpc_read(conn, y, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)param, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDrotm_v2(cublasHandle_t handle, int n, double *x, int incx,
                              double *y, int incy, const double *param) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)param, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDrotm_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, x, sizeof(double)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, y, sizeof(double)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_write(conn, &param, sizeof(const double *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(double)) < 0 ||
      rpc_read(conn, y, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)param, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDrotm_v2_64(cublasHandle_t handle, int64_t n, double *x,
                                 int64_t incx, double *y, int64_t incy,
                                 const double *param) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)param, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDrotm_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, x, sizeof(double)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, y, sizeof(double)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &param, sizeof(const double *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(double)) < 0 ||
      rpc_read(conn, y, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)param, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSrotmg_v2(cublasHandle_t handle, float *d1, float *d2,
                               float *x1, const float *y1, float *param) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)d1, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)d2, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x1, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y1, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)param, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSrotmg_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, d1, sizeof(float)) < 0 ||
      rpc_write(conn, d2, sizeof(float)) < 0 ||
      rpc_write(conn, x1, sizeof(float)) < 0 ||
      rpc_write(conn, &y1, sizeof(const float *)) < 0 ||
      rpc_write(conn, param, sizeof(float)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, d1, sizeof(float)) < 0 ||
      rpc_read(conn, d2, sizeof(float)) < 0 ||
      rpc_read(conn, x1, sizeof(float)) < 0 ||
      rpc_read(conn, param, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)d1, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)d2, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x1, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y1, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)param, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDrotmg_v2(cublasHandle_t handle, double *d1, double *d2,
                               double *x1, const double *y1, double *param) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)d1, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)d2, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x1, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y1, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)param, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDrotmg_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, d1, sizeof(double)) < 0 ||
      rpc_write(conn, d2, sizeof(double)) < 0 ||
      rpc_write(conn, x1, sizeof(double)) < 0 ||
      rpc_write(conn, &y1, sizeof(const double *)) < 0 ||
      rpc_write(conn, param, sizeof(double)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, d1, sizeof(double)) < 0 ||
      rpc_read(conn, d2, sizeof(double)) < 0 ||
      rpc_read(conn, x1, sizeof(double)) < 0 ||
      rpc_read(conn, param, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)d1, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)d2, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x1, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y1, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)param, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSgemv_v2(cublasHandle_t handle, cublasOperation_t trans,
                              int m, int n, const float *alpha, const float *A,
                              int lda, const float *x, int incx,
                              const float *beta, float *y, int incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSgemv_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &A, sizeof(const float *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &x, sizeof(const float *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const float *)) < 0 ||
      rpc_write(conn, y, sizeof(float)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, y, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSgemv_v2_64(cublasHandle_t handle, cublasOperation_t trans,
                                 int64_t m, int64_t n, const float *alpha,
                                 const float *A, int64_t lda, const float *x,
                                 int64_t incx, const float *beta, float *y,
                                 int64_t incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSgemv_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &A, sizeof(const float *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const float *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const float *)) < 0 ||
      rpc_write(conn, y, sizeof(float)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, y, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDgemv_v2(cublasHandle_t handle, cublasOperation_t trans,
                              int m, int n, const double *alpha,
                              const double *A, int lda, const double *x,
                              int incx, const double *beta, double *y,
                              int incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDgemv_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      rpc_write(conn, &A, sizeof(const double *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &x, sizeof(const double *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const double *)) < 0 ||
      rpc_write(conn, y, sizeof(double)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDgemv_v2_64(cublasHandle_t handle, cublasOperation_t trans,
                                 int64_t m, int64_t n, const double *alpha,
                                 const double *A, int64_t lda, const double *x,
                                 int64_t incx, const double *beta, double *y,
                                 int64_t incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDgemv_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      rpc_write(conn, &A, sizeof(const double *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const double *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const double *)) < 0 ||
      rpc_write(conn, y, sizeof(double)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCgemv_v2(cublasHandle_t handle, cublasOperation_t trans,
                              int m, int n, const cuComplex *alpha,
                              const cuComplex *A, int lda, const cuComplex *x,
                              int incx, const cuComplex *beta, cuComplex *y,
                              int incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCgemv_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, y, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCgemv_v2_64(cublasHandle_t handle, cublasOperation_t trans,
                                 int64_t m, int64_t n, const cuComplex *alpha,
                                 const cuComplex *A, int64_t lda,
                                 const cuComplex *x, int64_t incx,
                                 const cuComplex *beta, cuComplex *y,
                                 int64_t incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCgemv_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, y, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZgemv_v2(cublasHandle_t handle, cublasOperation_t trans,
                              int m, int n, const cuDoubleComplex *alpha,
                              const cuDoubleComplex *A, int lda,
                              const cuDoubleComplex *x, int incx,
                              const cuDoubleComplex *beta, cuDoubleComplex *y,
                              int incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZgemv_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, y, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZgemv_v2_64(cublasHandle_t handle, cublasOperation_t trans,
                                 int64_t m, int64_t n,
                                 const cuDoubleComplex *alpha,
                                 const cuDoubleComplex *A, int64_t lda,
                                 const cuDoubleComplex *x, int64_t incx,
                                 const cuDoubleComplex *beta,
                                 cuDoubleComplex *y, int64_t incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZgemv_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, y, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSgbmv_v2(cublasHandle_t handle, cublasOperation_t trans,
                              int m, int n, int kl, int ku, const float *alpha,
                              const float *A, int lda, const float *x, int incx,
                              const float *beta, float *y, int incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&kl, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ku, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSgbmv_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &kl, sizeof(int)) < 0 ||
      rpc_write(conn, &ku, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &A, sizeof(const float *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &x, sizeof(const float *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const float *)) < 0 ||
      rpc_write(conn, y, sizeof(float)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, y, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&kl, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ku, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSgbmv_v2_64(cublasHandle_t handle, cublasOperation_t trans,
                                 int64_t m, int64_t n, int64_t kl, int64_t ku,
                                 const float *alpha, const float *A,
                                 int64_t lda, const float *x, int64_t incx,
                                 const float *beta, float *y, int64_t incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&kl, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ku, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSgbmv_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &kl, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &ku, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &A, sizeof(const float *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const float *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const float *)) < 0 ||
      rpc_write(conn, y, sizeof(float)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, y, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&kl, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ku, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDgbmv_v2(cublasHandle_t handle, cublasOperation_t trans,
                              int m, int n, int kl, int ku, const double *alpha,
                              const double *A, int lda, const double *x,
                              int incx, const double *beta, double *y,
                              int incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&kl, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ku, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDgbmv_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &kl, sizeof(int)) < 0 ||
      rpc_write(conn, &ku, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      rpc_write(conn, &A, sizeof(const double *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &x, sizeof(const double *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const double *)) < 0 ||
      rpc_write(conn, y, sizeof(double)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&kl, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ku, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDgbmv_v2_64(cublasHandle_t handle, cublasOperation_t trans,
                                 int64_t m, int64_t n, int64_t kl, int64_t ku,
                                 const double *alpha, const double *A,
                                 int64_t lda, const double *x, int64_t incx,
                                 const double *beta, double *y, int64_t incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&kl, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ku, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDgbmv_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &kl, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &ku, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      rpc_write(conn, &A, sizeof(const double *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const double *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const double *)) < 0 ||
      rpc_write(conn, y, sizeof(double)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&kl, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ku, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCgbmv_v2(cublasHandle_t handle, cublasOperation_t trans,
                              int m, int n, int kl, int ku,
                              const cuComplex *alpha, const cuComplex *A,
                              int lda, const cuComplex *x, int incx,
                              const cuComplex *beta, cuComplex *y, int incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&kl, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ku, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCgbmv_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &kl, sizeof(int)) < 0 ||
      rpc_write(conn, &ku, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, y, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&kl, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ku, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCgbmv_v2_64(cublasHandle_t handle, cublasOperation_t trans,
                                 int64_t m, int64_t n, int64_t kl, int64_t ku,
                                 const cuComplex *alpha, const cuComplex *A,
                                 int64_t lda, const cuComplex *x, int64_t incx,
                                 const cuComplex *beta, cuComplex *y,
                                 int64_t incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&kl, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ku, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCgbmv_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &kl, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &ku, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, y, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&kl, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ku, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZgbmv_v2(cublasHandle_t handle, cublasOperation_t trans,
                              int m, int n, int kl, int ku,
                              const cuDoubleComplex *alpha,
                              const cuDoubleComplex *A, int lda,
                              const cuDoubleComplex *x, int incx,
                              const cuDoubleComplex *beta, cuDoubleComplex *y,
                              int incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&kl, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ku, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZgbmv_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &kl, sizeof(int)) < 0 ||
      rpc_write(conn, &ku, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, y, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&kl, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ku, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZgbmv_v2_64(cublasHandle_t handle, cublasOperation_t trans,
                                 int64_t m, int64_t n, int64_t kl, int64_t ku,
                                 const cuDoubleComplex *alpha,
                                 const cuDoubleComplex *A, int64_t lda,
                                 const cuDoubleComplex *x, int64_t incx,
                                 const cuDoubleComplex *beta,
                                 cuDoubleComplex *y, int64_t incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&kl, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ku, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZgbmv_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &kl, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &ku, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, y, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&kl, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ku, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasStrmv_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              cublasOperation_t trans, cublasDiagType_t diag,
                              int n, const float *A, int lda, float *x,
                              int incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasStrmv_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &A, sizeof(const float *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, x, sizeof(float)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, x, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasStrmv_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 cublasOperation_t trans, cublasDiagType_t diag,
                                 int64_t n, const float *A, int64_t lda,
                                 float *x, int64_t incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasStrmv_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &A, sizeof(const float *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, x, sizeof(float)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, x, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDtrmv_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              cublasOperation_t trans, cublasDiagType_t diag,
                              int n, const double *A, int lda, double *x,
                              int incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDtrmv_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &A, sizeof(const double *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, x, sizeof(double)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDtrmv_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 cublasOperation_t trans, cublasDiagType_t diag,
                                 int64_t n, const double *A, int64_t lda,
                                 double *x, int64_t incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDtrmv_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &A, sizeof(const double *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, x, sizeof(double)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCtrmv_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              cublasOperation_t trans, cublasDiagType_t diag,
                              int n, const cuComplex *A, int lda, cuComplex *x,
                              int incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCtrmv_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, x, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCtrmv_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 cublasOperation_t trans, cublasDiagType_t diag,
                                 int64_t n, const cuComplex *A, int64_t lda,
                                 cuComplex *x, int64_t incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCtrmv_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, x, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZtrmv_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              cublasOperation_t trans, cublasDiagType_t diag,
                              int n, const cuDoubleComplex *A, int lda,
                              cuDoubleComplex *x, int incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZtrmv_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, x, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZtrmv_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 cublasOperation_t trans, cublasDiagType_t diag,
                                 int64_t n, const cuDoubleComplex *A,
                                 int64_t lda, cuDoubleComplex *x,
                                 int64_t incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZtrmv_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, x, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasStbmv_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              cublasOperation_t trans, cublasDiagType_t diag,
                              int n, int k, const float *A, int lda, float *x,
                              int incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasStbmv_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &k, sizeof(int)) < 0 ||
      rpc_write(conn, &A, sizeof(const float *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, x, sizeof(float)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, x, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasStbmv_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 cublasOperation_t trans, cublasDiagType_t diag,
                                 int64_t n, int64_t k, const float *A,
                                 int64_t lda, float *x, int64_t incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasStbmv_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &k, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &A, sizeof(const float *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, x, sizeof(float)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, x, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDtbmv_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              cublasOperation_t trans, cublasDiagType_t diag,
                              int n, int k, const double *A, int lda, double *x,
                              int incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDtbmv_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &k, sizeof(int)) < 0 ||
      rpc_write(conn, &A, sizeof(const double *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, x, sizeof(double)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDtbmv_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 cublasOperation_t trans, cublasDiagType_t diag,
                                 int64_t n, int64_t k, const double *A,
                                 int64_t lda, double *x, int64_t incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDtbmv_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &k, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &A, sizeof(const double *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, x, sizeof(double)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCtbmv_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              cublasOperation_t trans, cublasDiagType_t diag,
                              int n, int k, const cuComplex *A, int lda,
                              cuComplex *x, int incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCtbmv_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &k, sizeof(int)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, x, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCtbmv_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 cublasOperation_t trans, cublasDiagType_t diag,
                                 int64_t n, int64_t k, const cuComplex *A,
                                 int64_t lda, cuComplex *x, int64_t incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCtbmv_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &k, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, x, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZtbmv_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              cublasOperation_t trans, cublasDiagType_t diag,
                              int n, int k, const cuDoubleComplex *A, int lda,
                              cuDoubleComplex *x, int incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZtbmv_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &k, sizeof(int)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, x, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZtbmv_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 cublasOperation_t trans, cublasDiagType_t diag,
                                 int64_t n, int64_t k, const cuDoubleComplex *A,
                                 int64_t lda, cuDoubleComplex *x,
                                 int64_t incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZtbmv_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &k, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, x, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasStpmv_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              cublasOperation_t trans, cublasDiagType_t diag,
                              int n, const float *AP, float *x, int incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasStpmv_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &AP, sizeof(const float *)) < 0 ||
      rpc_write(conn, x, sizeof(float)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, x, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasStpmv_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 cublasOperation_t trans, cublasDiagType_t diag,
                                 int64_t n, const float *AP, float *x,
                                 int64_t incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasStpmv_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &AP, sizeof(const float *)) < 0 ||
      rpc_write(conn, x, sizeof(float)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, x, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDtpmv_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              cublasOperation_t trans, cublasDiagType_t diag,
                              int n, const double *AP, double *x, int incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDtpmv_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &AP, sizeof(const double *)) < 0 ||
      rpc_write(conn, x, sizeof(double)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDtpmv_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 cublasOperation_t trans, cublasDiagType_t diag,
                                 int64_t n, const double *AP, double *x,
                                 int64_t incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDtpmv_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &AP, sizeof(const double *)) < 0 ||
      rpc_write(conn, x, sizeof(double)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCtpmv_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              cublasOperation_t trans, cublasDiagType_t diag,
                              int n, const cuComplex *AP, cuComplex *x,
                              int incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCtpmv_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &AP, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, x, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCtpmv_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 cublasOperation_t trans, cublasDiagType_t diag,
                                 int64_t n, const cuComplex *AP, cuComplex *x,
                                 int64_t incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCtpmv_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &AP, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, x, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZtpmv_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              cublasOperation_t trans, cublasDiagType_t diag,
                              int n, const cuDoubleComplex *AP,
                              cuDoubleComplex *x, int incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZtpmv_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &AP, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, x, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZtpmv_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 cublasOperation_t trans, cublasDiagType_t diag,
                                 int64_t n, const cuDoubleComplex *AP,
                                 cuDoubleComplex *x, int64_t incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZtpmv_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &AP, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, x, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasStrsv_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              cublasOperation_t trans, cublasDiagType_t diag,
                              int n, const float *A, int lda, float *x,
                              int incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasStrsv_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &A, sizeof(const float *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, x, sizeof(float)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, x, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasStrsv_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 cublasOperation_t trans, cublasDiagType_t diag,
                                 int64_t n, const float *A, int64_t lda,
                                 float *x, int64_t incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasStrsv_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &A, sizeof(const float *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, x, sizeof(float)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, x, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDtrsv_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              cublasOperation_t trans, cublasDiagType_t diag,
                              int n, const double *A, int lda, double *x,
                              int incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDtrsv_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &A, sizeof(const double *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, x, sizeof(double)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDtrsv_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 cublasOperation_t trans, cublasDiagType_t diag,
                                 int64_t n, const double *A, int64_t lda,
                                 double *x, int64_t incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDtrsv_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &A, sizeof(const double *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, x, sizeof(double)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCtrsv_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              cublasOperation_t trans, cublasDiagType_t diag,
                              int n, const cuComplex *A, int lda, cuComplex *x,
                              int incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCtrsv_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, x, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCtrsv_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 cublasOperation_t trans, cublasDiagType_t diag,
                                 int64_t n, const cuComplex *A, int64_t lda,
                                 cuComplex *x, int64_t incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCtrsv_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, x, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZtrsv_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              cublasOperation_t trans, cublasDiagType_t diag,
                              int n, const cuDoubleComplex *A, int lda,
                              cuDoubleComplex *x, int incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZtrsv_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, x, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZtrsv_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 cublasOperation_t trans, cublasDiagType_t diag,
                                 int64_t n, const cuDoubleComplex *A,
                                 int64_t lda, cuDoubleComplex *x,
                                 int64_t incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZtrsv_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, x, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasStpsv_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              cublasOperation_t trans, cublasDiagType_t diag,
                              int n, const float *AP, float *x, int incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasStpsv_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &AP, sizeof(const float *)) < 0 ||
      rpc_write(conn, x, sizeof(float)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, x, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasStpsv_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 cublasOperation_t trans, cublasDiagType_t diag,
                                 int64_t n, const float *AP, float *x,
                                 int64_t incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasStpsv_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &AP, sizeof(const float *)) < 0 ||
      rpc_write(conn, x, sizeof(float)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, x, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDtpsv_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              cublasOperation_t trans, cublasDiagType_t diag,
                              int n, const double *AP, double *x, int incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDtpsv_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &AP, sizeof(const double *)) < 0 ||
      rpc_write(conn, x, sizeof(double)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDtpsv_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 cublasOperation_t trans, cublasDiagType_t diag,
                                 int64_t n, const double *AP, double *x,
                                 int64_t incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDtpsv_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &AP, sizeof(const double *)) < 0 ||
      rpc_write(conn, x, sizeof(double)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCtpsv_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              cublasOperation_t trans, cublasDiagType_t diag,
                              int n, const cuComplex *AP, cuComplex *x,
                              int incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCtpsv_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &AP, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, x, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCtpsv_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 cublasOperation_t trans, cublasDiagType_t diag,
                                 int64_t n, const cuComplex *AP, cuComplex *x,
                                 int64_t incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCtpsv_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &AP, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, x, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZtpsv_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              cublasOperation_t trans, cublasDiagType_t diag,
                              int n, const cuDoubleComplex *AP,
                              cuDoubleComplex *x, int incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZtpsv_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &AP, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, x, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZtpsv_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 cublasOperation_t trans, cublasDiagType_t diag,
                                 int64_t n, const cuDoubleComplex *AP,
                                 cuDoubleComplex *x, int64_t incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZtpsv_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &AP, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, x, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasStbsv_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              cublasOperation_t trans, cublasDiagType_t diag,
                              int n, int k, const float *A, int lda, float *x,
                              int incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasStbsv_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &k, sizeof(int)) < 0 ||
      rpc_write(conn, &A, sizeof(const float *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, x, sizeof(float)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, x, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasStbsv_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 cublasOperation_t trans, cublasDiagType_t diag,
                                 int64_t n, int64_t k, const float *A,
                                 int64_t lda, float *x, int64_t incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasStbsv_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &k, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &A, sizeof(const float *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, x, sizeof(float)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, x, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDtbsv_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              cublasOperation_t trans, cublasDiagType_t diag,
                              int n, int k, const double *A, int lda, double *x,
                              int incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDtbsv_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &k, sizeof(int)) < 0 ||
      rpc_write(conn, &A, sizeof(const double *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, x, sizeof(double)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDtbsv_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 cublasOperation_t trans, cublasDiagType_t diag,
                                 int64_t n, int64_t k, const double *A,
                                 int64_t lda, double *x, int64_t incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDtbsv_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &k, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &A, sizeof(const double *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, x, sizeof(double)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCtbsv_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              cublasOperation_t trans, cublasDiagType_t diag,
                              int n, int k, const cuComplex *A, int lda,
                              cuComplex *x, int incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCtbsv_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &k, sizeof(int)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, x, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCtbsv_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 cublasOperation_t trans, cublasDiagType_t diag,
                                 int64_t n, int64_t k, const cuComplex *A,
                                 int64_t lda, cuComplex *x, int64_t incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCtbsv_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &k, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, x, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZtbsv_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              cublasOperation_t trans, cublasDiagType_t diag,
                              int n, int k, const cuDoubleComplex *A, int lda,
                              cuDoubleComplex *x, int incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZtbsv_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &k, sizeof(int)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, x, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZtbsv_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 cublasOperation_t trans, cublasDiagType_t diag,
                                 int64_t n, int64_t k, const cuDoubleComplex *A,
                                 int64_t lda, cuDoubleComplex *x,
                                 int64_t incx) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZtbsv_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &k, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, x, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, x, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSsymv_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              int n, const float *alpha, const float *A,
                              int lda, const float *x, int incx,
                              const float *beta, float *y, int incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSsymv_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &A, sizeof(const float *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &x, sizeof(const float *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const float *)) < 0 ||
      rpc_write(conn, y, sizeof(float)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, y, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSsymv_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 int64_t n, const float *alpha, const float *A,
                                 int64_t lda, const float *x, int64_t incx,
                                 const float *beta, float *y, int64_t incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSsymv_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &A, sizeof(const float *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const float *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const float *)) < 0 ||
      rpc_write(conn, y, sizeof(float)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, y, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDsymv_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              int n, const double *alpha, const double *A,
                              int lda, const double *x, int incx,
                              const double *beta, double *y, int incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDsymv_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      rpc_write(conn, &A, sizeof(const double *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &x, sizeof(const double *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const double *)) < 0 ||
      rpc_write(conn, y, sizeof(double)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDsymv_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 int64_t n, const double *alpha,
                                 const double *A, int64_t lda, const double *x,
                                 int64_t incx, const double *beta, double *y,
                                 int64_t incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDsymv_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      rpc_write(conn, &A, sizeof(const double *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const double *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const double *)) < 0 ||
      rpc_write(conn, y, sizeof(double)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCsymv_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              int n, const cuComplex *alpha, const cuComplex *A,
                              int lda, const cuComplex *x, int incx,
                              const cuComplex *beta, cuComplex *y, int incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCsymv_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, y, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCsymv_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 int64_t n, const cuComplex *alpha,
                                 const cuComplex *A, int64_t lda,
                                 const cuComplex *x, int64_t incx,
                                 const cuComplex *beta, cuComplex *y,
                                 int64_t incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCsymv_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, y, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZsymv_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              int n, const cuDoubleComplex *alpha,
                              const cuDoubleComplex *A, int lda,
                              const cuDoubleComplex *x, int incx,
                              const cuDoubleComplex *beta, cuDoubleComplex *y,
                              int incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZsymv_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, y, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZsymv_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 int64_t n, const cuDoubleComplex *alpha,
                                 const cuDoubleComplex *A, int64_t lda,
                                 const cuDoubleComplex *x, int64_t incx,
                                 const cuDoubleComplex *beta,
                                 cuDoubleComplex *y, int64_t incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZsymv_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, y, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasChemv_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              int n, const cuComplex *alpha, const cuComplex *A,
                              int lda, const cuComplex *x, int incx,
                              const cuComplex *beta, cuComplex *y, int incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasChemv_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, y, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasChemv_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 int64_t n, const cuComplex *alpha,
                                 const cuComplex *A, int64_t lda,
                                 const cuComplex *x, int64_t incx,
                                 const cuComplex *beta, cuComplex *y,
                                 int64_t incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasChemv_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, y, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZhemv_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              int n, const cuDoubleComplex *alpha,
                              const cuDoubleComplex *A, int lda,
                              const cuDoubleComplex *x, int incx,
                              const cuDoubleComplex *beta, cuDoubleComplex *y,
                              int incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZhemv_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, y, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZhemv_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 int64_t n, const cuDoubleComplex *alpha,
                                 const cuDoubleComplex *A, int64_t lda,
                                 const cuDoubleComplex *x, int64_t incx,
                                 const cuDoubleComplex *beta,
                                 cuDoubleComplex *y, int64_t incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZhemv_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, y, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSsbmv_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              int n, int k, const float *alpha, const float *A,
                              int lda, const float *x, int incx,
                              const float *beta, float *y, int incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSsbmv_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &k, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &A, sizeof(const float *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &x, sizeof(const float *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const float *)) < 0 ||
      rpc_write(conn, y, sizeof(float)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, y, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSsbmv_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 int64_t n, int64_t k, const float *alpha,
                                 const float *A, int64_t lda, const float *x,
                                 int64_t incx, const float *beta, float *y,
                                 int64_t incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSsbmv_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &k, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &A, sizeof(const float *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const float *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const float *)) < 0 ||
      rpc_write(conn, y, sizeof(float)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, y, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDsbmv_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              int n, int k, const double *alpha,
                              const double *A, int lda, const double *x,
                              int incx, const double *beta, double *y,
                              int incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDsbmv_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &k, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      rpc_write(conn, &A, sizeof(const double *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &x, sizeof(const double *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const double *)) < 0 ||
      rpc_write(conn, y, sizeof(double)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDsbmv_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 int64_t n, int64_t k, const double *alpha,
                                 const double *A, int64_t lda, const double *x,
                                 int64_t incx, const double *beta, double *y,
                                 int64_t incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDsbmv_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &k, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      rpc_write(conn, &A, sizeof(const double *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const double *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const double *)) < 0 ||
      rpc_write(conn, y, sizeof(double)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasChbmv_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              int n, int k, const cuComplex *alpha,
                              const cuComplex *A, int lda, const cuComplex *x,
                              int incx, const cuComplex *beta, cuComplex *y,
                              int incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasChbmv_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &k, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, y, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasChbmv_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 int64_t n, int64_t k, const cuComplex *alpha,
                                 const cuComplex *A, int64_t lda,
                                 const cuComplex *x, int64_t incx,
                                 const cuComplex *beta, cuComplex *y,
                                 int64_t incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasChbmv_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &k, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, y, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZhbmv_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              int n, int k, const cuDoubleComplex *alpha,
                              const cuDoubleComplex *A, int lda,
                              const cuDoubleComplex *x, int incx,
                              const cuDoubleComplex *beta, cuDoubleComplex *y,
                              int incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZhbmv_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &k, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, y, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZhbmv_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 int64_t n, int64_t k,
                                 const cuDoubleComplex *alpha,
                                 const cuDoubleComplex *A, int64_t lda,
                                 const cuDoubleComplex *x, int64_t incx,
                                 const cuDoubleComplex *beta,
                                 cuDoubleComplex *y, int64_t incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZhbmv_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &k, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, y, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSspmv_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              int n, const float *alpha, const float *AP,
                              const float *x, int incx, const float *beta,
                              float *y, int incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSspmv_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &AP, sizeof(const float *)) < 0 ||
      rpc_write(conn, &x, sizeof(const float *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const float *)) < 0 ||
      rpc_write(conn, y, sizeof(float)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, y, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSspmv_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 int64_t n, const float *alpha, const float *AP,
                                 const float *x, int64_t incx,
                                 const float *beta, float *y, int64_t incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSspmv_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &AP, sizeof(const float *)) < 0 ||
      rpc_write(conn, &x, sizeof(const float *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const float *)) < 0 ||
      rpc_write(conn, y, sizeof(float)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, y, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDspmv_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              int n, const double *alpha, const double *AP,
                              const double *x, int incx, const double *beta,
                              double *y, int incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDspmv_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      rpc_write(conn, &AP, sizeof(const double *)) < 0 ||
      rpc_write(conn, &x, sizeof(const double *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const double *)) < 0 ||
      rpc_write(conn, y, sizeof(double)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDspmv_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 int64_t n, const double *alpha,
                                 const double *AP, const double *x,
                                 int64_t incx, const double *beta, double *y,
                                 int64_t incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDspmv_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      rpc_write(conn, &AP, sizeof(const double *)) < 0 ||
      rpc_write(conn, &x, sizeof(const double *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const double *)) < 0 ||
      rpc_write(conn, y, sizeof(double)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasChpmv_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              int n, const cuComplex *alpha,
                              const cuComplex *AP, const cuComplex *x, int incx,
                              const cuComplex *beta, cuComplex *y, int incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasChpmv_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &AP, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, y, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasChpmv_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 int64_t n, const cuComplex *alpha,
                                 const cuComplex *AP, const cuComplex *x,
                                 int64_t incx, const cuComplex *beta,
                                 cuComplex *y, int64_t incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasChpmv_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &AP, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, y, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZhpmv_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              int n, const cuDoubleComplex *alpha,
                              const cuDoubleComplex *AP,
                              const cuDoubleComplex *x, int incx,
                              const cuDoubleComplex *beta, cuDoubleComplex *y,
                              int incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZhpmv_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &AP, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, y, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZhpmv_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 int64_t n, const cuDoubleComplex *alpha,
                                 const cuDoubleComplex *AP,
                                 const cuDoubleComplex *x, int64_t incx,
                                 const cuDoubleComplex *beta,
                                 cuDoubleComplex *y, int64_t incy) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZhpmv_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &AP, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, y, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSger_v2(cublasHandle_t handle, int m, int n,
                             const float *alpha, const float *x, int incx,
                             const float *y, int incy, float *A, int lda) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSger_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &x, sizeof(const float *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &y, sizeof(const float *)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_write(conn, A, sizeof(float)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, A, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSger_v2_64(cublasHandle_t handle, int64_t m, int64_t n,
                                const float *alpha, const float *x,
                                int64_t incx, const float *y, int64_t incy,
                                float *A, int64_t lda) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSger_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &x, sizeof(const float *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &y, sizeof(const float *)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_write(conn, A, sizeof(float)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, A, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDger_v2(cublasHandle_t handle, int m, int n,
                             const double *alpha, const double *x, int incx,
                             const double *y, int incy, double *A, int lda) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDger_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      rpc_write(conn, &x, sizeof(const double *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &y, sizeof(const double *)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_write(conn, A, sizeof(double)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, A, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDger_v2_64(cublasHandle_t handle, int64_t m, int64_t n,
                                const double *alpha, const double *x,
                                int64_t incx, const double *y, int64_t incy,
                                double *A, int64_t lda) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDger_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      rpc_write(conn, &x, sizeof(const double *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &y, sizeof(const double *)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_write(conn, A, sizeof(double)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, A, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCgeru_v2(cublasHandle_t handle, int m, int n,
                              const cuComplex *alpha, const cuComplex *x,
                              int incx, const cuComplex *y, int incy,
                              cuComplex *A, int lda) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCgeru_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &y, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_write(conn, A, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, A, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCgeru_v2_64(cublasHandle_t handle, int64_t m, int64_t n,
                                 const cuComplex *alpha, const cuComplex *x,
                                 int64_t incx, const cuComplex *y, int64_t incy,
                                 cuComplex *A, int64_t lda) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCgeru_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &y, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_write(conn, A, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, A, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCgerc_v2(cublasHandle_t handle, int m, int n,
                              const cuComplex *alpha, const cuComplex *x,
                              int incx, const cuComplex *y, int incy,
                              cuComplex *A, int lda) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCgerc_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &y, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_write(conn, A, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, A, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCgerc_v2_64(cublasHandle_t handle, int64_t m, int64_t n,
                                 const cuComplex *alpha, const cuComplex *x,
                                 int64_t incx, const cuComplex *y, int64_t incy,
                                 cuComplex *A, int64_t lda) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCgerc_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &y, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_write(conn, A, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, A, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZgeru_v2(cublasHandle_t handle, int m, int n,
                              const cuDoubleComplex *alpha,
                              const cuDoubleComplex *x, int incx,
                              const cuDoubleComplex *y, int incy,
                              cuDoubleComplex *A, int lda) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZgeru_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &y, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_write(conn, A, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, A, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZgeru_v2_64(cublasHandle_t handle, int64_t m, int64_t n,
                                 const cuDoubleComplex *alpha,
                                 const cuDoubleComplex *x, int64_t incx,
                                 const cuDoubleComplex *y, int64_t incy,
                                 cuDoubleComplex *A, int64_t lda) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZgeru_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &y, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_write(conn, A, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, A, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZgerc_v2(cublasHandle_t handle, int m, int n,
                              const cuDoubleComplex *alpha,
                              const cuDoubleComplex *x, int incx,
                              const cuDoubleComplex *y, int incy,
                              cuDoubleComplex *A, int lda) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZgerc_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &y, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_write(conn, A, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, A, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZgerc_v2_64(cublasHandle_t handle, int64_t m, int64_t n,
                                 const cuDoubleComplex *alpha,
                                 const cuDoubleComplex *x, int64_t incx,
                                 const cuDoubleComplex *y, int64_t incy,
                                 cuDoubleComplex *A, int64_t lda) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZgerc_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &y, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_write(conn, A, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, A, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSsyr_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                             int n, const float *alpha, const float *x,
                             int incx, float *A, int lda) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSsyr_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &x, sizeof(const float *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, A, sizeof(float)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, A, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSsyr_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                int64_t n, const float *alpha, const float *x,
                                int64_t incx, float *A, int64_t lda) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSsyr_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &x, sizeof(const float *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, A, sizeof(float)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, A, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDsyr_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                             int n, const double *alpha, const double *x,
                             int incx, double *A, int lda) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDsyr_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      rpc_write(conn, &x, sizeof(const double *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, A, sizeof(double)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, A, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDsyr_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                int64_t n, const double *alpha, const double *x,
                                int64_t incx, double *A, int64_t lda) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDsyr_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      rpc_write(conn, &x, sizeof(const double *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, A, sizeof(double)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, A, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCsyr_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                             int n, const cuComplex *alpha, const cuComplex *x,
                             int incx, cuComplex *A, int lda) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCsyr_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, A, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, A, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCsyr_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                int64_t n, const cuComplex *alpha,
                                const cuComplex *x, int64_t incx, cuComplex *A,
                                int64_t lda) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCsyr_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, A, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, A, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZsyr_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                             int n, const cuDoubleComplex *alpha,
                             const cuDoubleComplex *x, int incx,
                             cuDoubleComplex *A, int lda) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZsyr_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, A, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, A, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZsyr_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                int64_t n, const cuDoubleComplex *alpha,
                                const cuDoubleComplex *x, int64_t incx,
                                cuDoubleComplex *A, int64_t lda) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZsyr_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, A, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, A, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCher_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                             int n, const float *alpha, const cuComplex *x,
                             int incx, cuComplex *A, int lda) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCher_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, A, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, A, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCher_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                int64_t n, const float *alpha,
                                const cuComplex *x, int64_t incx, cuComplex *A,
                                int64_t lda) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCher_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, A, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, A, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZher_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                             int n, const double *alpha,
                             const cuDoubleComplex *x, int incx,
                             cuDoubleComplex *A, int lda) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZher_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, A, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, A, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZher_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                int64_t n, const double *alpha,
                                const cuDoubleComplex *x, int64_t incx,
                                cuDoubleComplex *A, int64_t lda) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZher_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, A, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, A, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSspr_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                             int n, const float *alpha, const float *x,
                             int incx, float *AP) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSspr_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &x, sizeof(const float *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, AP, sizeof(float)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, AP, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSspr_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                int64_t n, const float *alpha, const float *x,
                                int64_t incx, float *AP) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSspr_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &x, sizeof(const float *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, AP, sizeof(float)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, AP, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDspr_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                             int n, const double *alpha, const double *x,
                             int incx, double *AP) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDspr_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      rpc_write(conn, &x, sizeof(const double *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, AP, sizeof(double)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, AP, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDspr_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                int64_t n, const double *alpha, const double *x,
                                int64_t incx, double *AP) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDspr_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      rpc_write(conn, &x, sizeof(const double *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, AP, sizeof(double)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, AP, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasChpr_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                             int n, const float *alpha, const cuComplex *x,
                             int incx, cuComplex *AP) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasChpr_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, AP, sizeof(cuComplex)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, AP, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasChpr_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                int64_t n, const float *alpha,
                                const cuComplex *x, int64_t incx,
                                cuComplex *AP) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasChpr_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, AP, sizeof(cuComplex)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, AP, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZhpr_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                             int n, const double *alpha,
                             const cuDoubleComplex *x, int incx,
                             cuDoubleComplex *AP) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZhpr_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, AP, sizeof(cuDoubleComplex)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, AP, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZhpr_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                int64_t n, const double *alpha,
                                const cuDoubleComplex *x, int64_t incx,
                                cuDoubleComplex *AP) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZhpr_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, AP, sizeof(cuDoubleComplex)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, AP, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSsyr2_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              int n, const float *alpha, const float *x,
                              int incx, const float *y, int incy, float *A,
                              int lda) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSsyr2_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &x, sizeof(const float *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &y, sizeof(const float *)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_write(conn, A, sizeof(float)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, A, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSsyr2_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 int64_t n, const float *alpha, const float *x,
                                 int64_t incx, const float *y, int64_t incy,
                                 float *A, int64_t lda) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSsyr2_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &x, sizeof(const float *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &y, sizeof(const float *)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_write(conn, A, sizeof(float)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, A, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDsyr2_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              int n, const double *alpha, const double *x,
                              int incx, const double *y, int incy, double *A,
                              int lda) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDsyr2_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      rpc_write(conn, &x, sizeof(const double *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &y, sizeof(const double *)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_write(conn, A, sizeof(double)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, A, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDsyr2_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 int64_t n, const double *alpha,
                                 const double *x, int64_t incx, const double *y,
                                 int64_t incy, double *A, int64_t lda) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDsyr2_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      rpc_write(conn, &x, sizeof(const double *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &y, sizeof(const double *)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_write(conn, A, sizeof(double)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, A, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCsyr2_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              int n, const cuComplex *alpha, const cuComplex *x,
                              int incx, const cuComplex *y, int incy,
                              cuComplex *A, int lda) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCsyr2_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &y, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_write(conn, A, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, A, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCsyr2_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 int64_t n, const cuComplex *alpha,
                                 const cuComplex *x, int64_t incx,
                                 const cuComplex *y, int64_t incy, cuComplex *A,
                                 int64_t lda) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCsyr2_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &y, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_write(conn, A, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, A, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZsyr2_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              int n, const cuDoubleComplex *alpha,
                              const cuDoubleComplex *x, int incx,
                              const cuDoubleComplex *y, int incy,
                              cuDoubleComplex *A, int lda) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZsyr2_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &y, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_write(conn, A, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, A, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZsyr2_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 int64_t n, const cuDoubleComplex *alpha,
                                 const cuDoubleComplex *x, int64_t incx,
                                 const cuDoubleComplex *y, int64_t incy,
                                 cuDoubleComplex *A, int64_t lda) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZsyr2_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &y, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_write(conn, A, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, A, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCher2_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              int n, const cuComplex *alpha, const cuComplex *x,
                              int incx, const cuComplex *y, int incy,
                              cuComplex *A, int lda) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCher2_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &y, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_write(conn, A, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, A, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCher2_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 int64_t n, const cuComplex *alpha,
                                 const cuComplex *x, int64_t incx,
                                 const cuComplex *y, int64_t incy, cuComplex *A,
                                 int64_t lda) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCher2_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &y, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_write(conn, A, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, A, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZher2_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              int n, const cuDoubleComplex *alpha,
                              const cuDoubleComplex *x, int incx,
                              const cuDoubleComplex *y, int incy,
                              cuDoubleComplex *A, int lda) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZher2_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &y, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_write(conn, A, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, A, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZher2_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 int64_t n, const cuDoubleComplex *alpha,
                                 const cuDoubleComplex *x, int64_t incx,
                                 const cuDoubleComplex *y, int64_t incy,
                                 cuDoubleComplex *A, int64_t lda) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZher2_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &y, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_write(conn, A, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, A, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSspr2_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              int n, const float *alpha, const float *x,
                              int incx, const float *y, int incy, float *AP) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSspr2_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &x, sizeof(const float *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &y, sizeof(const float *)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_write(conn, AP, sizeof(float)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, AP, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSspr2_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 int64_t n, const float *alpha, const float *x,
                                 int64_t incx, const float *y, int64_t incy,
                                 float *AP) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSspr2_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &x, sizeof(const float *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &y, sizeof(const float *)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_write(conn, AP, sizeof(float)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, AP, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDspr2_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              int n, const double *alpha, const double *x,
                              int incx, const double *y, int incy, double *AP) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDspr2_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      rpc_write(conn, &x, sizeof(const double *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &y, sizeof(const double *)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_write(conn, AP, sizeof(double)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, AP, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDspr2_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 int64_t n, const double *alpha,
                                 const double *x, int64_t incx, const double *y,
                                 int64_t incy, double *AP) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDspr2_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      rpc_write(conn, &x, sizeof(const double *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &y, sizeof(const double *)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_write(conn, AP, sizeof(double)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, AP, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasChpr2_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              int n, const cuComplex *alpha, const cuComplex *x,
                              int incx, const cuComplex *y, int incy,
                              cuComplex *AP) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasChpr2_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &y, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_write(conn, AP, sizeof(cuComplex)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, AP, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasChpr2_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 int64_t n, const cuComplex *alpha,
                                 const cuComplex *x, int64_t incx,
                                 const cuComplex *y, int64_t incy,
                                 cuComplex *AP) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasChpr2_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &y, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_write(conn, AP, sizeof(cuComplex)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, AP, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZhpr2_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              int n, const cuDoubleComplex *alpha,
                              const cuDoubleComplex *x, int incx,
                              const cuDoubleComplex *y, int incy,
                              cuDoubleComplex *AP) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZhpr2_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &y, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_write(conn, AP, sizeof(cuDoubleComplex)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, AP, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZhpr2_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 int64_t n, const cuDoubleComplex *alpha,
                                 const cuDoubleComplex *x, int64_t incx,
                                 const cuDoubleComplex *y, int64_t incy,
                                 cuDoubleComplex *AP) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZhpr2_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &y, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_write(conn, AP, sizeof(cuDoubleComplex)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, AP, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t
cublasSgemvStridedBatched(cublasHandle_t handle, cublasOperation_t trans, int m,
                          int n, const float *alpha, const float *A, int lda,
                          long long int strideA, const float *x, int incx,
                          long long int stridex, const float *beta, float *y,
                          int incy, long long int stridey, int batchCount) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridex, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridey, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSgemvStridedBatched) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &A, sizeof(const float *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &strideA, sizeof(long long int)) < 0 ||
      rpc_write(conn, &x, sizeof(const float *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &stridex, sizeof(long long int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const float *)) < 0 ||
      rpc_write(conn, y, sizeof(float)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_write(conn, &stridey, sizeof(long long int)) < 0 ||
      rpc_write(conn, &batchCount, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, y, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridex, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridey, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSgemvStridedBatched_64(
    cublasHandle_t handle, cublasOperation_t trans, int64_t m, int64_t n,
    const float *alpha, const float *A, int64_t lda, long long int strideA,
    const float *x, int64_t incx, long long int stridex, const float *beta,
    float *y, int64_t incy, long long int stridey, int64_t batchCount) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridex, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridey, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSgemvStridedBatched_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &A, sizeof(const float *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &strideA, sizeof(long long int)) < 0 ||
      rpc_write(conn, &x, sizeof(const float *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &stridex, sizeof(long long int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const float *)) < 0 ||
      rpc_write(conn, y, sizeof(float)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &stridey, sizeof(long long int)) < 0 ||
      rpc_write(conn, &batchCount, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, y, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridex, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridey, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t
cublasDgemvStridedBatched(cublasHandle_t handle, cublasOperation_t trans, int m,
                          int n, const double *alpha, const double *A, int lda,
                          long long int strideA, const double *x, int incx,
                          long long int stridex, const double *beta, double *y,
                          int incy, long long int stridey, int batchCount) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridex, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridey, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDgemvStridedBatched) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      rpc_write(conn, &A, sizeof(const double *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &strideA, sizeof(long long int)) < 0 ||
      rpc_write(conn, &x, sizeof(const double *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &stridex, sizeof(long long int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const double *)) < 0 ||
      rpc_write(conn, y, sizeof(double)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_write(conn, &stridey, sizeof(long long int)) < 0 ||
      rpc_write(conn, &batchCount, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridex, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridey, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDgemvStridedBatched_64(
    cublasHandle_t handle, cublasOperation_t trans, int64_t m, int64_t n,
    const double *alpha, const double *A, int64_t lda, long long int strideA,
    const double *x, int64_t incx, long long int stridex, const double *beta,
    double *y, int64_t incy, long long int stridey, int64_t batchCount) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridex, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridey, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDgemvStridedBatched_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      rpc_write(conn, &A, sizeof(const double *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &strideA, sizeof(long long int)) < 0 ||
      rpc_write(conn, &x, sizeof(const double *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &stridex, sizeof(long long int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const double *)) < 0 ||
      rpc_write(conn, y, sizeof(double)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &stridey, sizeof(long long int)) < 0 ||
      rpc_write(conn, &batchCount, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridex, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridey, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCgemvStridedBatched(
    cublasHandle_t handle, cublasOperation_t trans, int m, int n,
    const cuComplex *alpha, const cuComplex *A, int lda, long long int strideA,
    const cuComplex *x, int incx, long long int stridex, const cuComplex *beta,
    cuComplex *y, int incy, long long int stridey, int batchCount) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridex, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridey, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCgemvStridedBatched) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &strideA, sizeof(long long int)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &stridex, sizeof(long long int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, y, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_write(conn, &stridey, sizeof(long long int)) < 0 ||
      rpc_write(conn, &batchCount, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridex, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridey, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCgemvStridedBatched_64(
    cublasHandle_t handle, cublasOperation_t trans, int64_t m, int64_t n,
    const cuComplex *alpha, const cuComplex *A, int64_t lda,
    long long int strideA, const cuComplex *x, int64_t incx,
    long long int stridex, const cuComplex *beta, cuComplex *y, int64_t incy,
    long long int stridey, int64_t batchCount) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridex, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridey, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCgemvStridedBatched_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &strideA, sizeof(long long int)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &stridex, sizeof(long long int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, y, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &stridey, sizeof(long long int)) < 0 ||
      rpc_write(conn, &batchCount, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridex, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridey, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZgemvStridedBatched(
    cublasHandle_t handle, cublasOperation_t trans, int m, int n,
    const cuDoubleComplex *alpha, const cuDoubleComplex *A, int lda,
    long long int strideA, const cuDoubleComplex *x, int incx,
    long long int stridex, const cuDoubleComplex *beta, cuDoubleComplex *y,
    int incy, long long int stridey, int batchCount) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridex, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridey, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZgemvStridedBatched) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &strideA, sizeof(long long int)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &stridex, sizeof(long long int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, y, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_write(conn, &stridey, sizeof(long long int)) < 0 ||
      rpc_write(conn, &batchCount, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridex, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridey, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZgemvStridedBatched_64(
    cublasHandle_t handle, cublasOperation_t trans, int64_t m, int64_t n,
    const cuDoubleComplex *alpha, const cuDoubleComplex *A, int64_t lda,
    long long int strideA, const cuDoubleComplex *x, int64_t incx,
    long long int stridex, const cuDoubleComplex *beta, cuDoubleComplex *y,
    int64_t incy, long long int stridey, int64_t batchCount) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridex, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridey, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZgemvStridedBatched_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &strideA, sizeof(long long int)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &stridex, sizeof(long long int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, y, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &stridey, sizeof(long long int)) < 0 ||
      rpc_write(conn, &batchCount, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridex, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridey, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasHSHgemvStridedBatched(
    cublasHandle_t handle, cublasOperation_t trans, int m, int n,
    const float *alpha, const __half *A, int lda, long long int strideA,
    const __half *x, int incx, long long int stridex, const float *beta,
    __half *y, int incy, long long int stridey, int batchCount) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridex, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridey, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasHSHgemvStridedBatched) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &A, sizeof(const __half *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &strideA, sizeof(long long int)) < 0 ||
      rpc_write(conn, &x, sizeof(const __half *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &stridex, sizeof(long long int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const float *)) < 0 ||
      rpc_write(conn, y, sizeof(__half)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_write(conn, &stridey, sizeof(long long int)) < 0 ||
      rpc_write(conn, &batchCount, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(__half)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridex, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridey, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasHSHgemvStridedBatched_64(
    cublasHandle_t handle, cublasOperation_t trans, int64_t m, int64_t n,
    const float *alpha, const __half *A, int64_t lda, long long int strideA,
    const __half *x, int64_t incx, long long int stridex, const float *beta,
    __half *y, int64_t incy, long long int stridey, int64_t batchCount) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridex, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridey, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasHSHgemvStridedBatched_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &A, sizeof(const __half *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &strideA, sizeof(long long int)) < 0 ||
      rpc_write(conn, &x, sizeof(const __half *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &stridex, sizeof(long long int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const float *)) < 0 ||
      rpc_write(conn, y, sizeof(__half)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &stridey, sizeof(long long int)) < 0 ||
      rpc_write(conn, &batchCount, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(__half)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridex, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridey, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasHSSgemvStridedBatched(
    cublasHandle_t handle, cublasOperation_t trans, int m, int n,
    const float *alpha, const __half *A, int lda, long long int strideA,
    const __half *x, int incx, long long int stridex, const float *beta,
    float *y, int incy, long long int stridey, int batchCount) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridex, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridey, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasHSSgemvStridedBatched) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &A, sizeof(const __half *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &strideA, sizeof(long long int)) < 0 ||
      rpc_write(conn, &x, sizeof(const __half *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &stridex, sizeof(long long int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const float *)) < 0 ||
      rpc_write(conn, y, sizeof(float)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_write(conn, &stridey, sizeof(long long int)) < 0 ||
      rpc_write(conn, &batchCount, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, y, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridex, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridey, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasHSSgemvStridedBatched_64(
    cublasHandle_t handle, cublasOperation_t trans, int64_t m, int64_t n,
    const float *alpha, const __half *A, int64_t lda, long long int strideA,
    const __half *x, int64_t incx, long long int stridex, const float *beta,
    float *y, int64_t incy, long long int stridey, int64_t batchCount) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridex, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridey, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasHSSgemvStridedBatched_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &A, sizeof(const __half *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &strideA, sizeof(long long int)) < 0 ||
      rpc_write(conn, &x, sizeof(const __half *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &stridex, sizeof(long long int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const float *)) < 0 ||
      rpc_write(conn, y, sizeof(float)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &stridey, sizeof(long long int)) < 0 ||
      rpc_write(conn, &batchCount, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, y, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridex, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridey, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasTSTgemvStridedBatched(
    cublasHandle_t handle, cublasOperation_t trans, int m, int n,
    const float *alpha, const __nv_bfloat16 *A, int lda, long long int strideA,
    const __nv_bfloat16 *x, int incx, long long int stridex, const float *beta,
    __nv_bfloat16 *y, int incy, long long int stridey, int batchCount) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridex, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridey, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasTSTgemvStridedBatched) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &A, sizeof(const __nv_bfloat16 *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &strideA, sizeof(long long int)) < 0 ||
      rpc_write(conn, &x, sizeof(const __nv_bfloat16 *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &stridex, sizeof(long long int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const float *)) < 0 ||
      rpc_write(conn, y, sizeof(__nv_bfloat16)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_write(conn, &stridey, sizeof(long long int)) < 0 ||
      rpc_write(conn, &batchCount, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(__nv_bfloat16)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridex, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridey, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasTSTgemvStridedBatched_64(
    cublasHandle_t handle, cublasOperation_t trans, int64_t m, int64_t n,
    const float *alpha, const __nv_bfloat16 *A, int64_t lda,
    long long int strideA, const __nv_bfloat16 *x, int64_t incx,
    long long int stridex, const float *beta, __nv_bfloat16 *y, int64_t incy,
    long long int stridey, int64_t batchCount) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridex, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridey, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasTSTgemvStridedBatched_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &A, sizeof(const __nv_bfloat16 *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &strideA, sizeof(long long int)) < 0 ||
      rpc_write(conn, &x, sizeof(const __nv_bfloat16 *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &stridex, sizeof(long long int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const float *)) < 0 ||
      rpc_write(conn, y, sizeof(__nv_bfloat16)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &stridey, sizeof(long long int)) < 0 ||
      rpc_write(conn, &batchCount, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, y, sizeof(__nv_bfloat16)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridex, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridey, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasTSSgemvStridedBatched(
    cublasHandle_t handle, cublasOperation_t trans, int m, int n,
    const float *alpha, const __nv_bfloat16 *A, int lda, long long int strideA,
    const __nv_bfloat16 *x, int incx, long long int stridex, const float *beta,
    float *y, int incy, long long int stridey, int batchCount) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridex, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridey, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasTSSgemvStridedBatched) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &A, sizeof(const __nv_bfloat16 *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &strideA, sizeof(long long int)) < 0 ||
      rpc_write(conn, &x, sizeof(const __nv_bfloat16 *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, &stridex, sizeof(long long int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const float *)) < 0 ||
      rpc_write(conn, y, sizeof(float)) < 0 ||
      rpc_write(conn, &incy, sizeof(int)) < 0 ||
      rpc_write(conn, &stridey, sizeof(long long int)) < 0 ||
      rpc_write(conn, &batchCount, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, y, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridex, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridey, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasTSSgemvStridedBatched_64(
    cublasHandle_t handle, cublasOperation_t trans, int64_t m, int64_t n,
    const float *alpha, const __nv_bfloat16 *A, int64_t lda,
    long long int strideA, const __nv_bfloat16 *x, int64_t incx,
    long long int stridex, const float *beta, float *y, int64_t incy,
    long long int stridey, int64_t batchCount) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridex, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridey, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasTSSgemvStridedBatched_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &A, sizeof(const __nv_bfloat16 *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &strideA, sizeof(long long int)) < 0 ||
      rpc_write(conn, &x, sizeof(const __nv_bfloat16 *)) < 0 ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &stridex, sizeof(long long int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const float *)) < 0 ||
      rpc_write(conn, y, sizeof(float)) < 0 ||
      rpc_write(conn, &incy, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &stridey, sizeof(long long int)) < 0 ||
      rpc_write(conn, &batchCount, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, y, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridex, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incy, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stridey, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSgemm_v2(cublasHandle_t handle, cublasOperation_t transa,
                              cublasOperation_t transb, int m, int n, int k,
                              const float *alpha, const float *A, int lda,
                              const float *B, int ldb, const float *beta,
                              float *C, int ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSgemm_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &transa, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &transb, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &k, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      (alpha != nullptr && rpc_write(conn, alpha, sizeof(const float)) < 0) ||
      rpc_write(conn, &A, sizeof(const float *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &B, sizeof(const float *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const float *)) < 0 ||
      (beta != nullptr && rpc_write(conn, beta, sizeof(const float)) < 0) ||
      rpc_write(conn, &C, sizeof(float *)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSgemm_v2_64(cublasHandle_t handle,
                                 cublasOperation_t transa,
                                 cublasOperation_t transb, int64_t m, int64_t n,
                                 int64_t k, const float *alpha, const float *A,
                                 int64_t lda, const float *B, int64_t ldb,
                                 const float *beta, float *C, int64_t ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSgemm_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &transa, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &transb, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &k, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &A, sizeof(const float *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &B, sizeof(const float *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const float *)) < 0 ||
      rpc_write(conn, C, sizeof(float)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, C, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDgemm_v2(cublasHandle_t handle, cublasOperation_t transa,
                              cublasOperation_t transb, int m, int n, int k,
                              const double *alpha, const double *A, int lda,
                              const double *B, int ldb, const double *beta,
                              double *C, int ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDgemm_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &transa, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &transb, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &k, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      rpc_write(conn, &A, sizeof(const double *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &B, sizeof(const double *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const double *)) < 0 ||
      rpc_write(conn, C, sizeof(double)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDgemm_v2_64(cublasHandle_t handle,
                                 cublasOperation_t transa,
                                 cublasOperation_t transb, int64_t m, int64_t n,
                                 int64_t k, const double *alpha,
                                 const double *A, int64_t lda, const double *B,
                                 int64_t ldb, const double *beta, double *C,
                                 int64_t ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDgemm_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &transa, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &transb, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &k, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      rpc_write(conn, &A, sizeof(const double *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &B, sizeof(const double *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const double *)) < 0 ||
      rpc_write(conn, C, sizeof(double)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCgemm_v2(cublasHandle_t handle, cublasOperation_t transa,
                              cublasOperation_t transb, int m, int n, int k,
                              const cuComplex *alpha, const cuComplex *A,
                              int lda, const cuComplex *B, int ldb,
                              const cuComplex *beta, cuComplex *C, int ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCgemm_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &transa, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &transb, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &k, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &B, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t
cublasCgemm_v2_64(cublasHandle_t handle, cublasOperation_t transa,
                  cublasOperation_t transb, int64_t m, int64_t n, int64_t k,
                  const cuComplex *alpha, const cuComplex *A, int64_t lda,
                  const cuComplex *B, int64_t ldb, const cuComplex *beta,
                  cuComplex *C, int64_t ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCgemm_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &transa, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &transb, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &k, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &B, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCgemm3m(cublasHandle_t handle, cublasOperation_t transa,
                             cublasOperation_t transb, int m, int n, int k,
                             const cuComplex *alpha, const cuComplex *A,
                             int lda, const cuComplex *B, int ldb,
                             const cuComplex *beta, cuComplex *C, int ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCgemm3m) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &transa, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &transb, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &k, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &B, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCgemm3m_64(cublasHandle_t handle, cublasOperation_t transa,
                                cublasOperation_t transb, int64_t m, int64_t n,
                                int64_t k, const cuComplex *alpha,
                                const cuComplex *A, int64_t lda,
                                const cuComplex *B, int64_t ldb,
                                const cuComplex *beta, cuComplex *C,
                                int64_t ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCgemm3m_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &transa, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &transb, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &k, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &B, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZgemm_v2(cublasHandle_t handle, cublasOperation_t transa,
                              cublasOperation_t transb, int m, int n, int k,
                              const cuDoubleComplex *alpha,
                              const cuDoubleComplex *A, int lda,
                              const cuDoubleComplex *B, int ldb,
                              const cuDoubleComplex *beta, cuDoubleComplex *C,
                              int ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZgemm_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &transa, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &transb, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &k, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &B, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZgemm_v2_64(
    cublasHandle_t handle, cublasOperation_t transa, cublasOperation_t transb,
    int64_t m, int64_t n, int64_t k, const cuDoubleComplex *alpha,
    const cuDoubleComplex *A, int64_t lda, const cuDoubleComplex *B,
    int64_t ldb, const cuDoubleComplex *beta, cuDoubleComplex *C, int64_t ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZgemm_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &transa, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &transb, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &k, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &B, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZgemm3m(cublasHandle_t handle, cublasOperation_t transa,
                             cublasOperation_t transb, int m, int n, int k,
                             const cuDoubleComplex *alpha,
                             const cuDoubleComplex *A, int lda,
                             const cuDoubleComplex *B, int ldb,
                             const cuDoubleComplex *beta, cuDoubleComplex *C,
                             int ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZgemm3m) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &transa, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &transb, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &k, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &B, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZgemm3m_64(cublasHandle_t handle, cublasOperation_t transa,
                                cublasOperation_t transb, int64_t m, int64_t n,
                                int64_t k, const cuDoubleComplex *alpha,
                                const cuDoubleComplex *A, int64_t lda,
                                const cuDoubleComplex *B, int64_t ldb,
                                const cuDoubleComplex *beta, cuDoubleComplex *C,
                                int64_t ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZgemm3m_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &transa, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &transb, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &k, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &B, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasHgemm(cublasHandle_t handle, cublasOperation_t transa,
                           cublasOperation_t transb, int m, int n, int k,
                           const __half *alpha, const __half *A, int lda,
                           const __half *B, int ldb, const __half *beta,
                           __half *C, int ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasHgemm) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &transa, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &transb, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &k, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const __half *)) < 0 ||
      rpc_write(conn, &A, sizeof(const __half *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &B, sizeof(const __half *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const __half *)) < 0 ||
      rpc_write(conn, C, sizeof(__half)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(__half)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasHgemm_64(cublasHandle_t handle, cublasOperation_t transa,
                              cublasOperation_t transb, int64_t m, int64_t n,
                              int64_t k, const __half *alpha, const __half *A,
                              int64_t lda, const __half *B, int64_t ldb,
                              const __half *beta, __half *C, int64_t ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasHgemm_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &transa, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &transb, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &k, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const __half *)) < 0 ||
      rpc_write(conn, &A, sizeof(const __half *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &B, sizeof(const __half *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const __half *)) < 0 ||
      rpc_write(conn, C, sizeof(__half)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(__half)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSsyrk_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              cublasOperation_t trans, int n, int k,
                              const float *alpha, const float *A, int lda,
                              const float *beta, float *C, int ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSsyrk_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &k, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &A, sizeof(const float *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const float *)) < 0 ||
      rpc_write(conn, C, sizeof(float)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, C, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSsyrk_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 cublasOperation_t trans, int64_t n, int64_t k,
                                 const float *alpha, const float *A,
                                 int64_t lda, const float *beta, float *C,
                                 int64_t ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSsyrk_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &k, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &A, sizeof(const float *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const float *)) < 0 ||
      rpc_write(conn, C, sizeof(float)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, C, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDsyrk_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              cublasOperation_t trans, int n, int k,
                              const double *alpha, const double *A, int lda,
                              const double *beta, double *C, int ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDsyrk_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &k, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      rpc_write(conn, &A, sizeof(const double *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const double *)) < 0 ||
      rpc_write(conn, C, sizeof(double)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDsyrk_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 cublasOperation_t trans, int64_t n, int64_t k,
                                 const double *alpha, const double *A,
                                 int64_t lda, const double *beta, double *C,
                                 int64_t ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDsyrk_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &k, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      rpc_write(conn, &A, sizeof(const double *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const double *)) < 0 ||
      rpc_write(conn, C, sizeof(double)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCsyrk_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              cublasOperation_t trans, int n, int k,
                              const cuComplex *alpha, const cuComplex *A,
                              int lda, const cuComplex *beta, cuComplex *C,
                              int ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCsyrk_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &k, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCsyrk_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 cublasOperation_t trans, int64_t n, int64_t k,
                                 const cuComplex *alpha, const cuComplex *A,
                                 int64_t lda, const cuComplex *beta,
                                 cuComplex *C, int64_t ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCsyrk_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &k, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZsyrk_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              cublasOperation_t trans, int n, int k,
                              const cuDoubleComplex *alpha,
                              const cuDoubleComplex *A, int lda,
                              const cuDoubleComplex *beta, cuDoubleComplex *C,
                              int ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZsyrk_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &k, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZsyrk_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 cublasOperation_t trans, int64_t n, int64_t k,
                                 const cuDoubleComplex *alpha,
                                 const cuDoubleComplex *A, int64_t lda,
                                 const cuDoubleComplex *beta,
                                 cuDoubleComplex *C, int64_t ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZsyrk_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &k, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCherk_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              cublasOperation_t trans, int n, int k,
                              const float *alpha, const cuComplex *A, int lda,
                              const float *beta, cuComplex *C, int ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCherk_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &k, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const float *)) < 0 ||
      rpc_write(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCherk_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 cublasOperation_t trans, int64_t n, int64_t k,
                                 const float *alpha, const cuComplex *A,
                                 int64_t lda, const float *beta, cuComplex *C,
                                 int64_t ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCherk_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &k, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const float *)) < 0 ||
      rpc_write(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZherk_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                              cublasOperation_t trans, int n, int k,
                              const double *alpha, const cuDoubleComplex *A,
                              int lda, const double *beta, cuDoubleComplex *C,
                              int ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZherk_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &k, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const double *)) < 0 ||
      rpc_write(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZherk_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                 cublasOperation_t trans, int64_t n, int64_t k,
                                 const double *alpha, const cuDoubleComplex *A,
                                 int64_t lda, const double *beta,
                                 cuDoubleComplex *C, int64_t ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZherk_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &k, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const double *)) < 0 ||
      rpc_write(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSsyr2k_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                               cublasOperation_t trans, int n, int k,
                               const float *alpha, const float *A, int lda,
                               const float *B, int ldb, const float *beta,
                               float *C, int ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSsyr2k_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &k, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &A, sizeof(const float *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &B, sizeof(const float *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const float *)) < 0 ||
      rpc_write(conn, C, sizeof(float)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, C, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSsyr2k_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                  cublasOperation_t trans, int64_t n, int64_t k,
                                  const float *alpha, const float *A,
                                  int64_t lda, const float *B, int64_t ldb,
                                  const float *beta, float *C, int64_t ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSsyr2k_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &k, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &A, sizeof(const float *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &B, sizeof(const float *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const float *)) < 0 ||
      rpc_write(conn, C, sizeof(float)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, C, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDsyr2k_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                               cublasOperation_t trans, int n, int k,
                               const double *alpha, const double *A, int lda,
                               const double *B, int ldb, const double *beta,
                               double *C, int ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDsyr2k_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &k, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      rpc_write(conn, &A, sizeof(const double *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &B, sizeof(const double *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const double *)) < 0 ||
      rpc_write(conn, C, sizeof(double)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDsyr2k_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                  cublasOperation_t trans, int64_t n, int64_t k,
                                  const double *alpha, const double *A,
                                  int64_t lda, const double *B, int64_t ldb,
                                  const double *beta, double *C, int64_t ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDsyr2k_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &k, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      rpc_write(conn, &A, sizeof(const double *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &B, sizeof(const double *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const double *)) < 0 ||
      rpc_write(conn, C, sizeof(double)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCsyr2k_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                               cublasOperation_t trans, int n, int k,
                               const cuComplex *alpha, const cuComplex *A,
                               int lda, const cuComplex *B, int ldb,
                               const cuComplex *beta, cuComplex *C, int ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCsyr2k_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &k, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &B, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCsyr2k_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                  cublasOperation_t trans, int64_t n, int64_t k,
                                  const cuComplex *alpha, const cuComplex *A,
                                  int64_t lda, const cuComplex *B, int64_t ldb,
                                  const cuComplex *beta, cuComplex *C,
                                  int64_t ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCsyr2k_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &k, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &B, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZsyr2k_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                               cublasOperation_t trans, int n, int k,
                               const cuDoubleComplex *alpha,
                               const cuDoubleComplex *A, int lda,
                               const cuDoubleComplex *B, int ldb,
                               const cuDoubleComplex *beta, cuDoubleComplex *C,
                               int ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZsyr2k_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &k, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &B, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZsyr2k_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                  cublasOperation_t trans, int64_t n, int64_t k,
                                  const cuDoubleComplex *alpha,
                                  const cuDoubleComplex *A, int64_t lda,
                                  const cuDoubleComplex *B, int64_t ldb,
                                  const cuDoubleComplex *beta,
                                  cuDoubleComplex *C, int64_t ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZsyr2k_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &k, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &B, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCher2k_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                               cublasOperation_t trans, int n, int k,
                               const cuComplex *alpha, const cuComplex *A,
                               int lda, const cuComplex *B, int ldb,
                               const float *beta, cuComplex *C, int ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCher2k_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &k, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &B, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const float *)) < 0 ||
      rpc_write(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCher2k_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                  cublasOperation_t trans, int64_t n, int64_t k,
                                  const cuComplex *alpha, const cuComplex *A,
                                  int64_t lda, const cuComplex *B, int64_t ldb,
                                  const float *beta, cuComplex *C,
                                  int64_t ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCher2k_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &k, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &B, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const float *)) < 0 ||
      rpc_write(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZher2k_v2(cublasHandle_t handle, cublasFillMode_t uplo,
                               cublasOperation_t trans, int n, int k,
                               const cuDoubleComplex *alpha,
                               const cuDoubleComplex *A, int lda,
                               const cuDoubleComplex *B, int ldb,
                               const double *beta, cuDoubleComplex *C,
                               int ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZher2k_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &k, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &B, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const double *)) < 0 ||
      rpc_write(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZher2k_v2_64(cublasHandle_t handle, cublasFillMode_t uplo,
                                  cublasOperation_t trans, int64_t n, int64_t k,
                                  const cuDoubleComplex *alpha,
                                  const cuDoubleComplex *A, int64_t lda,
                                  const cuDoubleComplex *B, int64_t ldb,
                                  const double *beta, cuDoubleComplex *C,
                                  int64_t ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZher2k_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &k, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &B, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const double *)) < 0 ||
      rpc_write(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSsyrkx(cublasHandle_t handle, cublasFillMode_t uplo,
                            cublasOperation_t trans, int n, int k,
                            const float *alpha, const float *A, int lda,
                            const float *B, int ldb, const float *beta,
                            float *C, int ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSsyrkx) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &k, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &A, sizeof(const float *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &B, sizeof(const float *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const float *)) < 0 ||
      rpc_write(conn, C, sizeof(float)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, C, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSsyrkx_64(cublasHandle_t handle, cublasFillMode_t uplo,
                               cublasOperation_t trans, int64_t n, int64_t k,
                               const float *alpha, const float *A, int64_t lda,
                               const float *B, int64_t ldb, const float *beta,
                               float *C, int64_t ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSsyrkx_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &k, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &A, sizeof(const float *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &B, sizeof(const float *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const float *)) < 0 ||
      rpc_write(conn, C, sizeof(float)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, C, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDsyrkx(cublasHandle_t handle, cublasFillMode_t uplo,
                            cublasOperation_t trans, int n, int k,
                            const double *alpha, const double *A, int lda,
                            const double *B, int ldb, const double *beta,
                            double *C, int ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDsyrkx) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &k, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      rpc_write(conn, &A, sizeof(const double *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &B, sizeof(const double *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const double *)) < 0 ||
      rpc_write(conn, C, sizeof(double)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDsyrkx_64(cublasHandle_t handle, cublasFillMode_t uplo,
                               cublasOperation_t trans, int64_t n, int64_t k,
                               const double *alpha, const double *A,
                               int64_t lda, const double *B, int64_t ldb,
                               const double *beta, double *C, int64_t ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDsyrkx_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &k, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      rpc_write(conn, &A, sizeof(const double *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &B, sizeof(const double *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const double *)) < 0 ||
      rpc_write(conn, C, sizeof(double)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCsyrkx(cublasHandle_t handle, cublasFillMode_t uplo,
                            cublasOperation_t trans, int n, int k,
                            const cuComplex *alpha, const cuComplex *A, int lda,
                            const cuComplex *B, int ldb, const cuComplex *beta,
                            cuComplex *C, int ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCsyrkx) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &k, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &B, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCsyrkx_64(cublasHandle_t handle, cublasFillMode_t uplo,
                               cublasOperation_t trans, int64_t n, int64_t k,
                               const cuComplex *alpha, const cuComplex *A,
                               int64_t lda, const cuComplex *B, int64_t ldb,
                               const cuComplex *beta, cuComplex *C,
                               int64_t ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCsyrkx_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &k, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &B, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZsyrkx(cublasHandle_t handle, cublasFillMode_t uplo,
                            cublasOperation_t trans, int n, int k,
                            const cuDoubleComplex *alpha,
                            const cuDoubleComplex *A, int lda,
                            const cuDoubleComplex *B, int ldb,
                            const cuDoubleComplex *beta, cuDoubleComplex *C,
                            int ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZsyrkx) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &k, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &B, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZsyrkx_64(cublasHandle_t handle, cublasFillMode_t uplo,
                               cublasOperation_t trans, int64_t n, int64_t k,
                               const cuDoubleComplex *alpha,
                               const cuDoubleComplex *A, int64_t lda,
                               const cuDoubleComplex *B, int64_t ldb,
                               const cuDoubleComplex *beta, cuDoubleComplex *C,
                               int64_t ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZsyrkx_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &k, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &B, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCherkx(cublasHandle_t handle, cublasFillMode_t uplo,
                            cublasOperation_t trans, int n, int k,
                            const cuComplex *alpha, const cuComplex *A, int lda,
                            const cuComplex *B, int ldb, const float *beta,
                            cuComplex *C, int ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCherkx) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &k, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &B, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const float *)) < 0 ||
      rpc_write(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCherkx_64(cublasHandle_t handle, cublasFillMode_t uplo,
                               cublasOperation_t trans, int64_t n, int64_t k,
                               const cuComplex *alpha, const cuComplex *A,
                               int64_t lda, const cuComplex *B, int64_t ldb,
                               const float *beta, cuComplex *C, int64_t ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCherkx_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &k, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &B, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const float *)) < 0 ||
      rpc_write(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZherkx(cublasHandle_t handle, cublasFillMode_t uplo,
                            cublasOperation_t trans, int n, int k,
                            const cuDoubleComplex *alpha,
                            const cuDoubleComplex *A, int lda,
                            const cuDoubleComplex *B, int ldb,
                            const double *beta, cuDoubleComplex *C, int ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZherkx) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &k, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &B, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const double *)) < 0 ||
      rpc_write(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZherkx_64(cublasHandle_t handle, cublasFillMode_t uplo,
                               cublasOperation_t trans, int64_t n, int64_t k,
                               const cuDoubleComplex *alpha,
                               const cuDoubleComplex *A, int64_t lda,
                               const cuDoubleComplex *B, int64_t ldb,
                               const double *beta, cuDoubleComplex *C,
                               int64_t ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZherkx_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &k, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &B, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const double *)) < 0 ||
      rpc_write(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSsymm_v2(cublasHandle_t handle, cublasSideMode_t side,
                              cublasFillMode_t uplo, int m, int n,
                              const float *alpha, const float *A, int lda,
                              const float *B, int ldb, const float *beta,
                              float *C, int ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSsymm_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &side, sizeof(cublasSideMode_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &A, sizeof(const float *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &B, sizeof(const float *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const float *)) < 0 ||
      rpc_write(conn, C, sizeof(float)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, C, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSsymm_v2_64(cublasHandle_t handle, cublasSideMode_t side,
                                 cublasFillMode_t uplo, int64_t m, int64_t n,
                                 const float *alpha, const float *A,
                                 int64_t lda, const float *B, int64_t ldb,
                                 const float *beta, float *C, int64_t ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSsymm_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &side, sizeof(cublasSideMode_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &A, sizeof(const float *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &B, sizeof(const float *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const float *)) < 0 ||
      rpc_write(conn, C, sizeof(float)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, C, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDsymm_v2(cublasHandle_t handle, cublasSideMode_t side,
                              cublasFillMode_t uplo, int m, int n,
                              const double *alpha, const double *A, int lda,
                              const double *B, int ldb, const double *beta,
                              double *C, int ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDsymm_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &side, sizeof(cublasSideMode_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      rpc_write(conn, &A, sizeof(const double *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &B, sizeof(const double *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const double *)) < 0 ||
      rpc_write(conn, C, sizeof(double)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDsymm_v2_64(cublasHandle_t handle, cublasSideMode_t side,
                                 cublasFillMode_t uplo, int64_t m, int64_t n,
                                 const double *alpha, const double *A,
                                 int64_t lda, const double *B, int64_t ldb,
                                 const double *beta, double *C, int64_t ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDsymm_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &side, sizeof(cublasSideMode_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      rpc_write(conn, &A, sizeof(const double *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &B, sizeof(const double *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const double *)) < 0 ||
      rpc_write(conn, C, sizeof(double)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCsymm_v2(cublasHandle_t handle, cublasSideMode_t side,
                              cublasFillMode_t uplo, int m, int n,
                              const cuComplex *alpha, const cuComplex *A,
                              int lda, const cuComplex *B, int ldb,
                              const cuComplex *beta, cuComplex *C, int ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCsymm_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &side, sizeof(cublasSideMode_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &B, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCsymm_v2_64(cublasHandle_t handle, cublasSideMode_t side,
                                 cublasFillMode_t uplo, int64_t m, int64_t n,
                                 const cuComplex *alpha, const cuComplex *A,
                                 int64_t lda, const cuComplex *B, int64_t ldb,
                                 const cuComplex *beta, cuComplex *C,
                                 int64_t ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCsymm_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &side, sizeof(cublasSideMode_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &B, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZsymm_v2(cublasHandle_t handle, cublasSideMode_t side,
                              cublasFillMode_t uplo, int m, int n,
                              const cuDoubleComplex *alpha,
                              const cuDoubleComplex *A, int lda,
                              const cuDoubleComplex *B, int ldb,
                              const cuDoubleComplex *beta, cuDoubleComplex *C,
                              int ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZsymm_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &side, sizeof(cublasSideMode_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &B, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZsymm_v2_64(cublasHandle_t handle, cublasSideMode_t side,
                                 cublasFillMode_t uplo, int64_t m, int64_t n,
                                 const cuDoubleComplex *alpha,
                                 const cuDoubleComplex *A, int64_t lda,
                                 const cuDoubleComplex *B, int64_t ldb,
                                 const cuDoubleComplex *beta,
                                 cuDoubleComplex *C, int64_t ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZsymm_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &side, sizeof(cublasSideMode_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &B, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasChemm_v2(cublasHandle_t handle, cublasSideMode_t side,
                              cublasFillMode_t uplo, int m, int n,
                              const cuComplex *alpha, const cuComplex *A,
                              int lda, const cuComplex *B, int ldb,
                              const cuComplex *beta, cuComplex *C, int ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasChemm_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &side, sizeof(cublasSideMode_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &B, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasChemm_v2_64(cublasHandle_t handle, cublasSideMode_t side,
                                 cublasFillMode_t uplo, int64_t m, int64_t n,
                                 const cuComplex *alpha, const cuComplex *A,
                                 int64_t lda, const cuComplex *B, int64_t ldb,
                                 const cuComplex *beta, cuComplex *C,
                                 int64_t ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasChemm_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &side, sizeof(cublasSideMode_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &B, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZhemm_v2(cublasHandle_t handle, cublasSideMode_t side,
                              cublasFillMode_t uplo, int m, int n,
                              const cuDoubleComplex *alpha,
                              const cuDoubleComplex *A, int lda,
                              const cuDoubleComplex *B, int ldb,
                              const cuDoubleComplex *beta, cuDoubleComplex *C,
                              int ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZhemm_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &side, sizeof(cublasSideMode_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &B, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZhemm_v2_64(cublasHandle_t handle, cublasSideMode_t side,
                                 cublasFillMode_t uplo, int64_t m, int64_t n,
                                 const cuDoubleComplex *alpha,
                                 const cuDoubleComplex *A, int64_t lda,
                                 const cuDoubleComplex *B, int64_t ldb,
                                 const cuDoubleComplex *beta,
                                 cuDoubleComplex *C, int64_t ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZhemm_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &side, sizeof(cublasSideMode_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &B, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasStrsm_v2(cublasHandle_t handle, cublasSideMode_t side,
                              cublasFillMode_t uplo, cublasOperation_t trans,
                              cublasDiagType_t diag, int m, int n,
                              const float *alpha, const float *A, int lda,
                              float *B, int ldb) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasStrsm_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &side, sizeof(cublasSideMode_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &A, sizeof(const float *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, B, sizeof(float)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, B, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasStrsm_v2_64(cublasHandle_t handle, cublasSideMode_t side,
                                 cublasFillMode_t uplo, cublasOperation_t trans,
                                 cublasDiagType_t diag, int64_t m, int64_t n,
                                 const float *alpha, const float *A,
                                 int64_t lda, float *B, int64_t ldb) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasStrsm_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &side, sizeof(cublasSideMode_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &A, sizeof(const float *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, B, sizeof(float)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, B, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDtrsm_v2(cublasHandle_t handle, cublasSideMode_t side,
                              cublasFillMode_t uplo, cublasOperation_t trans,
                              cublasDiagType_t diag, int m, int n,
                              const double *alpha, const double *A, int lda,
                              double *B, int ldb) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDtrsm_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &side, sizeof(cublasSideMode_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      rpc_write(conn, &A, sizeof(const double *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, B, sizeof(double)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, B, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDtrsm_v2_64(cublasHandle_t handle, cublasSideMode_t side,
                                 cublasFillMode_t uplo, cublasOperation_t trans,
                                 cublasDiagType_t diag, int64_t m, int64_t n,
                                 const double *alpha, const double *A,
                                 int64_t lda, double *B, int64_t ldb) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDtrsm_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &side, sizeof(cublasSideMode_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      rpc_write(conn, &A, sizeof(const double *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, B, sizeof(double)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, B, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCtrsm_v2(cublasHandle_t handle, cublasSideMode_t side,
                              cublasFillMode_t uplo, cublasOperation_t trans,
                              cublasDiagType_t diag, int m, int n,
                              const cuComplex *alpha, const cuComplex *A,
                              int lda, cuComplex *B, int ldb) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCtrsm_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &side, sizeof(cublasSideMode_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, B, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, B, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCtrsm_v2_64(cublasHandle_t handle, cublasSideMode_t side,
                                 cublasFillMode_t uplo, cublasOperation_t trans,
                                 cublasDiagType_t diag, int64_t m, int64_t n,
                                 const cuComplex *alpha, const cuComplex *A,
                                 int64_t lda, cuComplex *B, int64_t ldb) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCtrsm_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &side, sizeof(cublasSideMode_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, B, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, B, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZtrsm_v2(cublasHandle_t handle, cublasSideMode_t side,
                              cublasFillMode_t uplo, cublasOperation_t trans,
                              cublasDiagType_t diag, int m, int n,
                              const cuDoubleComplex *alpha,
                              const cuDoubleComplex *A, int lda,
                              cuDoubleComplex *B, int ldb) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZtrsm_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &side, sizeof(cublasSideMode_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, B, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, B, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZtrsm_v2_64(cublasHandle_t handle, cublasSideMode_t side,
                                 cublasFillMode_t uplo, cublasOperation_t trans,
                                 cublasDiagType_t diag, int64_t m, int64_t n,
                                 const cuDoubleComplex *alpha,
                                 const cuDoubleComplex *A, int64_t lda,
                                 cuDoubleComplex *B, int64_t ldb) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZtrsm_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &side, sizeof(cublasSideMode_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, B, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, B, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasStrmm_v2(cublasHandle_t handle, cublasSideMode_t side,
                              cublasFillMode_t uplo, cublasOperation_t trans,
                              cublasDiagType_t diag, int m, int n,
                              const float *alpha, const float *A, int lda,
                              const float *B, int ldb, float *C, int ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasStrmm_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &side, sizeof(cublasSideMode_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &A, sizeof(const float *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &B, sizeof(const float *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int)) < 0 ||
      rpc_write(conn, C, sizeof(float)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, C, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasStrmm_v2_64(cublasHandle_t handle, cublasSideMode_t side,
                                 cublasFillMode_t uplo, cublasOperation_t trans,
                                 cublasDiagType_t diag, int64_t m, int64_t n,
                                 const float *alpha, const float *A,
                                 int64_t lda, const float *B, int64_t ldb,
                                 float *C, int64_t ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasStrmm_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &side, sizeof(cublasSideMode_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      rpc_write(conn, &A, sizeof(const float *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &B, sizeof(const float *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int64_t)) < 0 ||
      rpc_write(conn, C, sizeof(float)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, C, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDtrmm_v2(cublasHandle_t handle, cublasSideMode_t side,
                              cublasFillMode_t uplo, cublasOperation_t trans,
                              cublasDiagType_t diag, int m, int n,
                              const double *alpha, const double *A, int lda,
                              const double *B, int ldb, double *C, int ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDtrmm_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &side, sizeof(cublasSideMode_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      rpc_write(conn, &A, sizeof(const double *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &B, sizeof(const double *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int)) < 0 ||
      rpc_write(conn, C, sizeof(double)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDtrmm_v2_64(cublasHandle_t handle, cublasSideMode_t side,
                                 cublasFillMode_t uplo, cublasOperation_t trans,
                                 cublasDiagType_t diag, int64_t m, int64_t n,
                                 const double *alpha, const double *A,
                                 int64_t lda, const double *B, int64_t ldb,
                                 double *C, int64_t ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDtrmm_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &side, sizeof(cublasSideMode_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      rpc_write(conn, &A, sizeof(const double *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &B, sizeof(const double *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int64_t)) < 0 ||
      rpc_write(conn, C, sizeof(double)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCtrmm_v2(cublasHandle_t handle, cublasSideMode_t side,
                              cublasFillMode_t uplo, cublasOperation_t trans,
                              cublasDiagType_t diag, int m, int n,
                              const cuComplex *alpha, const cuComplex *A,
                              int lda, const cuComplex *B, int ldb,
                              cuComplex *C, int ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCtrmm_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &side, sizeof(cublasSideMode_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &B, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int)) < 0 ||
      rpc_write(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCtrmm_v2_64(cublasHandle_t handle, cublasSideMode_t side,
                                 cublasFillMode_t uplo, cublasOperation_t trans,
                                 cublasDiagType_t diag, int64_t m, int64_t n,
                                 const cuComplex *alpha, const cuComplex *A,
                                 int64_t lda, const cuComplex *B, int64_t ldb,
                                 cuComplex *C, int64_t ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCtrmm_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &side, sizeof(cublasSideMode_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &B, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int64_t)) < 0 ||
      rpc_write(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZtrmm_v2(cublasHandle_t handle, cublasSideMode_t side,
                              cublasFillMode_t uplo, cublasOperation_t trans,
                              cublasDiagType_t diag, int m, int n,
                              const cuDoubleComplex *alpha,
                              const cuDoubleComplex *A, int lda,
                              const cuDoubleComplex *B, int ldb,
                              cuDoubleComplex *C, int ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZtrmm_v2) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &side, sizeof(cublasSideMode_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &B, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int)) < 0 ||
      rpc_write(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZtrmm_v2_64(cublasHandle_t handle, cublasSideMode_t side,
                                 cublasFillMode_t uplo, cublasOperation_t trans,
                                 cublasDiagType_t diag, int64_t m, int64_t n,
                                 const cuDoubleComplex *alpha,
                                 const cuDoubleComplex *A, int64_t lda,
                                 const cuDoubleComplex *B, int64_t ldb,
                                 cuDoubleComplex *C, int64_t ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZtrmm_v2_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &side, sizeof(cublasSideMode_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &trans, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &diag, sizeof(cublasDiagType_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &B, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int64_t)) < 0 ||
      rpc_write(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&side, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&trans, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&diag, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t
cublasHgemmStridedBatched(cublasHandle_t handle, cublasOperation_t transa,
                          cublasOperation_t transb, int m, int n, int k,
                          const __half *alpha, const __half *A, int lda,
                          long long int strideA, const __half *B, int ldb,
                          long long int strideB, const __half *beta, __half *C,
                          int ldc, long long int strideC, int batchCount) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideB, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideC, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasHgemmStridedBatched) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &transa, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &transb, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &k, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const __half *)) < 0 ||
      (alpha != nullptr && rpc_write(conn, alpha, sizeof(const __half)) < 0) ||
      rpc_write(conn, &A, sizeof(const __half *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &strideA, sizeof(long long int)) < 0 ||
      rpc_write(conn, &B, sizeof(const __half *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int)) < 0 ||
      rpc_write(conn, &strideB, sizeof(long long int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const __half *)) < 0 ||
      (beta != nullptr && rpc_write(conn, beta, sizeof(const __half)) < 0) ||
      rpc_write(conn, C, sizeof(__half)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int)) < 0 ||
      rpc_write(conn, &strideC, sizeof(long long int)) < 0 ||
      rpc_write(conn, &batchCount, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(__half)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideB, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideC, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasHgemmStridedBatched_64(
    cublasHandle_t handle, cublasOperation_t transa, cublasOperation_t transb,
    int64_t m, int64_t n, int64_t k, const __half *alpha, const __half *A,
    int64_t lda, long long int strideA, const __half *B, int64_t ldb,
    long long int strideB, const __half *beta, __half *C, int64_t ldc,
    long long int strideC, int64_t batchCount) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideB, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideC, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasHgemmStridedBatched_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &transa, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &transb, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &k, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const __half *)) < 0 ||
      (alpha != nullptr && rpc_write(conn, alpha, sizeof(const __half)) < 0) ||
      rpc_write(conn, &A, sizeof(const __half *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &strideA, sizeof(long long int)) < 0 ||
      rpc_write(conn, &B, sizeof(const __half *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &strideB, sizeof(long long int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const __half *)) < 0 ||
      (beta != nullptr && rpc_write(conn, beta, sizeof(const __half)) < 0) ||
      rpc_write(conn, C, sizeof(__half)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &strideC, sizeof(long long int)) < 0 ||
      rpc_write(conn, &batchCount, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(__half)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideB, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideC, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t
cublasSgemmStridedBatched(cublasHandle_t handle, cublasOperation_t transa,
                          cublasOperation_t transb, int m, int n, int k,
                          const float *alpha, const float *A, int lda,
                          long long int strideA, const float *B, int ldb,
                          long long int strideB, const float *beta, float *C,
                          int ldc, long long int strideC, int batchCount) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideB, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideC, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSgemmStridedBatched) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &transa, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &transb, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &k, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      (alpha != nullptr && rpc_write(conn, alpha, sizeof(const float)) < 0) ||
      rpc_write(conn, &A, sizeof(const float *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &strideA, sizeof(long long int)) < 0 ||
      rpc_write(conn, &B, sizeof(const float *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int)) < 0 ||
      rpc_write(conn, &strideB, sizeof(long long int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const float *)) < 0 ||
      (beta != nullptr && rpc_write(conn, beta, sizeof(const float)) < 0) ||
      rpc_write(conn, C, sizeof(float)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int)) < 0 ||
      rpc_write(conn, &strideC, sizeof(long long int)) < 0 ||
      rpc_write(conn, &batchCount, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, C, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideB, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideC, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSgemmStridedBatched_64(
    cublasHandle_t handle, cublasOperation_t transa, cublasOperation_t transb,
    int64_t m, int64_t n, int64_t k, const float *alpha, const float *A,
    int64_t lda, long long int strideA, const float *B, int64_t ldb,
    long long int strideB, const float *beta, float *C, int64_t ldc,
    long long int strideC, int64_t batchCount) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideB, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideC, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSgemmStridedBatched_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &transa, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &transb, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &k, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      (alpha != nullptr && rpc_write(conn, alpha, sizeof(const float)) < 0) ||
      rpc_write(conn, &A, sizeof(const float *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &strideA, sizeof(long long int)) < 0 ||
      rpc_write(conn, &B, sizeof(const float *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &strideB, sizeof(long long int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const float *)) < 0 ||
      (beta != nullptr && rpc_write(conn, beta, sizeof(const float)) < 0) ||
      rpc_write(conn, C, sizeof(float)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &strideC, sizeof(long long int)) < 0 ||
      rpc_write(conn, &batchCount, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, C, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideB, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideC, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t
cublasDgemmStridedBatched(cublasHandle_t handle, cublasOperation_t transa,
                          cublasOperation_t transb, int m, int n, int k,
                          const double *alpha, const double *A, int lda,
                          long long int strideA, const double *B, int ldb,
                          long long int strideB, const double *beta, double *C,
                          int ldc, long long int strideC, int batchCount) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideB, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideC, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDgemmStridedBatched) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &transa, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &transb, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &k, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      (alpha != nullptr && rpc_write(conn, alpha, sizeof(const double)) < 0) ||
      rpc_write(conn, &A, sizeof(const double *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &strideA, sizeof(long long int)) < 0 ||
      rpc_write(conn, &B, sizeof(const double *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int)) < 0 ||
      rpc_write(conn, &strideB, sizeof(long long int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const double *)) < 0 ||
      (beta != nullptr && rpc_write(conn, beta, sizeof(const double)) < 0) ||
      rpc_write(conn, C, sizeof(double)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int)) < 0 ||
      rpc_write(conn, &strideC, sizeof(long long int)) < 0 ||
      rpc_write(conn, &batchCount, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideB, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideC, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDgemmStridedBatched_64(
    cublasHandle_t handle, cublasOperation_t transa, cublasOperation_t transb,
    int64_t m, int64_t n, int64_t k, const double *alpha, const double *A,
    int64_t lda, long long int strideA, const double *B, int64_t ldb,
    long long int strideB, const double *beta, double *C, int64_t ldc,
    long long int strideC, int64_t batchCount) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideB, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideC, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDgemmStridedBatched_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &transa, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &transb, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &k, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      (alpha != nullptr && rpc_write(conn, alpha, sizeof(const double)) < 0) ||
      rpc_write(conn, &A, sizeof(const double *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &strideA, sizeof(long long int)) < 0 ||
      rpc_write(conn, &B, sizeof(const double *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &strideB, sizeof(long long int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const double *)) < 0 ||
      (beta != nullptr && rpc_write(conn, beta, sizeof(const double)) < 0) ||
      rpc_write(conn, C, sizeof(double)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &strideC, sizeof(long long int)) < 0 ||
      rpc_write(conn, &batchCount, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideB, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideC, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCgemmStridedBatched(
    cublasHandle_t handle, cublasOperation_t transa, cublasOperation_t transb,
    int m, int n, int k, const cuComplex *alpha, const cuComplex *A, int lda,
    long long int strideA, const cuComplex *B, int ldb, long long int strideB,
    const cuComplex *beta, cuComplex *C, int ldc, long long int strideC,
    int batchCount) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideB, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideC, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCgemmStridedBatched) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &transa, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &transb, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &k, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      (alpha != nullptr &&
       rpc_write(conn, alpha, sizeof(const cuComplex)) < 0) ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &strideA, sizeof(long long int)) < 0 ||
      rpc_write(conn, &B, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int)) < 0 ||
      rpc_write(conn, &strideB, sizeof(long long int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuComplex *)) < 0 ||
      (beta != nullptr && rpc_write(conn, beta, sizeof(const cuComplex)) < 0) ||
      rpc_write(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int)) < 0 ||
      rpc_write(conn, &strideC, sizeof(long long int)) < 0 ||
      rpc_write(conn, &batchCount, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideB, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideC, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCgemmStridedBatched_64(
    cublasHandle_t handle, cublasOperation_t transa, cublasOperation_t transb,
    int64_t m, int64_t n, int64_t k, const cuComplex *alpha, const cuComplex *A,
    int64_t lda, long long int strideA, const cuComplex *B, int64_t ldb,
    long long int strideB, const cuComplex *beta, cuComplex *C, int64_t ldc,
    long long int strideC, int64_t batchCount) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideB, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideC, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCgemmStridedBatched_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &transa, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &transb, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &k, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      (alpha != nullptr &&
       rpc_write(conn, alpha, sizeof(const cuComplex)) < 0) ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &strideA, sizeof(long long int)) < 0 ||
      rpc_write(conn, &B, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &strideB, sizeof(long long int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuComplex *)) < 0 ||
      (beta != nullptr && rpc_write(conn, beta, sizeof(const cuComplex)) < 0) ||
      rpc_write(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &strideC, sizeof(long long int)) < 0 ||
      rpc_write(conn, &batchCount, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideB, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideC, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCgemm3mStridedBatched(
    cublasHandle_t handle, cublasOperation_t transa, cublasOperation_t transb,
    int m, int n, int k, const cuComplex *alpha, const cuComplex *A, int lda,
    long long int strideA, const cuComplex *B, int ldb, long long int strideB,
    const cuComplex *beta, cuComplex *C, int ldc, long long int strideC,
    int batchCount) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideB, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideC, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCgemm3mStridedBatched) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &transa, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &transb, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &k, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      (alpha != nullptr &&
       rpc_write(conn, alpha, sizeof(const cuComplex)) < 0) ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &strideA, sizeof(long long int)) < 0 ||
      rpc_write(conn, &B, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int)) < 0 ||
      rpc_write(conn, &strideB, sizeof(long long int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuComplex *)) < 0 ||
      (beta != nullptr && rpc_write(conn, beta, sizeof(const cuComplex)) < 0) ||
      rpc_write(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int)) < 0 ||
      rpc_write(conn, &strideC, sizeof(long long int)) < 0 ||
      rpc_write(conn, &batchCount, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideB, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideC, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCgemm3mStridedBatched_64(
    cublasHandle_t handle, cublasOperation_t transa, cublasOperation_t transb,
    int64_t m, int64_t n, int64_t k, const cuComplex *alpha, const cuComplex *A,
    int64_t lda, long long int strideA, const cuComplex *B, int64_t ldb,
    long long int strideB, const cuComplex *beta, cuComplex *C, int64_t ldc,
    long long int strideC, int64_t batchCount) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideB, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideC, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCgemm3mStridedBatched_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &transa, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &transb, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &k, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      (alpha != nullptr &&
       rpc_write(conn, alpha, sizeof(const cuComplex)) < 0) ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &strideA, sizeof(long long int)) < 0 ||
      rpc_write(conn, &B, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &strideB, sizeof(long long int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuComplex *)) < 0 ||
      (beta != nullptr && rpc_write(conn, beta, sizeof(const cuComplex)) < 0) ||
      rpc_write(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &strideC, sizeof(long long int)) < 0 ||
      rpc_write(conn, &batchCount, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideB, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideC, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZgemmStridedBatched(
    cublasHandle_t handle, cublasOperation_t transa, cublasOperation_t transb,
    int m, int n, int k, const cuDoubleComplex *alpha, const cuDoubleComplex *A,
    int lda, long long int strideA, const cuDoubleComplex *B, int ldb,
    long long int strideB, const cuDoubleComplex *beta, cuDoubleComplex *C,
    int ldc, long long int strideC, int batchCount) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideB, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideC, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZgemmStridedBatched) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &transa, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &transb, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &k, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      (alpha != nullptr &&
       rpc_write(conn, alpha, sizeof(const cuDoubleComplex)) < 0) ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &strideA, sizeof(long long int)) < 0 ||
      rpc_write(conn, &B, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int)) < 0 ||
      rpc_write(conn, &strideB, sizeof(long long int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuDoubleComplex *)) < 0 ||
      (beta != nullptr &&
       rpc_write(conn, beta, sizeof(const cuDoubleComplex)) < 0) ||
      rpc_write(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int)) < 0 ||
      rpc_write(conn, &strideC, sizeof(long long int)) < 0 ||
      rpc_write(conn, &batchCount, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideB, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideC, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZgemmStridedBatched_64(
    cublasHandle_t handle, cublasOperation_t transa, cublasOperation_t transb,
    int64_t m, int64_t n, int64_t k, const cuDoubleComplex *alpha,
    const cuDoubleComplex *A, int64_t lda, long long int strideA,
    const cuDoubleComplex *B, int64_t ldb, long long int strideB,
    const cuDoubleComplex *beta, cuDoubleComplex *C, int64_t ldc,
    long long int strideC, int64_t batchCount) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideB, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideC, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZgemmStridedBatched_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &transa, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &transb, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &k, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      (alpha != nullptr &&
       rpc_write(conn, alpha, sizeof(const cuDoubleComplex)) < 0) ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &strideA, sizeof(long long int)) < 0 ||
      rpc_write(conn, &B, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &strideB, sizeof(long long int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuDoubleComplex *)) < 0 ||
      (beta != nullptr &&
       rpc_write(conn, beta, sizeof(const cuDoubleComplex)) < 0) ||
      rpc_write(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &strideC, sizeof(long long int)) < 0 ||
      rpc_write(conn, &batchCount, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideA, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideB, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&strideC, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&batchCount,
                             cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSgeam(cublasHandle_t handle, cublasOperation_t transa,
                           cublasOperation_t transb, int m, int n,
                           const float *alpha, const float *A, int lda,
                           const float *beta, const float *B, int ldb, float *C,
                           int ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSgeam) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &transa, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &transb, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      (alpha != nullptr && rpc_write(conn, alpha, sizeof(const float)) < 0) ||
      rpc_write(conn, &A, sizeof(const float *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const float *)) < 0 ||
      (beta != nullptr && rpc_write(conn, beta, sizeof(const float)) < 0) ||
      rpc_write(conn, &B, sizeof(const float *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int)) < 0 ||
      rpc_write(conn, C, sizeof(float)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, C, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSgeam_64(cublasHandle_t handle, cublasOperation_t transa,
                              cublasOperation_t transb, int64_t m, int64_t n,
                              const float *alpha, const float *A, int64_t lda,
                              const float *beta, const float *B, int64_t ldb,
                              float *C, int64_t ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSgeam_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &transa, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &transb, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const float *)) < 0 ||
      (alpha != nullptr && rpc_write(conn, alpha, sizeof(const float)) < 0) ||
      rpc_write(conn, &A, sizeof(const float *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const float *)) < 0 ||
      (beta != nullptr && rpc_write(conn, beta, sizeof(const float)) < 0) ||
      rpc_write(conn, &B, sizeof(const float *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int64_t)) < 0 ||
      rpc_write(conn, C, sizeof(float)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, C, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDgeam(cublasHandle_t handle, cublasOperation_t transa,
                           cublasOperation_t transb, int m, int n,
                           const double *alpha, const double *A, int lda,
                           const double *beta, const double *B, int ldb,
                           double *C, int ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDgeam) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &transa, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &transb, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      (alpha != nullptr && rpc_write(conn, alpha, sizeof(const double)) < 0) ||
      rpc_write(conn, &A, sizeof(const double *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const double *)) < 0 ||
      (beta != nullptr && rpc_write(conn, beta, sizeof(const double)) < 0) ||
      rpc_write(conn, &B, sizeof(const double *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int)) < 0 ||
      rpc_write(conn, C, sizeof(double)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDgeam_64(cublasHandle_t handle, cublasOperation_t transa,
                              cublasOperation_t transb, int64_t m, int64_t n,
                              const double *alpha, const double *A, int64_t lda,
                              const double *beta, const double *B, int64_t ldb,
                              double *C, int64_t ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDgeam_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &transa, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &transb, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const double *)) < 0 ||
      (alpha != nullptr && rpc_write(conn, alpha, sizeof(const double)) < 0) ||
      rpc_write(conn, &A, sizeof(const double *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const double *)) < 0 ||
      (beta != nullptr && rpc_write(conn, beta, sizeof(const double)) < 0) ||
      rpc_write(conn, &B, sizeof(const double *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int64_t)) < 0 ||
      rpc_write(conn, C, sizeof(double)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCgeam(cublasHandle_t handle, cublasOperation_t transa,
                           cublasOperation_t transb, int m, int n,
                           const cuComplex *alpha, const cuComplex *A, int lda,
                           const cuComplex *beta, const cuComplex *B, int ldb,
                           cuComplex *C, int ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCgeam) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &transa, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &transb, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      (alpha != nullptr &&
       rpc_write(conn, alpha, sizeof(const cuComplex)) < 0) ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuComplex *)) < 0 ||
      (beta != nullptr && rpc_write(conn, beta, sizeof(const cuComplex)) < 0) ||
      rpc_write(conn, &B, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int)) < 0 ||
      rpc_write(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCgeam_64(cublasHandle_t handle, cublasOperation_t transa,
                              cublasOperation_t transb, int64_t m, int64_t n,
                              const cuComplex *alpha, const cuComplex *A,
                              int64_t lda, const cuComplex *beta,
                              const cuComplex *B, int64_t ldb, cuComplex *C,
                              int64_t ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCgeam_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &transa, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &transb, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuComplex *)) < 0 ||
      (alpha != nullptr &&
       rpc_write(conn, alpha, sizeof(const cuComplex)) < 0) ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuComplex *)) < 0 ||
      (beta != nullptr && rpc_write(conn, beta, sizeof(const cuComplex)) < 0) ||
      rpc_write(conn, &B, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int64_t)) < 0 ||
      rpc_write(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZgeam(cublasHandle_t handle, cublasOperation_t transa,
                           cublasOperation_t transb, int m, int n,
                           const cuDoubleComplex *alpha,
                           const cuDoubleComplex *A, int lda,
                           const cuDoubleComplex *beta,
                           const cuDoubleComplex *B, int ldb,
                           cuDoubleComplex *C, int ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZgeam) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &transa, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &transb, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      (alpha != nullptr &&
       rpc_write(conn, alpha, sizeof(const cuDoubleComplex)) < 0) ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuDoubleComplex *)) < 0 ||
      (beta != nullptr &&
       rpc_write(conn, beta, sizeof(const cuDoubleComplex)) < 0) ||
      rpc_write(conn, &B, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int)) < 0 ||
      rpc_write(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZgeam_64(cublasHandle_t handle, cublasOperation_t transa,
                              cublasOperation_t transb, int64_t m, int64_t n,
                              const cuDoubleComplex *alpha,
                              const cuDoubleComplex *A, int64_t lda,
                              const cuDoubleComplex *beta,
                              const cuDoubleComplex *B, int64_t ldb,
                              cuDoubleComplex *C, int64_t ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZgeam_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &transa, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &transb, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &alpha, sizeof(const cuDoubleComplex *)) < 0 ||
      (alpha != nullptr &&
       rpc_write(conn, alpha, sizeof(const cuDoubleComplex)) < 0) ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &beta, sizeof(const cuDoubleComplex *)) < 0 ||
      (beta != nullptr &&
       rpc_write(conn, beta, sizeof(const cuDoubleComplex)) < 0) ||
      rpc_write(conn, &B, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int64_t)) < 0 ||
      rpc_write(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSdgmm(cublasHandle_t handle, cublasSideMode_t mode, int m,
                           int n, const float *A, int lda, const float *x,
                           int incx, float *C, int ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSdgmm) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &mode, sizeof(cublasSideMode_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &A, sizeof(const float *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &x, sizeof(const float *)) < 0 ||
      (x != nullptr && rpc_write(conn, x, sizeof(const float)) < 0) ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, C, sizeof(float)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, C, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasSdgmm_64(cublasHandle_t handle, cublasSideMode_t mode,
                              int64_t m, int64_t n, const float *A, int64_t lda,
                              const float *x, int64_t incx, float *C,
                              int64_t ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasSdgmm_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &mode, sizeof(cublasSideMode_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &A, sizeof(const float *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const float *)) < 0 ||
      (x != nullptr && rpc_write(conn, x, sizeof(const float)) < 0) ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, C, sizeof(float)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, C, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDdgmm(cublasHandle_t handle, cublasSideMode_t mode, int m,
                           int n, const double *A, int lda, const double *x,
                           int incx, double *C, int ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDdgmm) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &mode, sizeof(cublasSideMode_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &A, sizeof(const double *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &x, sizeof(const double *)) < 0 ||
      (x != nullptr && rpc_write(conn, x, sizeof(const double)) < 0) ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, C, sizeof(double)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDdgmm_64(cublasHandle_t handle, cublasSideMode_t mode,
                              int64_t m, int64_t n, const double *A,
                              int64_t lda, const double *x, int64_t incx,
                              double *C, int64_t ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDdgmm_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &mode, sizeof(cublasSideMode_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &A, sizeof(const double *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const double *)) < 0 ||
      (x != nullptr && rpc_write(conn, x, sizeof(const double)) < 0) ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, C, sizeof(double)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCdgmm(cublasHandle_t handle, cublasSideMode_t mode, int m,
                           int n, const cuComplex *A, int lda,
                           const cuComplex *x, int incx, cuComplex *C,
                           int ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCdgmm) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &mode, sizeof(cublasSideMode_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuComplex *)) < 0 ||
      (x != nullptr && rpc_write(conn, x, sizeof(const cuComplex)) < 0) ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCdgmm_64(cublasHandle_t handle, cublasSideMode_t mode,
                              int64_t m, int64_t n, const cuComplex *A,
                              int64_t lda, const cuComplex *x, int64_t incx,
                              cuComplex *C, int64_t ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCdgmm_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &mode, sizeof(cublasSideMode_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuComplex *)) < 0 ||
      (x != nullptr && rpc_write(conn, x, sizeof(const cuComplex)) < 0) ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZdgmm(cublasHandle_t handle, cublasSideMode_t mode, int m,
                           int n, const cuDoubleComplex *A, int lda,
                           const cuDoubleComplex *x, int incx,
                           cuDoubleComplex *C, int ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZdgmm) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &mode, sizeof(cublasSideMode_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuDoubleComplex *)) < 0 ||
      (x != nullptr && rpc_write(conn, x, sizeof(const cuDoubleComplex)) < 0) ||
      rpc_write(conn, &incx, sizeof(int)) < 0 ||
      rpc_write(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZdgmm_64(cublasHandle_t handle, cublasSideMode_t mode,
                              int64_t m, int64_t n, const cuDoubleComplex *A,
                              int64_t lda, const cuDoubleComplex *x,
                              int64_t incx, cuDoubleComplex *C, int64_t ldc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZdgmm_64) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &mode, sizeof(cublasSideMode_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      rpc_write(conn, &lda, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const cuDoubleComplex *)) < 0 ||
      (x != nullptr && rpc_write(conn, x, sizeof(const cuDoubleComplex)) < 0) ||
      rpc_write(conn, &incx, sizeof(int64_t)) < 0 ||
      rpc_write(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int64_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&incx, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasStpttr(cublasHandle_t handle, cublasFillMode_t uplo, int n,
                            const float *AP, float *A, int lda) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasStpttr) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &AP, sizeof(const float *)) < 0 ||
      (AP != nullptr && rpc_write(conn, AP, sizeof(const float)) < 0) ||
      rpc_write(conn, A, sizeof(float)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 || rpc_read(conn, A, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDtpttr(cublasHandle_t handle, cublasFillMode_t uplo, int n,
                            const double *AP, double *A, int lda) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDtpttr) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &AP, sizeof(const double *)) < 0 ||
      (AP != nullptr && rpc_write(conn, AP, sizeof(const double)) < 0) ||
      rpc_write(conn, A, sizeof(double)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, A, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCtpttr(cublasHandle_t handle, cublasFillMode_t uplo, int n,
                            const cuComplex *AP, cuComplex *A, int lda) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCtpttr) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &AP, sizeof(const cuComplex *)) < 0 ||
      (AP != nullptr && rpc_write(conn, AP, sizeof(const cuComplex)) < 0) ||
      rpc_write(conn, A, sizeof(cuComplex)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, A, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZtpttr(cublasHandle_t handle, cublasFillMode_t uplo, int n,
                            const cuDoubleComplex *AP, cuDoubleComplex *A,
                            int lda) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZtpttr) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &AP, sizeof(const cuDoubleComplex *)) < 0 ||
      (AP != nullptr &&
       rpc_write(conn, AP, sizeof(const cuDoubleComplex)) < 0) ||
      rpc_write(conn, A, sizeof(cuDoubleComplex)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, A, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasStrttp(cublasHandle_t handle, cublasFillMode_t uplo, int n,
                            const float *A, int lda, float *AP) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasStrttp) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &A, sizeof(const float *)) < 0 ||
      (A != nullptr && rpc_write(conn, A, sizeof(const float)) < 0) ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, AP, sizeof(float)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, AP, sizeof(float)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasDtrttp(cublasHandle_t handle, cublasFillMode_t uplo, int n,
                            const double *A, int lda, double *AP) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasDtrttp) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &A, sizeof(const double *)) < 0 ||
      (A != nullptr && rpc_write(conn, A, sizeof(const double)) < 0) ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, AP, sizeof(double)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, AP, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasCtrttp(cublasHandle_t handle, cublasFillMode_t uplo, int n,
                            const cuComplex *A, int lda, cuComplex *AP) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasCtrttp) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuComplex *)) < 0 ||
      (A != nullptr && rpc_write(conn, A, sizeof(const cuComplex)) < 0) ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, AP, sizeof(cuComplex)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, AP, sizeof(cuComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasZtrttp(cublasHandle_t handle, cublasFillMode_t uplo, int n,
                            const cuDoubleComplex *A, int lda,
                            cuDoubleComplex *AP) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasZtrttp) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &uplo, sizeof(cublasFillMode_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &A, sizeof(const cuDoubleComplex *)) < 0 ||
      (A != nullptr && rpc_write(conn, A, sizeof(const cuDoubleComplex)) < 0) ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, AP, sizeof(cuDoubleComplex)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, AP, sizeof(cuDoubleComplex)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&uplo, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)AP, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cublasStatus_t cublasUint8gemmBias(
    cublasHandle_t handle, cublasOperation_t transa, cublasOperation_t transb,
    cublasOperation_t transc, int m, int n, int k, const unsigned char *A,
    int A_bias, int lda, const unsigned char *B, int B_bias, int ldb,
    unsigned char *C, int C_bias, int ldc, int C_mult, int C_shift) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&A_bias, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&B_bias, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&C_bias, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&C_mult, cudaMemcpyHostToDevice) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&C_shift, cudaMemcpyHostToDevice) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  cublasStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cublasUint8gemmBias) < 0 ||
      rpc_write(conn, &handle, sizeof(cublasHandle_t)) < 0 ||
      rpc_write(conn, &transa, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &transb, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &transc, sizeof(cublasOperation_t)) < 0 ||
      rpc_write(conn, &m, sizeof(int)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &k, sizeof(int)) < 0 ||
      rpc_write(conn, &A, sizeof(const unsigned char *)) < 0 ||
      rpc_write(conn, &A_bias, sizeof(int)) < 0 ||
      rpc_write(conn, &lda, sizeof(int)) < 0 ||
      rpc_write(conn, &B, sizeof(const unsigned char *)) < 0 ||
      rpc_write(conn, &B_bias, sizeof(int)) < 0 ||
      rpc_write(conn, &ldb, sizeof(int)) < 0 ||
      rpc_write(conn, C, sizeof(unsigned char)) < 0 ||
      rpc_write(conn, &C_bias, sizeof(int)) < 0 ||
      rpc_write(conn, &ldc, sizeof(int)) < 0 ||
      rpc_write(conn, &C_mult, sizeof(int)) < 0 ||
      rpc_write(conn, &C_shift, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, C, sizeof(unsigned char)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cublasStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transa, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&m, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)A, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&A_bias, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lda, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)B, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&B_bias, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldb, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)C, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&C_bias, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&ldc, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&C_mult, cudaMemcpyDeviceToHost) < 0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&C_shift, cudaMemcpyDeviceToHost) <
      0)
    return CUBLAS_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnGetProperty(libraryPropertyType type, int *value) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&type, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)value, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnGetProperty) < 0 ||
      rpc_write(conn, &type, sizeof(libraryPropertyType)) < 0 ||
      rpc_write(conn, value, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, value, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&type, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)value, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnCreate(cudnnHandle_t *handle) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)handle, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnCreate) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, handle, sizeof(cudnnHandle_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)handle, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnDestroy(cudnnHandle_t handle) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnDestroy) < 0 ||
      rpc_write(conn, &handle, sizeof(cudnnHandle_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnSetStream(cudnnHandle_t handle, cudaStream_t streamId) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&streamId, cudaMemcpyHostToDevice) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnSetStream) < 0 ||
      rpc_write(conn, &handle, sizeof(cudnnHandle_t)) < 0 ||
      rpc_write(conn, &streamId, sizeof(cudaStream_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&streamId, cudaMemcpyDeviceToHost) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnGetStream(cudnnHandle_t handle, cudaStream_t *streamId) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)streamId, cudaMemcpyHostToDevice) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnGetStream) < 0 ||
      rpc_write(conn, &handle, sizeof(cudnnHandle_t)) < 0 ||
      rpc_write(conn, streamId, sizeof(cudaStream_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, streamId, sizeof(cudaStream_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)streamId, cudaMemcpyDeviceToHost) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnGetCallback(unsigned *mask, void **udata,
                               cudnnCallback_t *fptr) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)mask, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)udata, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)fptr, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnGetCallback) < 0 ||
      rpc_write(conn, mask, sizeof(unsigned)) < 0 ||
      rpc_write(conn, udata, sizeof(void *)) < 0 ||
      rpc_write(conn, fptr, sizeof(cudnnCallback_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, mask, sizeof(unsigned)) < 0 ||
      rpc_read(conn, udata, sizeof(void *)) < 0 ||
      rpc_read(conn, fptr, sizeof(cudnnCallback_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)mask, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)udata, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)fptr, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnGraphVersionCheck() {
  conn_t *conn = rpc_client_get_connection(0);
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnGraphVersionCheck) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t
cudnnBackendCreateDescriptor(cudnnBackendDescriptorType_t descriptorType,
                             cudnnBackendDescriptor_t *descriptor) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&descriptorType,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)descriptor, cudaMemcpyHostToDevice) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnBackendCreateDescriptor) < 0 ||
      rpc_write(conn, &descriptorType, sizeof(cudnnBackendDescriptorType_t)) <
          0 ||
      rpc_write(conn, descriptor, sizeof(cudnnBackendDescriptor_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, descriptor, sizeof(cudnnBackendDescriptor_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&descriptorType,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)descriptor, cudaMemcpyDeviceToHost) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t
cudnnBackendDestroyDescriptor(cudnnBackendDescriptor_t descriptor) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&descriptor,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnBackendDestroyDescriptor) < 0 ||
      rpc_write(conn, &descriptor, sizeof(cudnnBackendDescriptor_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&descriptor,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnBackendInitialize(cudnnBackendDescriptor_t descriptor) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&descriptor,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnBackendInitialize) < 0 ||
      rpc_write(conn, &descriptor, sizeof(cudnnBackendDescriptor_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&descriptor,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnBackendFinalize(cudnnBackendDescriptor_t descriptor) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&descriptor,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnBackendFinalize) < 0 ||
      rpc_write(conn, &descriptor, sizeof(cudnnBackendDescriptor_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&descriptor,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t
cudnnBackendSetAttribute(cudnnBackendDescriptor_t descriptor,
                         cudnnBackendAttributeName_t attributeName,
                         cudnnBackendAttributeType_t attributeType,
                         int64_t elementCount, const void *arrayOfElements) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&descriptor,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&attributeName,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&attributeType,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&elementCount,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)arrayOfElements,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnBackendSetAttribute) < 0 ||
      rpc_write(conn, &descriptor, sizeof(cudnnBackendDescriptor_t)) < 0 ||
      rpc_write(conn, &attributeName, sizeof(cudnnBackendAttributeName_t)) <
          0 ||
      rpc_write(conn, &attributeType, sizeof(cudnnBackendAttributeType_t)) <
          0 ||
      rpc_write(conn, &elementCount, sizeof(int64_t)) < 0 ||
      rpc_write(conn, &arrayOfElements, sizeof(const void *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&descriptor,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&attributeName,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&attributeType,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&elementCount,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)arrayOfElements,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnBackendExecute(cudnnHandle_t handle,
                                  cudnnBackendDescriptor_t executionPlan,
                                  cudnnBackendDescriptor_t variantPack) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&executionPlan,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&variantPack,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnBackendExecute) < 0 ||
      rpc_write(conn, &handle, sizeof(cudnnHandle_t)) < 0 ||
      rpc_write(conn, &executionPlan, sizeof(cudnnBackendDescriptor_t)) < 0 ||
      rpc_write(conn, &variantPack, sizeof(cudnnBackendDescriptor_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&executionPlan,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&variantPack,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnBackendPopulateCudaGraph(
    cudnnHandle_t handle, cudnnBackendDescriptor_t executionPlan,
    cudnnBackendDescriptor_t variantPack, cudaGraph_t graph) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&executionPlan,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&variantPack,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&graph, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnBackendPopulateCudaGraph) < 0 ||
      rpc_write(conn, &handle, sizeof(cudnnHandle_t)) < 0 ||
      rpc_write(conn, &executionPlan, sizeof(cudnnBackendDescriptor_t)) < 0 ||
      rpc_write(conn, &variantPack, sizeof(cudnnBackendDescriptor_t)) < 0 ||
      rpc_write(conn, &graph, sizeof(cudaGraph_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&executionPlan,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&variantPack,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&graph, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnBackendUpdateCudaGraph(
    cudnnHandle_t handle, cudnnBackendDescriptor_t executionPlan,
    cudnnBackendDescriptor_t variantPack, cudaGraph_t graph) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&executionPlan,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&variantPack,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&graph, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnBackendUpdateCudaGraph) < 0 ||
      rpc_write(conn, &handle, sizeof(cudnnHandle_t)) < 0 ||
      rpc_write(conn, &executionPlan, sizeof(cudnnBackendDescriptor_t)) < 0 ||
      rpc_write(conn, &variantPack, sizeof(cudnnBackendDescriptor_t)) < 0 ||
      rpc_write(conn, &graph, sizeof(cudaGraph_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&executionPlan,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&variantPack,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&graph, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnCreateTensorDescriptor(cudnnTensorDescriptor_t *tensorDesc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)tensorDesc, cudaMemcpyHostToDevice) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnCreateTensorDescriptor) < 0 ||
      rpc_write(conn, tensorDesc, sizeof(cudnnTensorDescriptor_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, tensorDesc, sizeof(cudnnTensorDescriptor_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)tensorDesc, cudaMemcpyDeviceToHost) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnSetTensor4dDescriptor(cudnnTensorDescriptor_t tensorDesc,
                                         cudnnTensorFormat_t format,
                                         cudnnDataType_t dataType, int n, int c,
                                         int h, int w) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&tensorDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&format, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&dataType, cudaMemcpyHostToDevice) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&c, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&h, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&w, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnSetTensor4dDescriptor) < 0 ||
      rpc_write(conn, &tensorDesc, sizeof(cudnnTensorDescriptor_t)) < 0 ||
      rpc_write(conn, &format, sizeof(cudnnTensorFormat_t)) < 0 ||
      rpc_write(conn, &dataType, sizeof(cudnnDataType_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &c, sizeof(int)) < 0 ||
      rpc_write(conn, &h, sizeof(int)) < 0 ||
      rpc_write(conn, &w, sizeof(int)) < 0 || rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&tensorDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&format, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&dataType, cudaMemcpyDeviceToHost) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&c, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&h, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&w, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnSetTensor4dDescriptorEx(cudnnTensorDescriptor_t tensorDesc,
                                           cudnnDataType_t dataType, int n,
                                           int c, int h, int w, int nStride,
                                           int cStride, int hStride,
                                           int wStride) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&tensorDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&dataType, cudaMemcpyHostToDevice) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&c, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&h, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&w, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&nStride, cudaMemcpyHostToDevice) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&cStride, cudaMemcpyHostToDevice) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&hStride, cudaMemcpyHostToDevice) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&wStride, cudaMemcpyHostToDevice) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnSetTensor4dDescriptorEx) < 0 ||
      rpc_write(conn, &tensorDesc, sizeof(cudnnTensorDescriptor_t)) < 0 ||
      rpc_write(conn, &dataType, sizeof(cudnnDataType_t)) < 0 ||
      rpc_write(conn, &n, sizeof(int)) < 0 ||
      rpc_write(conn, &c, sizeof(int)) < 0 ||
      rpc_write(conn, &h, sizeof(int)) < 0 ||
      rpc_write(conn, &w, sizeof(int)) < 0 ||
      rpc_write(conn, &nStride, sizeof(int)) < 0 ||
      rpc_write(conn, &cStride, sizeof(int)) < 0 ||
      rpc_write(conn, &hStride, sizeof(int)) < 0 ||
      rpc_write(conn, &wStride, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&tensorDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&dataType, cudaMemcpyDeviceToHost) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&n, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&c, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&h, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&w, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&nStride, cudaMemcpyDeviceToHost) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&cStride, cudaMemcpyDeviceToHost) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&hStride, cudaMemcpyDeviceToHost) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&wStride, cudaMemcpyDeviceToHost) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t
cudnnGetTensor4dDescriptor(const cudnnTensorDescriptor_t tensorDesc,
                           cudnnDataType_t *dataType, int *n, int *c, int *h,
                           int *w, int *nStride, int *cStride, int *hStride,
                           int *wStride) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&tensorDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)dataType, cudaMemcpyHostToDevice) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)n, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)c, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)h, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)w, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)nStride, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)cStride, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)hStride, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)wStride, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnGetTensor4dDescriptor) < 0 ||
      rpc_write(conn, &tensorDesc, sizeof(const cudnnTensorDescriptor_t)) < 0 ||
      rpc_write(conn, dataType, sizeof(cudnnDataType_t)) < 0 ||
      rpc_write(conn, n, sizeof(int)) < 0 ||
      rpc_write(conn, c, sizeof(int)) < 0 ||
      rpc_write(conn, h, sizeof(int)) < 0 ||
      rpc_write(conn, w, sizeof(int)) < 0 ||
      rpc_write(conn, nStride, sizeof(int)) < 0 ||
      rpc_write(conn, cStride, sizeof(int)) < 0 ||
      rpc_write(conn, hStride, sizeof(int)) < 0 ||
      rpc_write(conn, wStride, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, dataType, sizeof(cudnnDataType_t)) < 0 ||
      rpc_read(conn, n, sizeof(int)) < 0 ||
      rpc_read(conn, c, sizeof(int)) < 0 ||
      rpc_read(conn, h, sizeof(int)) < 0 ||
      rpc_read(conn, w, sizeof(int)) < 0 ||
      rpc_read(conn, nStride, sizeof(int)) < 0 ||
      rpc_read(conn, cStride, sizeof(int)) < 0 ||
      rpc_read(conn, hStride, sizeof(int)) < 0 ||
      rpc_read(conn, wStride, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&tensorDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)dataType, cudaMemcpyDeviceToHost) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)n, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)c, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)h, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)w, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)nStride, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)cStride, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)hStride, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)wStride, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t
cudnnGetTensorSizeInBytes(const cudnnTensorDescriptor_t tensorDesc,
                          size_t *size) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&tensorDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)size, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnGetTensorSizeInBytes) < 0 ||
      rpc_write(conn, &tensorDesc, sizeof(const cudnnTensorDescriptor_t)) < 0 ||
      rpc_write(conn, size, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, size, sizeof(size_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&tensorDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)size, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnDestroyTensorDescriptor(cudnnTensorDescriptor_t tensorDesc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&tensorDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnDestroyTensorDescriptor) < 0 ||
      rpc_write(conn, &tensorDesc, sizeof(cudnnTensorDescriptor_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&tensorDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t
cudnnInitTransformDest(const cudnnTensorTransformDescriptor_t transformDesc,
                       const cudnnTensorDescriptor_t srcDesc,
                       cudnnTensorDescriptor_t destDesc,
                       size_t *destSizeInBytes) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&transformDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&srcDesc, cudaMemcpyHostToDevice) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&destDesc, cudaMemcpyHostToDevice) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)destSizeInBytes,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnInitTransformDest) < 0 ||
      rpc_write(conn, &transformDesc,
                sizeof(const cudnnTensorTransformDescriptor_t)) < 0 ||
      rpc_write(conn, &srcDesc, sizeof(const cudnnTensorDescriptor_t)) < 0 ||
      rpc_write(conn, &destDesc, sizeof(cudnnTensorDescriptor_t)) < 0 ||
      rpc_write(conn, destSizeInBytes, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, destSizeInBytes, sizeof(size_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transformDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&srcDesc, cudaMemcpyDeviceToHost) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&destDesc, cudaMemcpyDeviceToHost) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)destSizeInBytes,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnCreateTensorTransformDescriptor(
    cudnnTensorTransformDescriptor_t *transformDesc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)transformDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnCreateTensorTransformDescriptor) <
          0 ||
      rpc_write(conn, transformDesc, sizeof(cudnnTensorTransformDescriptor_t)) <
          0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, transformDesc, sizeof(cudnnTensorTransformDescriptor_t)) <
          0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)transformDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnDestroyTensorTransformDescriptor(
    cudnnTensorTransformDescriptor_t transformDesc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&transformDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnDestroyTensorTransformDescriptor) <
          0 ||
      rpc_write(conn, &transformDesc,
                sizeof(cudnnTensorTransformDescriptor_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&transformDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t
cudnnCreateOpTensorDescriptor(cudnnOpTensorDescriptor_t *opTensorDesc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)opTensorDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnCreateOpTensorDescriptor) < 0 ||
      rpc_write(conn, opTensorDesc, sizeof(cudnnOpTensorDescriptor_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, opTensorDesc, sizeof(cudnnOpTensorDescriptor_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)opTensorDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnSetOpTensorDescriptor(cudnnOpTensorDescriptor_t opTensorDesc,
                                         cudnnOpTensorOp_t opTensorOp,
                                         cudnnDataType_t opTensorCompType,
                                         cudnnNanPropagation_t opTensorNanOpt) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&opTensorDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&opTensorOp,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&opTensorCompType,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&opTensorNanOpt,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnSetOpTensorDescriptor) < 0 ||
      rpc_write(conn, &opTensorDesc, sizeof(cudnnOpTensorDescriptor_t)) < 0 ||
      rpc_write(conn, &opTensorOp, sizeof(cudnnOpTensorOp_t)) < 0 ||
      rpc_write(conn, &opTensorCompType, sizeof(cudnnDataType_t)) < 0 ||
      rpc_write(conn, &opTensorNanOpt, sizeof(cudnnNanPropagation_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&opTensorDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&opTensorOp,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&opTensorCompType,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&opTensorNanOpt,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnGetOpTensorDescriptor(
    const cudnnOpTensorDescriptor_t opTensorDesc, cudnnOpTensorOp_t *opTensorOp,
    cudnnDataType_t *opTensorCompType, cudnnNanPropagation_t *opTensorNanOpt) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&opTensorDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)opTensorOp, cudaMemcpyHostToDevice) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)opTensorCompType,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)opTensorNanOpt,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnGetOpTensorDescriptor) < 0 ||
      rpc_write(conn, &opTensorDesc, sizeof(const cudnnOpTensorDescriptor_t)) <
          0 ||
      rpc_write(conn, opTensorOp, sizeof(cudnnOpTensorOp_t)) < 0 ||
      rpc_write(conn, opTensorCompType, sizeof(cudnnDataType_t)) < 0 ||
      rpc_write(conn, opTensorNanOpt, sizeof(cudnnNanPropagation_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, opTensorOp, sizeof(cudnnOpTensorOp_t)) < 0 ||
      rpc_read(conn, opTensorCompType, sizeof(cudnnDataType_t)) < 0 ||
      rpc_read(conn, opTensorNanOpt, sizeof(cudnnNanPropagation_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&opTensorDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)opTensorOp, cudaMemcpyDeviceToHost) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)opTensorCompType,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)opTensorNanOpt,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t
cudnnDestroyOpTensorDescriptor(cudnnOpTensorDescriptor_t opTensorDesc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&opTensorDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnDestroyOpTensorDescriptor) < 0 ||
      rpc_write(conn, &opTensorDesc, sizeof(cudnnOpTensorDescriptor_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&opTensorDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnCreateReduceTensorDescriptor(
    cudnnReduceTensorDescriptor_t *reduceTensorDesc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)reduceTensorDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnCreateReduceTensorDescriptor) <
          0 ||
      rpc_write(conn, reduceTensorDesc, sizeof(cudnnReduceTensorDescriptor_t)) <
          0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, reduceTensorDesc, sizeof(cudnnReduceTensorDescriptor_t)) <
          0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)reduceTensorDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t
cudnnSetReduceTensorDescriptor(cudnnReduceTensorDescriptor_t reduceTensorDesc,
                               cudnnReduceTensorOp_t reduceTensorOp,
                               cudnnDataType_t reduceTensorCompType,
                               cudnnNanPropagation_t reduceTensorNanOpt,
                               cudnnReduceTensorIndices_t reduceTensorIndices,
                               cudnnIndicesType_t reduceTensorIndicesType) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&reduceTensorDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&reduceTensorOp,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&reduceTensorCompType,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&reduceTensorNanOpt,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&reduceTensorIndices,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&reduceTensorIndicesType,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnSetReduceTensorDescriptor) < 0 ||
      rpc_write(conn, &reduceTensorDesc,
                sizeof(cudnnReduceTensorDescriptor_t)) < 0 ||
      rpc_write(conn, &reduceTensorOp, sizeof(cudnnReduceTensorOp_t)) < 0 ||
      rpc_write(conn, &reduceTensorCompType, sizeof(cudnnDataType_t)) < 0 ||
      rpc_write(conn, &reduceTensorNanOpt, sizeof(cudnnNanPropagation_t)) < 0 ||
      rpc_write(conn, &reduceTensorIndices,
                sizeof(cudnnReduceTensorIndices_t)) < 0 ||
      rpc_write(conn, &reduceTensorIndicesType, sizeof(cudnnIndicesType_t)) <
          0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&reduceTensorDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&reduceTensorOp,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&reduceTensorCompType,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&reduceTensorNanOpt,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&reduceTensorIndices,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&reduceTensorIndicesType,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnGetReduceTensorDescriptor(
    const cudnnReduceTensorDescriptor_t reduceTensorDesc,
    cudnnReduceTensorOp_t *reduceTensorOp,
    cudnnDataType_t *reduceTensorCompType,
    cudnnNanPropagation_t *reduceTensorNanOpt,
    cudnnReduceTensorIndices_t *reduceTensorIndices,
    cudnnIndicesType_t *reduceTensorIndicesType) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&reduceTensorDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)reduceTensorOp,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)reduceTensorCompType,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)reduceTensorNanOpt,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)reduceTensorIndices,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)reduceTensorIndicesType,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnGetReduceTensorDescriptor) < 0 ||
      rpc_write(conn, &reduceTensorDesc,
                sizeof(const cudnnReduceTensorDescriptor_t)) < 0 ||
      rpc_write(conn, reduceTensorOp, sizeof(cudnnReduceTensorOp_t)) < 0 ||
      rpc_write(conn, reduceTensorCompType, sizeof(cudnnDataType_t)) < 0 ||
      rpc_write(conn, reduceTensorNanOpt, sizeof(cudnnNanPropagation_t)) < 0 ||
      rpc_write(conn, reduceTensorIndices, sizeof(cudnnReduceTensorIndices_t)) <
          0 ||
      rpc_write(conn, reduceTensorIndicesType, sizeof(cudnnIndicesType_t)) <
          0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, reduceTensorOp, sizeof(cudnnReduceTensorOp_t)) < 0 ||
      rpc_read(conn, reduceTensorCompType, sizeof(cudnnDataType_t)) < 0 ||
      rpc_read(conn, reduceTensorNanOpt, sizeof(cudnnNanPropagation_t)) < 0 ||
      rpc_read(conn, reduceTensorIndices, sizeof(cudnnReduceTensorIndices_t)) <
          0 ||
      rpc_read(conn, reduceTensorIndicesType, sizeof(cudnnIndicesType_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&reduceTensorDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)reduceTensorOp,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)reduceTensorCompType,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)reduceTensorNanOpt,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)reduceTensorIndices,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)reduceTensorIndicesType,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnDestroyReduceTensorDescriptor(
    cudnnReduceTensorDescriptor_t reduceTensorDesc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&reduceTensorDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnDestroyReduceTensorDescriptor) <
          0 ||
      rpc_write(conn, &reduceTensorDesc,
                sizeof(cudnnReduceTensorDescriptor_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&reduceTensorDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnGetReductionIndicesSize(
    cudnnHandle_t handle, const cudnnReduceTensorDescriptor_t reduceTensorDesc,
    const cudnnTensorDescriptor_t aDesc, const cudnnTensorDescriptor_t cDesc,
    size_t *sizeInBytes) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&reduceTensorDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&aDesc, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&cDesc, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)sizeInBytes,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnGetReductionIndicesSize) < 0 ||
      rpc_write(conn, &handle, sizeof(cudnnHandle_t)) < 0 ||
      rpc_write(conn, &reduceTensorDesc,
                sizeof(const cudnnReduceTensorDescriptor_t)) < 0 ||
      rpc_write(conn, &aDesc, sizeof(const cudnnTensorDescriptor_t)) < 0 ||
      rpc_write(conn, &cDesc, sizeof(const cudnnTensorDescriptor_t)) < 0 ||
      rpc_write(conn, sizeInBytes, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, sizeInBytes, sizeof(size_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&reduceTensorDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&aDesc, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&cDesc, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)sizeInBytes,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnGetReductionWorkspaceSize(
    cudnnHandle_t handle, const cudnnReduceTensorDescriptor_t reduceTensorDesc,
    const cudnnTensorDescriptor_t aDesc, const cudnnTensorDescriptor_t cDesc,
    size_t *sizeInBytes) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&reduceTensorDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&aDesc, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&cDesc, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)sizeInBytes,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnGetReductionWorkspaceSize) < 0 ||
      rpc_write(conn, &handle, sizeof(cudnnHandle_t)) < 0 ||
      rpc_write(conn, &reduceTensorDesc,
                sizeof(const cudnnReduceTensorDescriptor_t)) < 0 ||
      rpc_write(conn, &aDesc, sizeof(const cudnnTensorDescriptor_t)) < 0 ||
      rpc_write(conn, &cDesc, sizeof(const cudnnTensorDescriptor_t)) < 0 ||
      rpc_write(conn, sizeInBytes, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, sizeInBytes, sizeof(size_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&reduceTensorDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&aDesc, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&cDesc, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)sizeInBytes,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnCreateFilterDescriptor(cudnnFilterDescriptor_t *filterDesc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)filterDesc, cudaMemcpyHostToDevice) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnCreateFilterDescriptor) < 0 ||
      rpc_write(conn, filterDesc, sizeof(cudnnFilterDescriptor_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, filterDesc, sizeof(cudnnFilterDescriptor_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)filterDesc, cudaMemcpyDeviceToHost) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnSetFilter4dDescriptor(cudnnFilterDescriptor_t filterDesc,
                                         cudnnDataType_t dataType,
                                         cudnnTensorFormat_t format, int k,
                                         int c, int h, int w) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&filterDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&dataType, cudaMemcpyHostToDevice) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&format, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&c, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&h, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&w, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnSetFilter4dDescriptor) < 0 ||
      rpc_write(conn, &filterDesc, sizeof(cudnnFilterDescriptor_t)) < 0 ||
      rpc_write(conn, &dataType, sizeof(cudnnDataType_t)) < 0 ||
      rpc_write(conn, &format, sizeof(cudnnTensorFormat_t)) < 0 ||
      rpc_write(conn, &k, sizeof(int)) < 0 ||
      rpc_write(conn, &c, sizeof(int)) < 0 ||
      rpc_write(conn, &h, sizeof(int)) < 0 ||
      rpc_write(conn, &w, sizeof(int)) < 0 || rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&filterDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&dataType, cudaMemcpyDeviceToHost) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&format, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&k, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&c, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&h, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&w, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnGetFilter4dDescriptor(
    const cudnnFilterDescriptor_t filterDesc, cudnnDataType_t *dataType,
    cudnnTensorFormat_t *format, int *k, int *c, int *h, int *w) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&filterDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)dataType, cudaMemcpyHostToDevice) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)format, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)k, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)c, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)h, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)w, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnGetFilter4dDescriptor) < 0 ||
      rpc_write(conn, &filterDesc, sizeof(const cudnnFilterDescriptor_t)) < 0 ||
      rpc_write(conn, dataType, sizeof(cudnnDataType_t)) < 0 ||
      rpc_write(conn, format, sizeof(cudnnTensorFormat_t)) < 0 ||
      rpc_write(conn, k, sizeof(int)) < 0 ||
      rpc_write(conn, c, sizeof(int)) < 0 ||
      rpc_write(conn, h, sizeof(int)) < 0 ||
      rpc_write(conn, w, sizeof(int)) < 0 || rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, dataType, sizeof(cudnnDataType_t)) < 0 ||
      rpc_read(conn, format, sizeof(cudnnTensorFormat_t)) < 0 ||
      rpc_read(conn, k, sizeof(int)) < 0 ||
      rpc_read(conn, c, sizeof(int)) < 0 ||
      rpc_read(conn, h, sizeof(int)) < 0 ||
      rpc_read(conn, w, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&filterDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)dataType, cudaMemcpyDeviceToHost) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)format, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)k, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)c, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)h, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)w, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t
cudnnGetFilterSizeInBytes(const cudnnFilterDescriptor_t filterDesc,
                          size_t *size) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&filterDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)size, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnGetFilterSizeInBytes) < 0 ||
      rpc_write(conn, &filterDesc, sizeof(const cudnnFilterDescriptor_t)) < 0 ||
      rpc_write(conn, size, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, size, sizeof(size_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&filterDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)size, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnDestroyFilterDescriptor(cudnnFilterDescriptor_t filterDesc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&filterDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnDestroyFilterDescriptor) < 0 ||
      rpc_write(conn, &filterDesc, sizeof(cudnnFilterDescriptor_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&filterDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t
cudnnCreatePoolingDescriptor(cudnnPoolingDescriptor_t *poolingDesc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)poolingDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnCreatePoolingDescriptor) < 0 ||
      rpc_write(conn, poolingDesc, sizeof(cudnnPoolingDescriptor_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, poolingDesc, sizeof(cudnnPoolingDescriptor_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)poolingDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnSetPooling2dDescriptor(
    cudnnPoolingDescriptor_t poolingDesc, cudnnPoolingMode_t mode,
    cudnnNanPropagation_t maxpoolingNanOpt, int windowHeight, int windowWidth,
    int verticalPadding, int horizontalPadding, int verticalStride,
    int horizontalStride) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&poolingDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&maxpoolingNanOpt,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&windowHeight,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&windowWidth,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&verticalPadding,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&horizontalPadding,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&verticalStride,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&horizontalStride,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnSetPooling2dDescriptor) < 0 ||
      rpc_write(conn, &poolingDesc, sizeof(cudnnPoolingDescriptor_t)) < 0 ||
      rpc_write(conn, &mode, sizeof(cudnnPoolingMode_t)) < 0 ||
      rpc_write(conn, &maxpoolingNanOpt, sizeof(cudnnNanPropagation_t)) < 0 ||
      rpc_write(conn, &windowHeight, sizeof(int)) < 0 ||
      rpc_write(conn, &windowWidth, sizeof(int)) < 0 ||
      rpc_write(conn, &verticalPadding, sizeof(int)) < 0 ||
      rpc_write(conn, &horizontalPadding, sizeof(int)) < 0 ||
      rpc_write(conn, &verticalStride, sizeof(int)) < 0 ||
      rpc_write(conn, &horizontalStride, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&poolingDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&maxpoolingNanOpt,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&windowHeight,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&windowWidth,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&verticalPadding,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&horizontalPadding,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&verticalStride,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&horizontalStride,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnGetPooling2dDescriptor(
    const cudnnPoolingDescriptor_t poolingDesc, cudnnPoolingMode_t *mode,
    cudnnNanPropagation_t *maxpoolingNanOpt, int *windowHeight,
    int *windowWidth, int *verticalPadding, int *horizontalPadding,
    int *verticalStride, int *horizontalStride) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&poolingDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)mode, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)maxpoolingNanOpt,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)windowHeight,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)windowWidth,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)verticalPadding,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)horizontalPadding,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)verticalStride,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)horizontalStride,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnGetPooling2dDescriptor) < 0 ||
      rpc_write(conn, &poolingDesc, sizeof(const cudnnPoolingDescriptor_t)) <
          0 ||
      rpc_write(conn, mode, sizeof(cudnnPoolingMode_t)) < 0 ||
      rpc_write(conn, maxpoolingNanOpt, sizeof(cudnnNanPropagation_t)) < 0 ||
      rpc_write(conn, windowHeight, sizeof(int)) < 0 ||
      rpc_write(conn, windowWidth, sizeof(int)) < 0 ||
      rpc_write(conn, verticalPadding, sizeof(int)) < 0 ||
      rpc_write(conn, horizontalPadding, sizeof(int)) < 0 ||
      rpc_write(conn, verticalStride, sizeof(int)) < 0 ||
      rpc_write(conn, horizontalStride, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, mode, sizeof(cudnnPoolingMode_t)) < 0 ||
      rpc_read(conn, maxpoolingNanOpt, sizeof(cudnnNanPropagation_t)) < 0 ||
      rpc_read(conn, windowHeight, sizeof(int)) < 0 ||
      rpc_read(conn, windowWidth, sizeof(int)) < 0 ||
      rpc_read(conn, verticalPadding, sizeof(int)) < 0 ||
      rpc_read(conn, horizontalPadding, sizeof(int)) < 0 ||
      rpc_read(conn, verticalStride, sizeof(int)) < 0 ||
      rpc_read(conn, horizontalStride, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&poolingDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)mode, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)maxpoolingNanOpt,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)windowHeight,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)windowWidth,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)verticalPadding,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)horizontalPadding,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)verticalStride,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)horizontalStride,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t
cudnnGetPooling2dForwardOutputDim(const cudnnPoolingDescriptor_t poolingDesc,
                                  const cudnnTensorDescriptor_t inputTensorDesc,
                                  int *n, int *c, int *h, int *w) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&poolingDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&inputTensorDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)n, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)c, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)h, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)w, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnGetPooling2dForwardOutputDim) <
          0 ||
      rpc_write(conn, &poolingDesc, sizeof(const cudnnPoolingDescriptor_t)) <
          0 ||
      rpc_write(conn, &inputTensorDesc, sizeof(const cudnnTensorDescriptor_t)) <
          0 ||
      rpc_write(conn, n, sizeof(int)) < 0 ||
      rpc_write(conn, c, sizeof(int)) < 0 ||
      rpc_write(conn, h, sizeof(int)) < 0 ||
      rpc_write(conn, w, sizeof(int)) < 0 || rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, n, sizeof(int)) < 0 ||
      rpc_read(conn, c, sizeof(int)) < 0 ||
      rpc_read(conn, h, sizeof(int)) < 0 ||
      rpc_read(conn, w, sizeof(int)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&poolingDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&inputTensorDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)n, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)c, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)h, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)w, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t
cudnnDestroyPoolingDescriptor(cudnnPoolingDescriptor_t poolingDesc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&poolingDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnDestroyPoolingDescriptor) < 0 ||
      rpc_write(conn, &poolingDesc, sizeof(cudnnPoolingDescriptor_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&poolingDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t
cudnnCreateActivationDescriptor(cudnnActivationDescriptor_t *activationDesc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)activationDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnCreateActivationDescriptor) < 0 ||
      rpc_write(conn, activationDesc, sizeof(cudnnActivationDescriptor_t)) <
          0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, activationDesc, sizeof(cudnnActivationDescriptor_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)activationDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t
cudnnSetActivationDescriptor(cudnnActivationDescriptor_t activationDesc,
                             cudnnActivationMode_t mode,
                             cudnnNanPropagation_t reluNanOpt, double coef) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&activationDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&reluNanOpt,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&coef, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnSetActivationDescriptor) < 0 ||
      rpc_write(conn, &activationDesc, sizeof(cudnnActivationDescriptor_t)) <
          0 ||
      rpc_write(conn, &mode, sizeof(cudnnActivationMode_t)) < 0 ||
      rpc_write(conn, &reluNanOpt, sizeof(cudnnNanPropagation_t)) < 0 ||
      rpc_write(conn, &coef, sizeof(double)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&activationDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&reluNanOpt,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&coef, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t
cudnnGetActivationDescriptor(const cudnnActivationDescriptor_t activationDesc,
                             cudnnActivationMode_t *mode,
                             cudnnNanPropagation_t *reluNanOpt, double *coef) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&activationDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)mode, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)reluNanOpt, cudaMemcpyHostToDevice) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)coef, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnGetActivationDescriptor) < 0 ||
      rpc_write(conn, &activationDesc,
                sizeof(const cudnnActivationDescriptor_t)) < 0 ||
      rpc_write(conn, mode, sizeof(cudnnActivationMode_t)) < 0 ||
      rpc_write(conn, reluNanOpt, sizeof(cudnnNanPropagation_t)) < 0 ||
      rpc_write(conn, coef, sizeof(double)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, mode, sizeof(cudnnActivationMode_t)) < 0 ||
      rpc_read(conn, reluNanOpt, sizeof(cudnnNanPropagation_t)) < 0 ||
      rpc_read(conn, coef, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&activationDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)mode, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)reluNanOpt, cudaMemcpyDeviceToHost) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)coef, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnSetActivationDescriptorSwishBeta(
    cudnnActivationDescriptor_t activationDesc, double swish_beta) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&activationDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&swish_beta,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnSetActivationDescriptorSwishBeta) <
          0 ||
      rpc_write(conn, &activationDesc, sizeof(cudnnActivationDescriptor_t)) <
          0 ||
      rpc_write(conn, &swish_beta, sizeof(double)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&activationDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&swish_beta,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnGetActivationDescriptorSwishBeta(
    cudnnActivationDescriptor_t activationDesc, double *swish_beta) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&activationDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)swish_beta, cudaMemcpyHostToDevice) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnGetActivationDescriptorSwishBeta) <
          0 ||
      rpc_write(conn, &activationDesc, sizeof(cudnnActivationDescriptor_t)) <
          0 ||
      rpc_write(conn, swish_beta, sizeof(double)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, swish_beta, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&activationDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)swish_beta, cudaMemcpyDeviceToHost) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t
cudnnDestroyActivationDescriptor(cudnnActivationDescriptor_t activationDesc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&activationDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnDestroyActivationDescriptor) < 0 ||
      rpc_write(conn, &activationDesc, sizeof(cudnnActivationDescriptor_t)) <
          0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&activationDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnActivationForward(
    cudnnHandle_t handle, cudnnActivationDescriptor_t activationDesc,
    const void *alpha, const cudnnTensorDescriptor_t xDesc, const void *x,
    const void *beta, const cudnnTensorDescriptor_t yDesc, void *y) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&activationDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&xDesc, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&yDesc, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnActivationForward) < 0 ||
      rpc_write(conn, &handle, sizeof(cudnnHandle_t)) < 0 ||
      rpc_write(conn, &activationDesc, sizeof(cudnnActivationDescriptor_t)) <
          0 ||
      rpc_write(conn, &alpha, sizeof(const void *)) < 0 ||
      (alpha != nullptr && rpc_write(conn, alpha, sizeof(const void *)) < 0) ||
      rpc_write(conn, &xDesc, sizeof(const cudnnTensorDescriptor_t)) < 0 ||
      rpc_write(conn, &x, sizeof(const void *)) < 0 ||
      rpc_write(conn, &beta, sizeof(const void *)) < 0 ||
      (beta != nullptr && rpc_write(conn, beta, sizeof(const void *)) < 0) ||
      rpc_write(conn, &yDesc, sizeof(const cudnnTensorDescriptor_t)) < 0 ||
      rpc_write(conn, &y, sizeof(void *)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&activationDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)alpha, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&xDesc, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)x, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)beta, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&yDesc, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)y, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnCreateLRNDescriptor(cudnnLRNDescriptor_t *normDesc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)normDesc, cudaMemcpyHostToDevice) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnCreateLRNDescriptor) < 0 ||
      rpc_write(conn, normDesc, sizeof(cudnnLRNDescriptor_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, normDesc, sizeof(cudnnLRNDescriptor_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)normDesc, cudaMemcpyDeviceToHost) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnSetLRNDescriptor(cudnnLRNDescriptor_t normDesc,
                                    unsigned lrnN, double lrnAlpha,
                                    double lrnBeta, double lrnK) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&normDesc, cudaMemcpyHostToDevice) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lrnN, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lrnAlpha, cudaMemcpyHostToDevice) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lrnBeta, cudaMemcpyHostToDevice) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lrnK, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnSetLRNDescriptor) < 0 ||
      rpc_write(conn, &normDesc, sizeof(cudnnLRNDescriptor_t)) < 0 ||
      rpc_write(conn, &lrnN, sizeof(unsigned)) < 0 ||
      rpc_write(conn, &lrnAlpha, sizeof(double)) < 0 ||
      rpc_write(conn, &lrnBeta, sizeof(double)) < 0 ||
      rpc_write(conn, &lrnK, sizeof(double)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&normDesc, cudaMemcpyDeviceToHost) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lrnN, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lrnAlpha, cudaMemcpyDeviceToHost) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lrnBeta, cudaMemcpyDeviceToHost) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lrnK, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnGetLRNDescriptor(cudnnLRNDescriptor_t normDesc,
                                    unsigned *lrnN, double *lrnAlpha,
                                    double *lrnBeta, double *lrnK) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&normDesc, cudaMemcpyHostToDevice) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)lrnN, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)lrnAlpha, cudaMemcpyHostToDevice) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)lrnBeta, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)lrnK, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnGetLRNDescriptor) < 0 ||
      rpc_write(conn, &normDesc, sizeof(cudnnLRNDescriptor_t)) < 0 ||
      rpc_write(conn, lrnN, sizeof(unsigned)) < 0 ||
      rpc_write(conn, lrnAlpha, sizeof(double)) < 0 ||
      rpc_write(conn, lrnBeta, sizeof(double)) < 0 ||
      rpc_write(conn, lrnK, sizeof(double)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, lrnN, sizeof(unsigned)) < 0 ||
      rpc_read(conn, lrnAlpha, sizeof(double)) < 0 ||
      rpc_read(conn, lrnBeta, sizeof(double)) < 0 ||
      rpc_read(conn, lrnK, sizeof(double)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&normDesc, cudaMemcpyDeviceToHost) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)lrnN, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)lrnAlpha, cudaMemcpyDeviceToHost) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)lrnBeta, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)lrnK, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnDestroyLRNDescriptor(cudnnLRNDescriptor_t lrnDesc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&lrnDesc, cudaMemcpyHostToDevice) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnDestroyLRNDescriptor) < 0 ||
      rpc_write(conn, &lrnDesc, sizeof(cudnnLRNDescriptor_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&lrnDesc, cudaMemcpyDeviceToHost) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t
cudnnDeriveBNTensorDescriptor(cudnnTensorDescriptor_t derivedBnDesc,
                              const cudnnTensorDescriptor_t xDesc,
                              cudnnBatchNormMode_t mode) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&derivedBnDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&xDesc, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnDeriveBNTensorDescriptor) < 0 ||
      rpc_write(conn, &derivedBnDesc, sizeof(cudnnTensorDescriptor_t)) < 0 ||
      rpc_write(conn, &xDesc, sizeof(const cudnnTensorDescriptor_t)) < 0 ||
      rpc_write(conn, &mode, sizeof(cudnnBatchNormMode_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&derivedBnDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&xDesc, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnDeriveNormTensorDescriptor(
    cudnnTensorDescriptor_t derivedNormScaleBiasDesc,
    cudnnTensorDescriptor_t derivedNormMeanVarDesc,
    const cudnnTensorDescriptor_t xDesc, cudnnNormMode_t mode, int groupCnt) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&derivedNormScaleBiasDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&derivedNormMeanVarDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&xDesc, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&groupCnt, cudaMemcpyHostToDevice) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnDeriveNormTensorDescriptor) < 0 ||
      rpc_write(conn, &derivedNormScaleBiasDesc,
                sizeof(cudnnTensorDescriptor_t)) < 0 ||
      rpc_write(conn, &derivedNormMeanVarDesc,
                sizeof(cudnnTensorDescriptor_t)) < 0 ||
      rpc_write(conn, &xDesc, sizeof(const cudnnTensorDescriptor_t)) < 0 ||
      rpc_write(conn, &mode, sizeof(cudnnNormMode_t)) < 0 ||
      rpc_write(conn, &groupCnt, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&derivedNormScaleBiasDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&derivedNormMeanVarDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&xDesc, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&groupCnt, cudaMemcpyDeviceToHost) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnCreateSpatialTransformerDescriptor(
    cudnnSpatialTransformerDescriptor_t *stDesc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)stDesc, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(
          conn, RPC_cudnnCreateSpatialTransformerDescriptor) < 0 ||
      rpc_write(conn, stDesc, sizeof(cudnnSpatialTransformerDescriptor_t)) <
          0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, stDesc, sizeof(cudnnSpatialTransformerDescriptor_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)stDesc, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnDestroySpatialTransformerDescriptor(
    cudnnSpatialTransformerDescriptor_t stDesc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&stDesc, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(
          conn, RPC_cudnnDestroySpatialTransformerDescriptor) < 0 ||
      rpc_write(conn, &stDesc, sizeof(cudnnSpatialTransformerDescriptor_t)) <
          0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&stDesc, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t
cudnnCreateDropoutDescriptor(cudnnDropoutDescriptor_t *dropoutDesc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)dropoutDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnCreateDropoutDescriptor) < 0 ||
      rpc_write(conn, dropoutDesc, sizeof(cudnnDropoutDescriptor_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, dropoutDesc, sizeof(cudnnDropoutDescriptor_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)dropoutDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t
cudnnDestroyDropoutDescriptor(cudnnDropoutDescriptor_t dropoutDesc) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&dropoutDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnDestroyDropoutDescriptor) < 0 ||
      rpc_write(conn, &dropoutDesc, sizeof(cudnnDropoutDescriptor_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&dropoutDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnDropoutGetStatesSize(cudnnHandle_t handle,
                                        size_t *sizeInBytes) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)sizeInBytes,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnDropoutGetStatesSize) < 0 ||
      rpc_write(conn, &handle, sizeof(cudnnHandle_t)) < 0 ||
      rpc_write(conn, sizeInBytes, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, sizeInBytes, sizeof(size_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)sizeInBytes,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnDropoutGetReserveSpaceSize(cudnnTensorDescriptor_t xdesc,
                                              size_t *sizeInBytes) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&xdesc, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)sizeInBytes,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnDropoutGetReserveSpaceSize) < 0 ||
      rpc_write(conn, &xdesc, sizeof(cudnnTensorDescriptor_t)) < 0 ||
      rpc_write(conn, sizeInBytes, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, sizeInBytes, sizeof(size_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&xdesc, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)sizeInBytes,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnGetDropoutDescriptor(cudnnDropoutDescriptor_t dropoutDesc,
                                        cudnnHandle_t handle, float *dropout,
                                        void **states,
                                        unsigned long long *seed) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&dropoutDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)dropout, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)states, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)seed, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnGetDropoutDescriptor) < 0 ||
      rpc_write(conn, &dropoutDesc, sizeof(cudnnDropoutDescriptor_t)) < 0 ||
      rpc_write(conn, &handle, sizeof(cudnnHandle_t)) < 0 ||
      rpc_write(conn, dropout, sizeof(float)) < 0 ||
      rpc_write(conn, states, sizeof(void *)) < 0 ||
      rpc_write(conn, seed, sizeof(unsigned long long)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, dropout, sizeof(float)) < 0 ||
      rpc_read(conn, states, sizeof(void *)) < 0 ||
      rpc_read(conn, seed, sizeof(unsigned long long)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&dropoutDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)dropout, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)states, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)seed, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnOpsVersionCheck() {
  conn_t *conn = rpc_client_get_connection(0);
  cudnnStatus_t return_value;
  if (rpc_write_start_request(conn, RPC_cudnnOpsVersionCheck) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnGetBatchNormalizationForwardTrainingExWorkspaceSize(
    cudnnHandle_t handle, cudnnBatchNormMode_t mode, cudnnBatchNormOps_t bnOps,
    const cudnnTensorDescriptor_t xDesc, const cudnnTensorDescriptor_t zDesc,
    const cudnnTensorDescriptor_t yDesc,
    const cudnnTensorDescriptor_t bnScaleBiasMeanVarDesc,
    const cudnnActivationDescriptor_t activationDesc, size_t *sizeInBytes) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&bnOps, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&xDesc, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&zDesc, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&yDesc, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&bnScaleBiasMeanVarDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&activationDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)sizeInBytes,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(
          conn, RPC_cudnnGetBatchNormalizationForwardTrainingExWorkspaceSize) <
          0 ||
      rpc_write(conn, &handle, sizeof(cudnnHandle_t)) < 0 ||
      rpc_write(conn, &mode, sizeof(cudnnBatchNormMode_t)) < 0 ||
      rpc_write(conn, &bnOps, sizeof(cudnnBatchNormOps_t)) < 0 ||
      rpc_write(conn, &xDesc, sizeof(const cudnnTensorDescriptor_t)) < 0 ||
      rpc_write(conn, &zDesc, sizeof(const cudnnTensorDescriptor_t)) < 0 ||
      rpc_write(conn, &yDesc, sizeof(const cudnnTensorDescriptor_t)) < 0 ||
      rpc_write(conn, &bnScaleBiasMeanVarDesc,
                sizeof(const cudnnTensorDescriptor_t)) < 0 ||
      rpc_write(conn, &activationDesc,
                sizeof(const cudnnActivationDescriptor_t)) < 0 ||
      rpc_write(conn, sizeInBytes, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, sizeInBytes, sizeof(size_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&bnOps, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&xDesc, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&zDesc, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&yDesc, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&bnScaleBiasMeanVarDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&activationDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)sizeInBytes,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnGetBatchNormalizationBackwardExWorkspaceSize(
    cudnnHandle_t handle, cudnnBatchNormMode_t mode, cudnnBatchNormOps_t bnOps,
    const cudnnTensorDescriptor_t xDesc, const cudnnTensorDescriptor_t yDesc,
    const cudnnTensorDescriptor_t dyDesc, const cudnnTensorDescriptor_t dzDesc,
    const cudnnTensorDescriptor_t dxDesc,
    const cudnnTensorDescriptor_t dBnScaleBiasDesc,
    const cudnnActivationDescriptor_t activationDesc, size_t *sizeInBytes) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&bnOps, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&xDesc, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&yDesc, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&dyDesc, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&dzDesc, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&dxDesc, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&dBnScaleBiasDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&activationDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)sizeInBytes,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(
          conn, RPC_cudnnGetBatchNormalizationBackwardExWorkspaceSize) < 0 ||
      rpc_write(conn, &handle, sizeof(cudnnHandle_t)) < 0 ||
      rpc_write(conn, &mode, sizeof(cudnnBatchNormMode_t)) < 0 ||
      rpc_write(conn, &bnOps, sizeof(cudnnBatchNormOps_t)) < 0 ||
      rpc_write(conn, &xDesc, sizeof(const cudnnTensorDescriptor_t)) < 0 ||
      rpc_write(conn, &yDesc, sizeof(const cudnnTensorDescriptor_t)) < 0 ||
      rpc_write(conn, &dyDesc, sizeof(const cudnnTensorDescriptor_t)) < 0 ||
      rpc_write(conn, &dzDesc, sizeof(const cudnnTensorDescriptor_t)) < 0 ||
      rpc_write(conn, &dxDesc, sizeof(const cudnnTensorDescriptor_t)) < 0 ||
      rpc_write(conn, &dBnScaleBiasDesc,
                sizeof(const cudnnTensorDescriptor_t)) < 0 ||
      rpc_write(conn, &activationDesc,
                sizeof(const cudnnActivationDescriptor_t)) < 0 ||
      rpc_write(conn, sizeInBytes, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, sizeInBytes, sizeof(size_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&bnOps, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&xDesc, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&yDesc, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&dyDesc, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&dzDesc, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&dxDesc, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&dBnScaleBiasDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&activationDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)sizeInBytes,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnGetBatchNormalizationTrainingExReserveSpaceSize(
    cudnnHandle_t handle, cudnnBatchNormMode_t mode, cudnnBatchNormOps_t bnOps,
    const cudnnActivationDescriptor_t activationDesc,
    const cudnnTensorDescriptor_t xDesc, size_t *sizeInBytes) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&bnOps, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&activationDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&xDesc, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)sizeInBytes,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(
          conn, RPC_cudnnGetBatchNormalizationTrainingExReserveSpaceSize) < 0 ||
      rpc_write(conn, &handle, sizeof(cudnnHandle_t)) < 0 ||
      rpc_write(conn, &mode, sizeof(cudnnBatchNormMode_t)) < 0 ||
      rpc_write(conn, &bnOps, sizeof(cudnnBatchNormOps_t)) < 0 ||
      rpc_write(conn, &activationDesc,
                sizeof(const cudnnActivationDescriptor_t)) < 0 ||
      rpc_write(conn, &xDesc, sizeof(const cudnnTensorDescriptor_t)) < 0 ||
      rpc_write(conn, sizeInBytes, sizeof(size_t)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, sizeInBytes, sizeof(size_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&bnOps, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&activationDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&xDesc, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)sizeInBytes,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnGetNormalizationForwardTrainingWorkspaceSize(
    cudnnHandle_t handle, cudnnNormMode_t mode, cudnnNormOps_t normOps,
    cudnnNormAlgo_t algo, const cudnnTensorDescriptor_t xDesc,
    const cudnnTensorDescriptor_t zDesc, const cudnnTensorDescriptor_t yDesc,
    const cudnnTensorDescriptor_t normScaleBiasDesc,
    const cudnnActivationDescriptor_t activationDesc,
    const cudnnTensorDescriptor_t normMeanVarDesc, size_t *sizeInBytes,
    int groupCnt) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&normOps, cudaMemcpyHostToDevice) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&algo, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&xDesc, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&zDesc, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&yDesc, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&normScaleBiasDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&activationDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&normMeanVarDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)sizeInBytes,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&groupCnt, cudaMemcpyHostToDevice) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(
          conn, RPC_cudnnGetNormalizationForwardTrainingWorkspaceSize) < 0 ||
      rpc_write(conn, &handle, sizeof(cudnnHandle_t)) < 0 ||
      rpc_write(conn, &mode, sizeof(cudnnNormMode_t)) < 0 ||
      rpc_write(conn, &normOps, sizeof(cudnnNormOps_t)) < 0 ||
      rpc_write(conn, &algo, sizeof(cudnnNormAlgo_t)) < 0 ||
      rpc_write(conn, &xDesc, sizeof(const cudnnTensorDescriptor_t)) < 0 ||
      rpc_write(conn, &zDesc, sizeof(const cudnnTensorDescriptor_t)) < 0 ||
      rpc_write(conn, &yDesc, sizeof(const cudnnTensorDescriptor_t)) < 0 ||
      rpc_write(conn, &normScaleBiasDesc,
                sizeof(const cudnnTensorDescriptor_t)) < 0 ||
      rpc_write(conn, &activationDesc,
                sizeof(const cudnnActivationDescriptor_t)) < 0 ||
      rpc_write(conn, &normMeanVarDesc, sizeof(const cudnnTensorDescriptor_t)) <
          0 ||
      rpc_write(conn, sizeInBytes, sizeof(size_t)) < 0 ||
      rpc_write(conn, &groupCnt, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, sizeInBytes, sizeof(size_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&normOps, cudaMemcpyDeviceToHost) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&algo, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&xDesc, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&zDesc, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&yDesc, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&normScaleBiasDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&activationDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&normMeanVarDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)sizeInBytes,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&groupCnt, cudaMemcpyDeviceToHost) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnGetNormalizationBackwardWorkspaceSize(
    cudnnHandle_t handle, cudnnNormMode_t mode, cudnnNormOps_t normOps,
    cudnnNormAlgo_t algo, const cudnnTensorDescriptor_t xDesc,
    const cudnnTensorDescriptor_t yDesc, const cudnnTensorDescriptor_t dyDesc,
    const cudnnTensorDescriptor_t dzDesc, const cudnnTensorDescriptor_t dxDesc,
    const cudnnTensorDescriptor_t dNormScaleBiasDesc,
    const cudnnActivationDescriptor_t activationDesc,
    const cudnnTensorDescriptor_t normMeanVarDesc, size_t *sizeInBytes,
    int groupCnt) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&normOps, cudaMemcpyHostToDevice) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&algo, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&xDesc, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&yDesc, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&dyDesc, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&dzDesc, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&dxDesc, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&dNormScaleBiasDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&activationDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&normMeanVarDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)sizeInBytes,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&groupCnt, cudaMemcpyHostToDevice) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(
          conn, RPC_cudnnGetNormalizationBackwardWorkspaceSize) < 0 ||
      rpc_write(conn, &handle, sizeof(cudnnHandle_t)) < 0 ||
      rpc_write(conn, &mode, sizeof(cudnnNormMode_t)) < 0 ||
      rpc_write(conn, &normOps, sizeof(cudnnNormOps_t)) < 0 ||
      rpc_write(conn, &algo, sizeof(cudnnNormAlgo_t)) < 0 ||
      rpc_write(conn, &xDesc, sizeof(const cudnnTensorDescriptor_t)) < 0 ||
      rpc_write(conn, &yDesc, sizeof(const cudnnTensorDescriptor_t)) < 0 ||
      rpc_write(conn, &dyDesc, sizeof(const cudnnTensorDescriptor_t)) < 0 ||
      rpc_write(conn, &dzDesc, sizeof(const cudnnTensorDescriptor_t)) < 0 ||
      rpc_write(conn, &dxDesc, sizeof(const cudnnTensorDescriptor_t)) < 0 ||
      rpc_write(conn, &dNormScaleBiasDesc,
                sizeof(const cudnnTensorDescriptor_t)) < 0 ||
      rpc_write(conn, &activationDesc,
                sizeof(const cudnnActivationDescriptor_t)) < 0 ||
      rpc_write(conn, &normMeanVarDesc, sizeof(const cudnnTensorDescriptor_t)) <
          0 ||
      rpc_write(conn, sizeInBytes, sizeof(size_t)) < 0 ||
      rpc_write(conn, &groupCnt, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, sizeInBytes, sizeof(size_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&normOps, cudaMemcpyDeviceToHost) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&algo, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&xDesc, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&yDesc, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&dyDesc, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&dzDesc, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&dxDesc, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&dNormScaleBiasDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&activationDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&normMeanVarDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)sizeInBytes,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&groupCnt, cudaMemcpyDeviceToHost) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

cudnnStatus_t cudnnGetNormalizationTrainingReserveSpaceSize(
    cudnnHandle_t handle, cudnnNormMode_t mode, cudnnNormOps_t normOps,
    cudnnNormAlgo_t algo, const cudnnActivationDescriptor_t activationDesc,
    const cudnnTensorDescriptor_t xDesc, size_t *sizeInBytes, int groupCnt) {
  conn_t *conn = rpc_client_get_connection(0);
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&normOps, cudaMemcpyHostToDevice) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&algo, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&activationDesc,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&xDesc, cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)sizeInBytes,
                             cudaMemcpyHostToDevice) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&groupCnt, cudaMemcpyHostToDevice) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  cudnnStatus_t return_value;
  if (rpc_write_start_request(
          conn, RPC_cudnnGetNormalizationTrainingReserveSpaceSize) < 0 ||
      rpc_write(conn, &handle, sizeof(cudnnHandle_t)) < 0 ||
      rpc_write(conn, &mode, sizeof(cudnnNormMode_t)) < 0 ||
      rpc_write(conn, &normOps, sizeof(cudnnNormOps_t)) < 0 ||
      rpc_write(conn, &algo, sizeof(cudnnNormAlgo_t)) < 0 ||
      rpc_write(conn, &activationDesc,
                sizeof(const cudnnActivationDescriptor_t)) < 0 ||
      rpc_write(conn, &xDesc, sizeof(const cudnnTensorDescriptor_t)) < 0 ||
      rpc_write(conn, sizeInBytes, sizeof(size_t)) < 0 ||
      rpc_write(conn, &groupCnt, sizeof(int)) < 0 ||
      rpc_wait_for_response(conn) < 0 ||
      rpc_read(conn, sizeInBytes, sizeof(size_t)) < 0 ||
      rpc_read(conn, &return_value, sizeof(cudnnStatus_t)) < 0 ||
      rpc_read_end(conn) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&handle, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&mode, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&normOps, cudaMemcpyDeviceToHost) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&algo, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&activationDesc,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&xDesc, cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)sizeInBytes,
                             cudaMemcpyDeviceToHost) < 0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  if (maybe_copy_unified_arg(conn, (void *)&groupCnt, cudaMemcpyDeviceToHost) <
      0)
    return CUDNN_STATUS_NOT_INITIALIZED;
  return return_value;
}

std::unordered_map<std::string, void *> functionMap = {
    {"__cudaRegisterVar", (void *)__cudaRegisterVar},
    {"__cudaRegisterFunction", (void *)__cudaRegisterFunction},
    {"__cudaRegisterFatBinary", (void *)__cudaRegisterFatBinary},
    {"__cudaRegisterFatBinaryEnd", (void *)__cudaRegisterFatBinaryEnd},
    {"__cudaPushCallConfiguration", (void *)__cudaPushCallConfiguration},
    {"__cudaPopCallConfiguration", (void *)__cudaPopCallConfiguration},
    {"nvmlInit", (void *)nvmlInit_v2},
    {"nvmlInit_v2", (void *)nvmlInit_v2},
    {"nvmlInitWithFlags", (void *)nvmlInitWithFlags},
    {"nvmlShutdown", (void *)nvmlShutdown},
    {"nvmlSystemGetDriverVersion", (void *)nvmlSystemGetDriverVersion},
    {"nvmlSystemGetNVMLVersion", (void *)nvmlSystemGetNVMLVersion},
    {"nvmlSystemGetCudaDriverVersion", (void *)nvmlSystemGetCudaDriverVersion},
    {"nvmlSystemGetCudaDriverVersion_v2",
     (void *)nvmlSystemGetCudaDriverVersion_v2},
    {"nvmlSystemGetProcessName", (void *)nvmlSystemGetProcessName},
    {"nvmlUnitGetCount", (void *)nvmlUnitGetCount},
    {"nvmlUnitGetHandleByIndex", (void *)nvmlUnitGetHandleByIndex},
    {"nvmlUnitGetUnitInfo", (void *)nvmlUnitGetUnitInfo},
    {"nvmlUnitGetLedState", (void *)nvmlUnitGetLedState},
    {"nvmlUnitGetPsuInfo", (void *)nvmlUnitGetPsuInfo},
    {"nvmlUnitGetTemperature", (void *)nvmlUnitGetTemperature},
    {"nvmlUnitGetFanSpeedInfo", (void *)nvmlUnitGetFanSpeedInfo},
    {"nvmlUnitGetDevices", (void *)nvmlUnitGetDevices},
    {"nvmlSystemGetHicVersion", (void *)nvmlSystemGetHicVersion},
    {"nvmlDeviceGetCount_v2", (void *)nvmlDeviceGetCount_v2},
    {"nvmlDeviceGetAttributes_v2", (void *)nvmlDeviceGetAttributes_v2},
    {"nvmlDeviceGetHandleByIndex_v2", (void *)nvmlDeviceGetHandleByIndex_v2},
    {"nvmlDeviceGetHandleBySerial", (void *)nvmlDeviceGetHandleBySerial},
    {"nvmlDeviceGetHandleByUUID", (void *)nvmlDeviceGetHandleByUUID},
    {"nvmlDeviceGetHandleByPciBusId_v2",
     (void *)nvmlDeviceGetHandleByPciBusId_v2},
    {"nvmlDeviceGetName", (void *)nvmlDeviceGetName},
    {"nvmlDeviceGetBrand", (void *)nvmlDeviceGetBrand},
    {"nvmlDeviceGetIndex", (void *)nvmlDeviceGetIndex},
    {"nvmlDeviceGetSerial", (void *)nvmlDeviceGetSerial},
    {"nvmlDeviceGetMemoryAffinity", (void *)nvmlDeviceGetMemoryAffinity},
    {"nvmlDeviceGetCpuAffinityWithinScope",
     (void *)nvmlDeviceGetCpuAffinityWithinScope},
    {"nvmlDeviceGetCpuAffinity", (void *)nvmlDeviceGetCpuAffinity},
    {"nvmlDeviceSetCpuAffinity", (void *)nvmlDeviceSetCpuAffinity},
    {"nvmlDeviceClearCpuAffinity", (void *)nvmlDeviceClearCpuAffinity},
    {"nvmlDeviceGetTopologyCommonAncestor",
     (void *)nvmlDeviceGetTopologyCommonAncestor},
    {"nvmlDeviceGetTopologyNearestGpus",
     (void *)nvmlDeviceGetTopologyNearestGpus},
    {"nvmlSystemGetTopologyGpuSet", (void *)nvmlSystemGetTopologyGpuSet},
    {"nvmlDeviceGetP2PStatus", (void *)nvmlDeviceGetP2PStatus},
    {"nvmlDeviceGetUUID", (void *)nvmlDeviceGetUUID},
    {"nvmlVgpuInstanceGetMdevUUID", (void *)nvmlVgpuInstanceGetMdevUUID},
    {"nvmlDeviceGetMinorNumber", (void *)nvmlDeviceGetMinorNumber},
    {"nvmlDeviceGetBoardPartNumber", (void *)nvmlDeviceGetBoardPartNumber},
    {"nvmlDeviceGetInforomVersion", (void *)nvmlDeviceGetInforomVersion},
    {"nvmlDeviceGetInforomImageVersion",
     (void *)nvmlDeviceGetInforomImageVersion},
    {"nvmlDeviceGetInforomConfigurationChecksum",
     (void *)nvmlDeviceGetInforomConfigurationChecksum},
    {"nvmlDeviceValidateInforom", (void *)nvmlDeviceValidateInforom},
    {"nvmlDeviceGetDisplayMode", (void *)nvmlDeviceGetDisplayMode},
    {"nvmlDeviceGetDisplayActive", (void *)nvmlDeviceGetDisplayActive},
    {"nvmlDeviceGetPersistenceMode", (void *)nvmlDeviceGetPersistenceMode},
    {"nvmlDeviceGetPciInfo_v3", (void *)nvmlDeviceGetPciInfo_v3},
    {"nvmlDeviceGetMaxPcieLinkGeneration",
     (void *)nvmlDeviceGetMaxPcieLinkGeneration},
    {"nvmlDeviceGetGpuMaxPcieLinkGeneration",
     (void *)nvmlDeviceGetGpuMaxPcieLinkGeneration},
    {"nvmlDeviceGetMaxPcieLinkWidth", (void *)nvmlDeviceGetMaxPcieLinkWidth},
    {"nvmlDeviceGetCurrPcieLinkGeneration",
     (void *)nvmlDeviceGetCurrPcieLinkGeneration},
    {"nvmlDeviceGetCurrPcieLinkWidth", (void *)nvmlDeviceGetCurrPcieLinkWidth},
    {"nvmlDeviceGetPcieThroughput", (void *)nvmlDeviceGetPcieThroughput},
    {"nvmlDeviceGetPcieReplayCounter", (void *)nvmlDeviceGetPcieReplayCounter},
    {"nvmlDeviceGetClockInfo", (void *)nvmlDeviceGetClockInfo},
    {"nvmlDeviceGetMaxClockInfo", (void *)nvmlDeviceGetMaxClockInfo},
    {"nvmlDeviceGetApplicationsClock", (void *)nvmlDeviceGetApplicationsClock},
    {"nvmlDeviceGetDefaultApplicationsClock",
     (void *)nvmlDeviceGetDefaultApplicationsClock},
    {"nvmlDeviceResetApplicationsClocks",
     (void *)nvmlDeviceResetApplicationsClocks},
    {"nvmlDeviceGetClock", (void *)nvmlDeviceGetClock},
    {"nvmlDeviceGetMaxCustomerBoostClock",
     (void *)nvmlDeviceGetMaxCustomerBoostClock},
    {"nvmlDeviceGetSupportedMemoryClocks",
     (void *)nvmlDeviceGetSupportedMemoryClocks},
    {"nvmlDeviceGetSupportedGraphicsClocks",
     (void *)nvmlDeviceGetSupportedGraphicsClocks},
    {"nvmlDeviceGetAutoBoostedClocksEnabled",
     (void *)nvmlDeviceGetAutoBoostedClocksEnabled},
    {"nvmlDeviceSetAutoBoostedClocksEnabled",
     (void *)nvmlDeviceSetAutoBoostedClocksEnabled},
    {"nvmlDeviceSetDefaultAutoBoostedClocksEnabled",
     (void *)nvmlDeviceSetDefaultAutoBoostedClocksEnabled},
    {"nvmlDeviceGetFanSpeed", (void *)nvmlDeviceGetFanSpeed},
    {"nvmlDeviceGetFanSpeed_v2", (void *)nvmlDeviceGetFanSpeed_v2},
    {"nvmlDeviceGetTargetFanSpeed", (void *)nvmlDeviceGetTargetFanSpeed},
    {"nvmlDeviceSetDefaultFanSpeed_v2",
     (void *)nvmlDeviceSetDefaultFanSpeed_v2},
    {"nvmlDeviceGetMinMaxFanSpeed", (void *)nvmlDeviceGetMinMaxFanSpeed},
    {"nvmlDeviceGetFanControlPolicy_v2",
     (void *)nvmlDeviceGetFanControlPolicy_v2},
    {"nvmlDeviceSetFanControlPolicy", (void *)nvmlDeviceSetFanControlPolicy},
    {"nvmlDeviceGetNumFans", (void *)nvmlDeviceGetNumFans},
    {"nvmlDeviceGetTemperature", (void *)nvmlDeviceGetTemperature},
    {"nvmlDeviceGetTemperatureThreshold",
     (void *)nvmlDeviceGetTemperatureThreshold},
    {"nvmlDeviceSetTemperatureThreshold",
     (void *)nvmlDeviceSetTemperatureThreshold},
    {"nvmlDeviceGetThermalSettings", (void *)nvmlDeviceGetThermalSettings},
    {"nvmlDeviceGetPerformanceState", (void *)nvmlDeviceGetPerformanceState},
    {"nvmlDeviceGetCurrentClocksThrottleReasons",
     (void *)nvmlDeviceGetCurrentClocksThrottleReasons},
    {"nvmlDeviceGetSupportedClocksThrottleReasons",
     (void *)nvmlDeviceGetSupportedClocksThrottleReasons},
    {"nvmlDeviceGetPowerState", (void *)nvmlDeviceGetPowerState},
    {"nvmlDeviceGetPowerManagementMode",
     (void *)nvmlDeviceGetPowerManagementMode},
    {"nvmlDeviceGetPowerManagementLimit",
     (void *)nvmlDeviceGetPowerManagementLimit},
    {"nvmlDeviceGetPowerManagementLimitConstraints",
     (void *)nvmlDeviceGetPowerManagementLimitConstraints},
    {"nvmlDeviceGetPowerManagementDefaultLimit",
     (void *)nvmlDeviceGetPowerManagementDefaultLimit},
    {"nvmlDeviceGetPowerUsage", (void *)nvmlDeviceGetPowerUsage},
    {"nvmlDeviceGetTotalEnergyConsumption",
     (void *)nvmlDeviceGetTotalEnergyConsumption},
    {"nvmlDeviceGetEnforcedPowerLimit",
     (void *)nvmlDeviceGetEnforcedPowerLimit},
    {"nvmlDeviceGetGpuOperationMode", (void *)nvmlDeviceGetGpuOperationMode},
    {"nvmlDeviceGetMemoryInfo", (void *)nvmlDeviceGetMemoryInfo},
    {"nvmlDeviceGetMemoryInfo_v2", (void *)nvmlDeviceGetMemoryInfo_v2},
    {"nvmlDeviceGetComputeMode", (void *)nvmlDeviceGetComputeMode},
    {"nvmlDeviceGetCudaComputeCapability",
     (void *)nvmlDeviceGetCudaComputeCapability},
    {"nvmlDeviceGetEccMode", (void *)nvmlDeviceGetEccMode},
    {"nvmlDeviceGetDefaultEccMode", (void *)nvmlDeviceGetDefaultEccMode},
    {"nvmlDeviceGetBoardId", (void *)nvmlDeviceGetBoardId},
    {"nvmlDeviceGetMultiGpuBoard", (void *)nvmlDeviceGetMultiGpuBoard},
    {"nvmlDeviceGetTotalEccErrors", (void *)nvmlDeviceGetTotalEccErrors},
    {"nvmlDeviceGetDetailedEccErrors", (void *)nvmlDeviceGetDetailedEccErrors},
    {"nvmlDeviceGetMemoryErrorCounter",
     (void *)nvmlDeviceGetMemoryErrorCounter},
    {"nvmlDeviceGetUtilizationRates", (void *)nvmlDeviceGetUtilizationRates},
    {"nvmlDeviceGetEncoderUtilization",
     (void *)nvmlDeviceGetEncoderUtilization},
    {"nvmlDeviceGetEncoderCapacity", (void *)nvmlDeviceGetEncoderCapacity},
    {"nvmlDeviceGetEncoderStats", (void *)nvmlDeviceGetEncoderStats},
    {"nvmlDeviceGetEncoderSessions", (void *)nvmlDeviceGetEncoderSessions},
    {"nvmlDeviceGetDecoderUtilization",
     (void *)nvmlDeviceGetDecoderUtilization},
    {"nvmlDeviceGetFBCStats", (void *)nvmlDeviceGetFBCStats},
    {"nvmlDeviceGetFBCSessions", (void *)nvmlDeviceGetFBCSessions},
    {"nvmlDeviceGetVbiosVersion", (void *)nvmlDeviceGetVbiosVersion},
    {"nvmlDeviceGetBridgeChipInfo", (void *)nvmlDeviceGetBridgeChipInfo},
    {"nvmlDeviceGetComputeRunningProcesses_v3",
     (void *)nvmlDeviceGetComputeRunningProcesses_v3},
    {"nvmlDeviceGetGraphicsRunningProcesses_v3",
     (void *)nvmlDeviceGetGraphicsRunningProcesses_v3},
    {"nvmlDeviceGetMPSComputeRunningProcesses_v3",
     (void *)nvmlDeviceGetMPSComputeRunningProcesses_v3},
    {"nvmlDeviceOnSameBoard", (void *)nvmlDeviceOnSameBoard},
    {"nvmlDeviceGetAPIRestriction", (void *)nvmlDeviceGetAPIRestriction},
    {"nvmlDeviceGetSamples", (void *)nvmlDeviceGetSamples},
    {"nvmlDeviceGetBAR1MemoryInfo", (void *)nvmlDeviceGetBAR1MemoryInfo},
    {"nvmlDeviceGetViolationStatus", (void *)nvmlDeviceGetViolationStatus},
    {"nvmlDeviceGetIrqNum", (void *)nvmlDeviceGetIrqNum},
    {"nvmlDeviceGetNumGpuCores", (void *)nvmlDeviceGetNumGpuCores},
    {"nvmlDeviceGetPowerSource", (void *)nvmlDeviceGetPowerSource},
    {"nvmlDeviceGetMemoryBusWidth", (void *)nvmlDeviceGetMemoryBusWidth},
    {"nvmlDeviceGetPcieLinkMaxSpeed", (void *)nvmlDeviceGetPcieLinkMaxSpeed},
    {"nvmlDeviceGetPcieSpeed", (void *)nvmlDeviceGetPcieSpeed},
    {"nvmlDeviceGetAdaptiveClockInfoStatus",
     (void *)nvmlDeviceGetAdaptiveClockInfoStatus},
    {"nvmlDeviceGetAccountingMode", (void *)nvmlDeviceGetAccountingMode},
    {"nvmlDeviceGetAccountingStats", (void *)nvmlDeviceGetAccountingStats},
    {"nvmlDeviceGetAccountingPids", (void *)nvmlDeviceGetAccountingPids},
    {"nvmlDeviceGetAccountingBufferSize",
     (void *)nvmlDeviceGetAccountingBufferSize},
    {"nvmlDeviceGetRetiredPages", (void *)nvmlDeviceGetRetiredPages},
    {"nvmlDeviceGetRetiredPages_v2", (void *)nvmlDeviceGetRetiredPages_v2},
    {"nvmlDeviceGetRetiredPagesPendingStatus",
     (void *)nvmlDeviceGetRetiredPagesPendingStatus},
    {"nvmlDeviceGetRemappedRows", (void *)nvmlDeviceGetRemappedRows},
    {"nvmlDeviceGetRowRemapperHistogram",
     (void *)nvmlDeviceGetRowRemapperHistogram},
    {"nvmlDeviceGetArchitecture", (void *)nvmlDeviceGetArchitecture},
    {"nvmlUnitSetLedState", (void *)nvmlUnitSetLedState},
    {"nvmlDeviceSetPersistenceMode", (void *)nvmlDeviceSetPersistenceMode},
    {"nvmlDeviceSetComputeMode", (void *)nvmlDeviceSetComputeMode},
    {"nvmlDeviceSetEccMode", (void *)nvmlDeviceSetEccMode},
    {"nvmlDeviceClearEccErrorCounts", (void *)nvmlDeviceClearEccErrorCounts},
    {"nvmlDeviceSetDriverModel", (void *)nvmlDeviceSetDriverModel},
    {"nvmlDeviceSetGpuLockedClocks", (void *)nvmlDeviceSetGpuLockedClocks},
    {"nvmlDeviceResetGpuLockedClocks", (void *)nvmlDeviceResetGpuLockedClocks},
    {"nvmlDeviceSetMemoryLockedClocks",
     (void *)nvmlDeviceSetMemoryLockedClocks},
    {"nvmlDeviceResetMemoryLockedClocks",
     (void *)nvmlDeviceResetMemoryLockedClocks},
    {"nvmlDeviceSetApplicationsClocks",
     (void *)nvmlDeviceSetApplicationsClocks},
    {"nvmlDeviceGetClkMonStatus", (void *)nvmlDeviceGetClkMonStatus},
    {"nvmlDeviceSetPowerManagementLimit",
     (void *)nvmlDeviceSetPowerManagementLimit},
    {"nvmlDeviceSetGpuOperationMode", (void *)nvmlDeviceSetGpuOperationMode},
    {"nvmlDeviceSetAPIRestriction", (void *)nvmlDeviceSetAPIRestriction},
    {"nvmlDeviceSetAccountingMode", (void *)nvmlDeviceSetAccountingMode},
    {"nvmlDeviceClearAccountingPids", (void *)nvmlDeviceClearAccountingPids},
    {"nvmlDeviceGetNvLinkState", (void *)nvmlDeviceGetNvLinkState},
    {"nvmlDeviceGetNvLinkVersion", (void *)nvmlDeviceGetNvLinkVersion},
    {"nvmlDeviceGetNvLinkCapability", (void *)nvmlDeviceGetNvLinkCapability},
    {"nvmlDeviceGetNvLinkRemotePciInfo_v2",
     (void *)nvmlDeviceGetNvLinkRemotePciInfo_v2},
    {"nvmlDeviceGetNvLinkErrorCounter",
     (void *)nvmlDeviceGetNvLinkErrorCounter},
    {"nvmlDeviceResetNvLinkErrorCounters",
     (void *)nvmlDeviceResetNvLinkErrorCounters},
    {"nvmlDeviceSetNvLinkUtilizationControl",
     (void *)nvmlDeviceSetNvLinkUtilizationControl},
    {"nvmlDeviceGetNvLinkUtilizationControl",
     (void *)nvmlDeviceGetNvLinkUtilizationControl},
    {"nvmlDeviceGetNvLinkUtilizationCounter",
     (void *)nvmlDeviceGetNvLinkUtilizationCounter},
    {"nvmlDeviceFreezeNvLinkUtilizationCounter",
     (void *)nvmlDeviceFreezeNvLinkUtilizationCounter},
    {"nvmlDeviceResetNvLinkUtilizationCounter",
     (void *)nvmlDeviceResetNvLinkUtilizationCounter},
    {"nvmlDeviceGetNvLinkRemoteDeviceType",
     (void *)nvmlDeviceGetNvLinkRemoteDeviceType},
    {"nvmlEventSetCreate", (void *)nvmlEventSetCreate},
    {"nvmlDeviceRegisterEvents", (void *)nvmlDeviceRegisterEvents},
    {"nvmlDeviceGetSupportedEventTypes",
     (void *)nvmlDeviceGetSupportedEventTypes},
    {"nvmlEventSetWait_v2", (void *)nvmlEventSetWait_v2},
    {"nvmlEventSetFree", (void *)nvmlEventSetFree},
    {"nvmlDeviceModifyDrainState", (void *)nvmlDeviceModifyDrainState},
    {"nvmlDeviceQueryDrainState", (void *)nvmlDeviceQueryDrainState},
    {"nvmlDeviceRemoveGpu_v2", (void *)nvmlDeviceRemoveGpu_v2},
    {"nvmlDeviceDiscoverGpus", (void *)nvmlDeviceDiscoverGpus},
    {"nvmlDeviceGetFieldValues", (void *)nvmlDeviceGetFieldValues},
    {"nvmlDeviceClearFieldValues", (void *)nvmlDeviceClearFieldValues},
    {"nvmlDeviceGetVirtualizationMode",
     (void *)nvmlDeviceGetVirtualizationMode},
    {"nvmlDeviceGetHostVgpuMode", (void *)nvmlDeviceGetHostVgpuMode},
    {"nvmlDeviceSetVirtualizationMode",
     (void *)nvmlDeviceSetVirtualizationMode},
    {"nvmlDeviceGetGridLicensableFeatures_v4",
     (void *)nvmlDeviceGetGridLicensableFeatures_v4},
    {"nvmlDeviceGetProcessUtilization",
     (void *)nvmlDeviceGetProcessUtilization},
    {"nvmlDeviceGetGspFirmwareVersion",
     (void *)nvmlDeviceGetGspFirmwareVersion},
    {"nvmlDeviceGetGspFirmwareMode", (void *)nvmlDeviceGetGspFirmwareMode},
    {"nvmlGetVgpuDriverCapabilities", (void *)nvmlGetVgpuDriverCapabilities},
    {"nvmlDeviceGetVgpuCapabilities", (void *)nvmlDeviceGetVgpuCapabilities},
    {"nvmlDeviceGetSupportedVgpus", (void *)nvmlDeviceGetSupportedVgpus},
    {"nvmlDeviceGetCreatableVgpus", (void *)nvmlDeviceGetCreatableVgpus},
    {"nvmlVgpuTypeGetClass", (void *)nvmlVgpuTypeGetClass},
    {"nvmlVgpuTypeGetName", (void *)nvmlVgpuTypeGetName},
    {"nvmlVgpuTypeGetGpuInstanceProfileId",
     (void *)nvmlVgpuTypeGetGpuInstanceProfileId},
    {"nvmlVgpuTypeGetDeviceID", (void *)nvmlVgpuTypeGetDeviceID},
    {"nvmlVgpuTypeGetFramebufferSize", (void *)nvmlVgpuTypeGetFramebufferSize},
    {"nvmlVgpuTypeGetNumDisplayHeads", (void *)nvmlVgpuTypeGetNumDisplayHeads},
    {"nvmlVgpuTypeGetResolution", (void *)nvmlVgpuTypeGetResolution},
    {"nvmlVgpuTypeGetLicense", (void *)nvmlVgpuTypeGetLicense},
    {"nvmlVgpuTypeGetFrameRateLimit", (void *)nvmlVgpuTypeGetFrameRateLimit},
    {"nvmlVgpuTypeGetMaxInstances", (void *)nvmlVgpuTypeGetMaxInstances},
    {"nvmlVgpuTypeGetMaxInstancesPerVm",
     (void *)nvmlVgpuTypeGetMaxInstancesPerVm},
    {"nvmlDeviceGetActiveVgpus", (void *)nvmlDeviceGetActiveVgpus},
    {"nvmlVgpuInstanceGetVmID", (void *)nvmlVgpuInstanceGetVmID},
    {"nvmlVgpuInstanceGetUUID", (void *)nvmlVgpuInstanceGetUUID},
    {"nvmlVgpuInstanceGetVmDriverVersion",
     (void *)nvmlVgpuInstanceGetVmDriverVersion},
    {"nvmlVgpuInstanceGetFbUsage", (void *)nvmlVgpuInstanceGetFbUsage},
    {"nvmlVgpuInstanceGetLicenseStatus",
     (void *)nvmlVgpuInstanceGetLicenseStatus},
    {"nvmlVgpuInstanceGetType", (void *)nvmlVgpuInstanceGetType},
    {"nvmlVgpuInstanceGetFrameRateLimit",
     (void *)nvmlVgpuInstanceGetFrameRateLimit},
    {"nvmlVgpuInstanceGetEccMode", (void *)nvmlVgpuInstanceGetEccMode},
    {"nvmlVgpuInstanceGetEncoderCapacity",
     (void *)nvmlVgpuInstanceGetEncoderCapacity},
    {"nvmlVgpuInstanceSetEncoderCapacity",
     (void *)nvmlVgpuInstanceSetEncoderCapacity},
    {"nvmlVgpuInstanceGetEncoderStats",
     (void *)nvmlVgpuInstanceGetEncoderStats},
    {"nvmlVgpuInstanceGetEncoderSessions",
     (void *)nvmlVgpuInstanceGetEncoderSessions},
    {"nvmlVgpuInstanceGetFBCStats", (void *)nvmlVgpuInstanceGetFBCStats},
    {"nvmlVgpuInstanceGetFBCSessions", (void *)nvmlVgpuInstanceGetFBCSessions},
    {"nvmlVgpuInstanceGetGpuInstanceId",
     (void *)nvmlVgpuInstanceGetGpuInstanceId},
    {"nvmlVgpuInstanceGetGpuPciId", (void *)nvmlVgpuInstanceGetGpuPciId},
    {"nvmlVgpuTypeGetCapabilities", (void *)nvmlVgpuTypeGetCapabilities},
    {"nvmlVgpuInstanceGetMetadata", (void *)nvmlVgpuInstanceGetMetadata},
    {"nvmlDeviceGetVgpuMetadata", (void *)nvmlDeviceGetVgpuMetadata},
    {"nvmlGetVgpuCompatibility", (void *)nvmlGetVgpuCompatibility},
    {"nvmlDeviceGetPgpuMetadataString",
     (void *)nvmlDeviceGetPgpuMetadataString},
    {"nvmlDeviceGetVgpuSchedulerLog", (void *)nvmlDeviceGetVgpuSchedulerLog},
    {"nvmlDeviceGetVgpuSchedulerState",
     (void *)nvmlDeviceGetVgpuSchedulerState},
    {"nvmlDeviceGetVgpuSchedulerCapabilities",
     (void *)nvmlDeviceGetVgpuSchedulerCapabilities},
    {"nvmlGetVgpuVersion", (void *)nvmlGetVgpuVersion},
    {"nvmlSetVgpuVersion", (void *)nvmlSetVgpuVersion},
    {"nvmlDeviceGetVgpuUtilization", (void *)nvmlDeviceGetVgpuUtilization},
    {"nvmlDeviceGetVgpuProcessUtilization",
     (void *)nvmlDeviceGetVgpuProcessUtilization},
    {"nvmlVgpuInstanceGetAccountingMode",
     (void *)nvmlVgpuInstanceGetAccountingMode},
    {"nvmlVgpuInstanceGetAccountingPids",
     (void *)nvmlVgpuInstanceGetAccountingPids},
    {"nvmlVgpuInstanceGetAccountingStats",
     (void *)nvmlVgpuInstanceGetAccountingStats},
    {"nvmlVgpuInstanceClearAccountingPids",
     (void *)nvmlVgpuInstanceClearAccountingPids},
    {"nvmlVgpuInstanceGetLicenseInfo_v2",
     (void *)nvmlVgpuInstanceGetLicenseInfo_v2},
    {"nvmlGetExcludedDeviceCount", (void *)nvmlGetExcludedDeviceCount},
    {"nvmlGetExcludedDeviceInfoByIndex",
     (void *)nvmlGetExcludedDeviceInfoByIndex},
    {"nvmlDeviceSetMigMode", (void *)nvmlDeviceSetMigMode},
    {"nvmlDeviceGetMigMode", (void *)nvmlDeviceGetMigMode},
    {"nvmlDeviceGetGpuInstanceProfileInfo",
     (void *)nvmlDeviceGetGpuInstanceProfileInfo},
    {"nvmlDeviceGetGpuInstanceProfileInfoV",
     (void *)nvmlDeviceGetGpuInstanceProfileInfoV},
    {"nvmlDeviceGetGpuInstancePossiblePlacements_v2",
     (void *)nvmlDeviceGetGpuInstancePossiblePlacements_v2},
    {"nvmlDeviceGetGpuInstanceRemainingCapacity",
     (void *)nvmlDeviceGetGpuInstanceRemainingCapacity},
    {"nvmlDeviceCreateGpuInstance", (void *)nvmlDeviceCreateGpuInstance},
    {"nvmlGpuInstanceDestroy", (void *)nvmlGpuInstanceDestroy},
    {"nvmlDeviceGetGpuInstances", (void *)nvmlDeviceGetGpuInstances},
    {"nvmlDeviceGetGpuInstanceById", (void *)nvmlDeviceGetGpuInstanceById},
    {"nvmlGpuInstanceGetInfo", (void *)nvmlGpuInstanceGetInfo},
    {"nvmlGpuInstanceGetComputeInstanceProfileInfo",
     (void *)nvmlGpuInstanceGetComputeInstanceProfileInfo},
    {"nvmlGpuInstanceGetComputeInstanceProfileInfoV",
     (void *)nvmlGpuInstanceGetComputeInstanceProfileInfoV},
    {"nvmlGpuInstanceGetComputeInstanceRemainingCapacity",
     (void *)nvmlGpuInstanceGetComputeInstanceRemainingCapacity},
    {"nvmlGpuInstanceGetComputeInstancePossiblePlacements",
     (void *)nvmlGpuInstanceGetComputeInstancePossiblePlacements},
    {"nvmlGpuInstanceCreateComputeInstance",
     (void *)nvmlGpuInstanceCreateComputeInstance},
    {"nvmlComputeInstanceDestroy", (void *)nvmlComputeInstanceDestroy},
    {"nvmlGpuInstanceGetComputeInstances",
     (void *)nvmlGpuInstanceGetComputeInstances},
    {"nvmlGpuInstanceGetComputeInstanceById",
     (void *)nvmlGpuInstanceGetComputeInstanceById},
    {"nvmlComputeInstanceGetInfo_v2", (void *)nvmlComputeInstanceGetInfo_v2},
    {"nvmlDeviceIsMigDeviceHandle", (void *)nvmlDeviceIsMigDeviceHandle},
    {"nvmlDeviceGetGpuInstanceId", (void *)nvmlDeviceGetGpuInstanceId},
    {"nvmlDeviceGetComputeInstanceId", (void *)nvmlDeviceGetComputeInstanceId},
    {"nvmlDeviceGetMaxMigDeviceCount", (void *)nvmlDeviceGetMaxMigDeviceCount},
    {"nvmlDeviceGetMigDeviceHandleByIndex",
     (void *)nvmlDeviceGetMigDeviceHandleByIndex},
    {"nvmlDeviceGetDeviceHandleFromMigDeviceHandle",
     (void *)nvmlDeviceGetDeviceHandleFromMigDeviceHandle},
    {"nvmlDeviceGetBusType", (void *)nvmlDeviceGetBusType},
    {"nvmlDeviceGetDynamicPstatesInfo",
     (void *)nvmlDeviceGetDynamicPstatesInfo},
    {"nvmlDeviceSetFanSpeed_v2", (void *)nvmlDeviceSetFanSpeed_v2},
    {"nvmlDeviceGetGpcClkVfOffset", (void *)nvmlDeviceGetGpcClkVfOffset},
    {"nvmlDeviceSetGpcClkVfOffset", (void *)nvmlDeviceSetGpcClkVfOffset},
    {"nvmlDeviceGetMemClkVfOffset", (void *)nvmlDeviceGetMemClkVfOffset},
    {"nvmlDeviceSetMemClkVfOffset", (void *)nvmlDeviceSetMemClkVfOffset},
    {"nvmlDeviceGetMinMaxClockOfPState",
     (void *)nvmlDeviceGetMinMaxClockOfPState},
    {"nvmlDeviceGetSupportedPerformanceStates",
     (void *)nvmlDeviceGetSupportedPerformanceStates},
    {"nvmlDeviceGetGpcClkMinMaxVfOffset",
     (void *)nvmlDeviceGetGpcClkMinMaxVfOffset},
    {"nvmlDeviceGetMemClkMinMaxVfOffset",
     (void *)nvmlDeviceGetMemClkMinMaxVfOffset},
    {"nvmlDeviceGetGpuFabricInfo", (void *)nvmlDeviceGetGpuFabricInfo},
    {"nvmlGpmMetricsGet", (void *)nvmlGpmMetricsGet},
    {"nvmlGpmSampleFree", (void *)nvmlGpmSampleFree},
    {"nvmlGpmSampleAlloc", (void *)nvmlGpmSampleAlloc},
    {"nvmlGpmSampleGet", (void *)nvmlGpmSampleGet},
    {"nvmlGpmMigSampleGet", (void *)nvmlGpmMigSampleGet},
    {"nvmlGpmQueryDeviceSupport", (void *)nvmlGpmQueryDeviceSupport},
    {"nvmlDeviceSetNvLinkDeviceLowPowerThreshold",
     (void *)nvmlDeviceSetNvLinkDeviceLowPowerThreshold},
    {"cuInit", (void *)cuInit},
    {"cuDriverGetVersion", (void *)cuDriverGetVersion},
    {"cuDeviceGet", (void *)cuDeviceGet},
    {"cuDeviceGetCount", (void *)cuDeviceGetCount},
    {"cuDeviceGetName", (void *)cuDeviceGetName},
    {"cuDeviceGetUuid", (void *)cuDeviceGetUuid},
    {"cuDeviceGetUuid_v2", (void *)cuDeviceGetUuid_v2},
    {"cuDeviceGetLuid", (void *)cuDeviceGetLuid},
    {"cuDeviceTotalMem_v2", (void *)cuDeviceTotalMem_v2},
    {"cuDeviceGetTexture1DLinearMaxWidth",
     (void *)cuDeviceGetTexture1DLinearMaxWidth},
    {"cuDeviceGetAttribute", (void *)cuDeviceGetAttribute},
    {"cuDeviceSetMemPool", (void *)cuDeviceSetMemPool},
    {"cuDeviceGetMemPool", (void *)cuDeviceGetMemPool},
    {"cuDeviceGetDefaultMemPool", (void *)cuDeviceGetDefaultMemPool},
    {"cuDeviceGetExecAffinitySupport", (void *)cuDeviceGetExecAffinitySupport},
    {"cuFlushGPUDirectRDMAWrites", (void *)cuFlushGPUDirectRDMAWrites},
    {"cuDeviceGetProperties", (void *)cuDeviceGetProperties},
    {"cuDeviceComputeCapability", (void *)cuDeviceComputeCapability},
    {"cuDevicePrimaryCtxRetain", (void *)cuDevicePrimaryCtxRetain},
    {"cuDevicePrimaryCtxRelease_v2", (void *)cuDevicePrimaryCtxRelease_v2},
    {"cuDevicePrimaryCtxSetFlags_v2", (void *)cuDevicePrimaryCtxSetFlags_v2},
    {"cuDevicePrimaryCtxGetState", (void *)cuDevicePrimaryCtxGetState},
    {"cuDevicePrimaryCtxReset_v2", (void *)cuDevicePrimaryCtxReset_v2},
    {"cuCtxCreate_v2", (void *)cuCtxCreate_v2},
    {"cuCtxCreate_v3", (void *)cuCtxCreate_v3},
    {"cuCtxDestroy_v2", (void *)cuCtxDestroy_v2},
    {"cuCtxPushCurrent_v2", (void *)cuCtxPushCurrent_v2},
    {"cuCtxPopCurrent_v2", (void *)cuCtxPopCurrent_v2},
    {"cuCtxSetCurrent", (void *)cuCtxSetCurrent},
    {"cuCtxGetCurrent", (void *)cuCtxGetCurrent},
    {"cuCtxGetDevice", (void *)cuCtxGetDevice},
    {"cuCtxGetFlags", (void *)cuCtxGetFlags},
    {"cuCtxGetId", (void *)cuCtxGetId},
    {"cuCtxSynchronize", (void *)cuCtxSynchronize},
    {"cuCtxSetLimit", (void *)cuCtxSetLimit},
    {"cuCtxGetLimit", (void *)cuCtxGetLimit},
    {"cuCtxGetCacheConfig", (void *)cuCtxGetCacheConfig},
    {"cuCtxSetCacheConfig", (void *)cuCtxSetCacheConfig},
    {"cuCtxGetSharedMemConfig", (void *)cuCtxGetSharedMemConfig},
    {"cuCtxSetSharedMemConfig", (void *)cuCtxSetSharedMemConfig},
    {"cuCtxGetApiVersion", (void *)cuCtxGetApiVersion},
    {"cuCtxGetStreamPriorityRange", (void *)cuCtxGetStreamPriorityRange},
    {"cuCtxResetPersistingL2Cache", (void *)cuCtxResetPersistingL2Cache},
    {"cuCtxGetExecAffinity", (void *)cuCtxGetExecAffinity},
    {"cuCtxAttach", (void *)cuCtxAttach},
    {"cuCtxDetach", (void *)cuCtxDetach},
    {"cuModuleLoad", (void *)cuModuleLoad},
    {"cuModuleUnload", (void *)cuModuleUnload},
    {"cuModuleGetLoadingMode", (void *)cuModuleGetLoadingMode},
    {"cuModuleGetFunction", (void *)cuModuleGetFunction},
    {"cuModuleGetGlobal_v2", (void *)cuModuleGetGlobal_v2},
    {"cuLinkCreate_v2", (void *)cuLinkCreate_v2},
    {"cuLinkAddFile_v2", (void *)cuLinkAddFile_v2},
    {"cuLinkComplete", (void *)cuLinkComplete},
    {"cuLinkDestroy", (void *)cuLinkDestroy},
    {"cuModuleGetTexRef", (void *)cuModuleGetTexRef},
    {"cuModuleGetSurfRef", (void *)cuModuleGetSurfRef},
    {"cuLibraryLoadFromFile", (void *)cuLibraryLoadFromFile},
    {"cuLibraryUnload", (void *)cuLibraryUnload},
    {"cuLibraryGetKernel", (void *)cuLibraryGetKernel},
    {"cuLibraryGetModule", (void *)cuLibraryGetModule},
    {"cuKernelGetFunction", (void *)cuKernelGetFunction},
    {"cuLibraryGetGlobal", (void *)cuLibraryGetGlobal},
    {"cuLibraryGetManaged", (void *)cuLibraryGetManaged},
    {"cuLibraryGetUnifiedFunction", (void *)cuLibraryGetUnifiedFunction},
    {"cuKernelGetAttribute", (void *)cuKernelGetAttribute},
    {"cuKernelSetAttribute", (void *)cuKernelSetAttribute},
    {"cuKernelSetCacheConfig", (void *)cuKernelSetCacheConfig},
    {"cuMemGetInfo_v2", (void *)cuMemGetInfo_v2},
    {"cuMemAlloc_v2", (void *)cuMemAlloc_v2},
    {"cuMemAllocPitch_v2", (void *)cuMemAllocPitch_v2},
    {"cuMemFree_v2", (void *)cuMemFree_v2},
    {"cuMemGetAddressRange_v2", (void *)cuMemGetAddressRange_v2},
    {"cuMemAllocHost_v2", (void *)cuMemAllocHost_v2},
    {"cuMemFreeHost", (void *)cuMemFreeHost},
    {"cuMemHostAlloc", (void *)cuMemHostAlloc},
    {"cuMemHostGetDevicePointer_v2", (void *)cuMemHostGetDevicePointer_v2},
    {"cuMemHostGetFlags", (void *)cuMemHostGetFlags},
    {"cuMemAllocManaged", (void *)cuMemAllocManaged},
    {"cuDeviceGetByPCIBusId", (void *)cuDeviceGetByPCIBusId},
    {"cuDeviceGetPCIBusId", (void *)cuDeviceGetPCIBusId},
    {"cuIpcGetEventHandle", (void *)cuIpcGetEventHandle},
    {"cuIpcOpenEventHandle", (void *)cuIpcOpenEventHandle},
    {"cuIpcGetMemHandle", (void *)cuIpcGetMemHandle},
    {"cuIpcOpenMemHandle_v2", (void *)cuIpcOpenMemHandle_v2},
    {"cuIpcCloseMemHandle", (void *)cuIpcCloseMemHandle},
    {"cuMemcpy", (void *)cuMemcpy},
    {"cuMemcpyPeer", (void *)cuMemcpyPeer},
    {"cuMemcpyHtoD_v2", (void *)cuMemcpyHtoD_v2},
    {"cuMemcpyDtoD_v2", (void *)cuMemcpyDtoD_v2},
    {"cuMemcpyDtoA_v2", (void *)cuMemcpyDtoA_v2},
    {"cuMemcpyAtoD_v2", (void *)cuMemcpyAtoD_v2},
    {"cuMemcpyAtoH_v2", (void *)cuMemcpyAtoH_v2},
    {"cuMemcpyAtoA_v2", (void *)cuMemcpyAtoA_v2},
    {"cuMemcpyAsync", (void *)cuMemcpyAsync},
    {"cuMemcpyPeerAsync", (void *)cuMemcpyPeerAsync},
    {"cuMemcpyHtoDAsync_v2", (void *)cuMemcpyHtoDAsync_v2},
    {"cuMemcpyDtoDAsync_v2", (void *)cuMemcpyDtoDAsync_v2},
    {"cuMemsetD8_v2", (void *)cuMemsetD8_v2},
    {"cuMemsetD16_v2", (void *)cuMemsetD16_v2},
    {"cuMemsetD32_v2", (void *)cuMemsetD32_v2},
    {"cuMemsetD2D8_v2", (void *)cuMemsetD2D8_v2},
    {"cuMemsetD2D16_v2", (void *)cuMemsetD2D16_v2},
    {"cuMemsetD2D32_v2", (void *)cuMemsetD2D32_v2},
    {"cuMemsetD8Async", (void *)cuMemsetD8Async},
    {"cuMemsetD16Async", (void *)cuMemsetD16Async},
    {"cuMemsetD32Async", (void *)cuMemsetD32Async},
    {"cuMemsetD2D8Async", (void *)cuMemsetD2D8Async},
    {"cuMemsetD2D16Async", (void *)cuMemsetD2D16Async},
    {"cuMemsetD2D32Async", (void *)cuMemsetD2D32Async},
    {"cuArrayCreate_v2", (void *)cuArrayCreate_v2},
    {"cuArrayGetDescriptor_v2", (void *)cuArrayGetDescriptor_v2},
    {"cuArrayGetSparseProperties", (void *)cuArrayGetSparseProperties},
    {"cuMipmappedArrayGetSparseProperties",
     (void *)cuMipmappedArrayGetSparseProperties},
    {"cuArrayGetMemoryRequirements", (void *)cuArrayGetMemoryRequirements},
    {"cuMipmappedArrayGetMemoryRequirements",
     (void *)cuMipmappedArrayGetMemoryRequirements},
    {"cuArrayGetPlane", (void *)cuArrayGetPlane},
    {"cuArrayDestroy", (void *)cuArrayDestroy},
    {"cuArray3DCreate_v2", (void *)cuArray3DCreate_v2},
    {"cuArray3DGetDescriptor_v2", (void *)cuArray3DGetDescriptor_v2},
    {"cuMipmappedArrayCreate", (void *)cuMipmappedArrayCreate},
    {"cuMipmappedArrayGetLevel", (void *)cuMipmappedArrayGetLevel},
    {"cuMipmappedArrayDestroy", (void *)cuMipmappedArrayDestroy},
    {"cuMemAddressReserve", (void *)cuMemAddressReserve},
    {"cuMemAddressFree", (void *)cuMemAddressFree},
    {"cuMemCreate", (void *)cuMemCreate},
    {"cuMemRelease", (void *)cuMemRelease},
    {"cuMemMap", (void *)cuMemMap},
    {"cuMemMapArrayAsync", (void *)cuMemMapArrayAsync},
    {"cuMemUnmap", (void *)cuMemUnmap},
    {"cuMemSetAccess", (void *)cuMemSetAccess},
    {"cuMemGetAccess", (void *)cuMemGetAccess},
    {"cuMemGetAllocationGranularity", (void *)cuMemGetAllocationGranularity},
    {"cuMemGetAllocationPropertiesFromHandle",
     (void *)cuMemGetAllocationPropertiesFromHandle},
    {"cuMemFreeAsync", (void *)cuMemFreeAsync},
    {"cuMemAllocAsync", (void *)cuMemAllocAsync},
    {"cuMemPoolTrimTo", (void *)cuMemPoolTrimTo},
    {"cuMemPoolSetAccess", (void *)cuMemPoolSetAccess},
    {"cuMemPoolGetAccess", (void *)cuMemPoolGetAccess},
    {"cuMemPoolCreate", (void *)cuMemPoolCreate},
    {"cuMemPoolDestroy", (void *)cuMemPoolDestroy},
    {"cuMemAllocFromPoolAsync", (void *)cuMemAllocFromPoolAsync},
    {"cuMemPoolExportPointer", (void *)cuMemPoolExportPointer},
    {"cuMemPoolImportPointer", (void *)cuMemPoolImportPointer},
    {"cuMemPrefetchAsync", (void *)cuMemPrefetchAsync},
    {"cuMemAdvise", (void *)cuMemAdvise},
    {"cuMemRangeGetAttributes", (void *)cuMemRangeGetAttributes},
    {"cuPointerSetAttribute", (void *)cuPointerSetAttribute},
    {"cuPointerGetAttributes", (void *)cuPointerGetAttributes},
    {"cuStreamCreate", (void *)cuStreamCreate},
    {"cuStreamCreateWithPriority", (void *)cuStreamCreateWithPriority},
    {"cuStreamGetPriority", (void *)cuStreamGetPriority},
    {"cuStreamGetFlags", (void *)cuStreamGetFlags},
    {"cuStreamGetId", (void *)cuStreamGetId},
    {"cuStreamGetCtx", (void *)cuStreamGetCtx},
    {"cuStreamWaitEvent", (void *)cuStreamWaitEvent},
    {"cuStreamBeginCapture_v2", (void *)cuStreamBeginCapture_v2},
    {"cuThreadExchangeStreamCaptureMode",
     (void *)cuThreadExchangeStreamCaptureMode},
    {"cuStreamEndCapture", (void *)cuStreamEndCapture},
    {"cuStreamIsCapturing", (void *)cuStreamIsCapturing},
    {"cuStreamUpdateCaptureDependencies",
     (void *)cuStreamUpdateCaptureDependencies},
    {"cuStreamAttachMemAsync", (void *)cuStreamAttachMemAsync},
    {"cuStreamQuery", (void *)cuStreamQuery},
    {"cuStreamSynchronize", (void *)cuStreamSynchronize},
    {"cuStreamDestroy_v2", (void *)cuStreamDestroy_v2},
    {"cuStreamCopyAttributes", (void *)cuStreamCopyAttributes},
    {"cuStreamGetAttribute", (void *)cuStreamGetAttribute},
    {"cuStreamSetAttribute", (void *)cuStreamSetAttribute},
    {"cuEventCreate", (void *)cuEventCreate},
    {"cuEventRecord", (void *)cuEventRecord},
    {"cuEventRecordWithFlags", (void *)cuEventRecordWithFlags},
    {"cuEventQuery", (void *)cuEventQuery},
    {"cuEventSynchronize", (void *)cuEventSynchronize},
    {"cuEventDestroy_v2", (void *)cuEventDestroy_v2},
    {"cuEventElapsedTime", (void *)cuEventElapsedTime},
    {"cuImportExternalMemory", (void *)cuImportExternalMemory},
    {"cuExternalMemoryGetMappedBuffer",
     (void *)cuExternalMemoryGetMappedBuffer},
    {"cuExternalMemoryGetMappedMipmappedArray",
     (void *)cuExternalMemoryGetMappedMipmappedArray},
    {"cuDestroyExternalMemory", (void *)cuDestroyExternalMemory},
    {"cuImportExternalSemaphore", (void *)cuImportExternalSemaphore},
    {"cuSignalExternalSemaphoresAsync",
     (void *)cuSignalExternalSemaphoresAsync},
    {"cuWaitExternalSemaphoresAsync", (void *)cuWaitExternalSemaphoresAsync},
    {"cuDestroyExternalSemaphore", (void *)cuDestroyExternalSemaphore},
    {"cuStreamWaitValue32_v2", (void *)cuStreamWaitValue32_v2},
    {"cuStreamWaitValue64_v2", (void *)cuStreamWaitValue64_v2},
    {"cuStreamWriteValue32_v2", (void *)cuStreamWriteValue32_v2},
    {"cuStreamWriteValue64_v2", (void *)cuStreamWriteValue64_v2},
    {"cuStreamBatchMemOp_v2", (void *)cuStreamBatchMemOp_v2},
    {"cuFuncGetAttribute", (void *)cuFuncGetAttribute},
    {"cuFuncSetAttribute", (void *)cuFuncSetAttribute},
    {"cuFuncSetCacheConfig", (void *)cuFuncSetCacheConfig},
    {"cuFuncSetSharedMemConfig", (void *)cuFuncSetSharedMemConfig},
    {"cuFuncGetModule", (void *)cuFuncGetModule},
    {"cuLaunchKernel", (void *)cuLaunchKernel},
    {"cuLaunchCooperativeKernel", (void *)cuLaunchCooperativeKernel},
    {"cuLaunchCooperativeKernelMultiDevice",
     (void *)cuLaunchCooperativeKernelMultiDevice},
    {"cuFuncSetBlockShape", (void *)cuFuncSetBlockShape},
    {"cuFuncSetSharedSize", (void *)cuFuncSetSharedSize},
    {"cuParamSetSize", (void *)cuParamSetSize},
    {"cuParamSeti", (void *)cuParamSeti},
    {"cuParamSetf", (void *)cuParamSetf},
    {"cuLaunch", (void *)cuLaunch},
    {"cuLaunchGrid", (void *)cuLaunchGrid},
    {"cuLaunchGridAsync", (void *)cuLaunchGridAsync},
    {"cuParamSetTexRef", (void *)cuParamSetTexRef},
    {"cuGraphCreate", (void *)cuGraphCreate},
    {"cuGraphAddKernelNode_v2", (void *)cuGraphAddKernelNode_v2},
    {"cuGraphKernelNodeGetParams_v2", (void *)cuGraphKernelNodeGetParams_v2},
    {"cuGraphKernelNodeSetParams_v2", (void *)cuGraphKernelNodeSetParams_v2},
    {"cuGraphAddMemcpyNode", (void *)cuGraphAddMemcpyNode},
    {"cuGraphMemcpyNodeGetParams", (void *)cuGraphMemcpyNodeGetParams},
    {"cuGraphMemcpyNodeSetParams", (void *)cuGraphMemcpyNodeSetParams},
    {"cuGraphAddMemsetNode", (void *)cuGraphAddMemsetNode},
    {"cuGraphMemsetNodeGetParams", (void *)cuGraphMemsetNodeGetParams},
    {"cuGraphMemsetNodeSetParams", (void *)cuGraphMemsetNodeSetParams},
    {"cuGraphAddHostNode", (void *)cuGraphAddHostNode},
    {"cuGraphHostNodeGetParams", (void *)cuGraphHostNodeGetParams},
    {"cuGraphHostNodeSetParams", (void *)cuGraphHostNodeSetParams},
    {"cuGraphAddChildGraphNode", (void *)cuGraphAddChildGraphNode},
    {"cuGraphChildGraphNodeGetGraph", (void *)cuGraphChildGraphNodeGetGraph},
    {"cuGraphAddEmptyNode", (void *)cuGraphAddEmptyNode},
    {"cuGraphAddEventRecordNode", (void *)cuGraphAddEventRecordNode},
    {"cuGraphEventRecordNodeGetEvent", (void *)cuGraphEventRecordNodeGetEvent},
    {"cuGraphEventRecordNodeSetEvent", (void *)cuGraphEventRecordNodeSetEvent},
    {"cuGraphAddEventWaitNode", (void *)cuGraphAddEventWaitNode},
    {"cuGraphEventWaitNodeGetEvent", (void *)cuGraphEventWaitNodeGetEvent},
    {"cuGraphEventWaitNodeSetEvent", (void *)cuGraphEventWaitNodeSetEvent},
    {"cuGraphAddExternalSemaphoresSignalNode",
     (void *)cuGraphAddExternalSemaphoresSignalNode},
    {"cuGraphExternalSemaphoresSignalNodeGetParams",
     (void *)cuGraphExternalSemaphoresSignalNodeGetParams},
    {"cuGraphExternalSemaphoresSignalNodeSetParams",
     (void *)cuGraphExternalSemaphoresSignalNodeSetParams},
    {"cuGraphAddExternalSemaphoresWaitNode",
     (void *)cuGraphAddExternalSemaphoresWaitNode},
    {"cuGraphExternalSemaphoresWaitNodeGetParams",
     (void *)cuGraphExternalSemaphoresWaitNodeGetParams},
    {"cuGraphExternalSemaphoresWaitNodeSetParams",
     (void *)cuGraphExternalSemaphoresWaitNodeSetParams},
    {"cuGraphAddBatchMemOpNode", (void *)cuGraphAddBatchMemOpNode},
    {"cuGraphBatchMemOpNodeGetParams", (void *)cuGraphBatchMemOpNodeGetParams},
    {"cuGraphBatchMemOpNodeSetParams", (void *)cuGraphBatchMemOpNodeSetParams},
    {"cuGraphExecBatchMemOpNodeSetParams",
     (void *)cuGraphExecBatchMemOpNodeSetParams},
    {"cuGraphAddMemAllocNode", (void *)cuGraphAddMemAllocNode},
    {"cuGraphMemAllocNodeGetParams", (void *)cuGraphMemAllocNodeGetParams},
    {"cuGraphAddMemFreeNode", (void *)cuGraphAddMemFreeNode},
    {"cuGraphMemFreeNodeGetParams", (void *)cuGraphMemFreeNodeGetParams},
    {"cuDeviceGraphMemTrim", (void *)cuDeviceGraphMemTrim},
    {"cuGraphClone", (void *)cuGraphClone},
    {"cuGraphNodeFindInClone", (void *)cuGraphNodeFindInClone},
    {"cuGraphNodeGetType", (void *)cuGraphNodeGetType},
    {"cuGraphGetNodes", (void *)cuGraphGetNodes},
    {"cuGraphGetRootNodes", (void *)cuGraphGetRootNodes},
    {"cuGraphGetEdges", (void *)cuGraphGetEdges},
    {"cuGraphNodeGetDependencies", (void *)cuGraphNodeGetDependencies},
    {"cuGraphNodeGetDependentNodes", (void *)cuGraphNodeGetDependentNodes},
    {"cuGraphAddDependencies", (void *)cuGraphAddDependencies},
    {"cuGraphRemoveDependencies", (void *)cuGraphRemoveDependencies},
    {"cuGraphDestroyNode", (void *)cuGraphDestroyNode},
    {"cuGraphInstantiateWithFlags", (void *)cuGraphInstantiateWithFlags},
    {"cuGraphInstantiateWithParams", (void *)cuGraphInstantiateWithParams},
    {"cuGraphExecGetFlags", (void *)cuGraphExecGetFlags},
    {"cuGraphExecKernelNodeSetParams_v2",
     (void *)cuGraphExecKernelNodeSetParams_v2},
    {"cuGraphExecMemcpyNodeSetParams", (void *)cuGraphExecMemcpyNodeSetParams},
    {"cuGraphExecMemsetNodeSetParams", (void *)cuGraphExecMemsetNodeSetParams},
    {"cuGraphExecHostNodeSetParams", (void *)cuGraphExecHostNodeSetParams},
    {"cuGraphExecChildGraphNodeSetParams",
     (void *)cuGraphExecChildGraphNodeSetParams},
    {"cuGraphExecEventRecordNodeSetEvent",
     (void *)cuGraphExecEventRecordNodeSetEvent},
    {"cuGraphExecEventWaitNodeSetEvent",
     (void *)cuGraphExecEventWaitNodeSetEvent},
    {"cuGraphExecExternalSemaphoresSignalNodeSetParams",
     (void *)cuGraphExecExternalSemaphoresSignalNodeSetParams},
    {"cuGraphExecExternalSemaphoresWaitNodeSetParams",
     (void *)cuGraphExecExternalSemaphoresWaitNodeSetParams},
    {"cuGraphNodeSetEnabled", (void *)cuGraphNodeSetEnabled},
    {"cuGraphNodeGetEnabled", (void *)cuGraphNodeGetEnabled},
    {"cuGraphUpload", (void *)cuGraphUpload},
    {"cuGraphLaunch", (void *)cuGraphLaunch},
    {"cuGraphExecDestroy", (void *)cuGraphExecDestroy},
    {"cuGraphDestroy", (void *)cuGraphDestroy},
    {"cuGraphExecUpdate_v2", (void *)cuGraphExecUpdate_v2},
    {"cuGraphKernelNodeCopyAttributes",
     (void *)cuGraphKernelNodeCopyAttributes},
    {"cuGraphKernelNodeGetAttribute", (void *)cuGraphKernelNodeGetAttribute},
    {"cuGraphKernelNodeSetAttribute", (void *)cuGraphKernelNodeSetAttribute},
    {"cuGraphDebugDotPrint", (void *)cuGraphDebugDotPrint},
    {"cuUserObjectRetain", (void *)cuUserObjectRetain},
    {"cuUserObjectRelease", (void *)cuUserObjectRelease},
    {"cuGraphRetainUserObject", (void *)cuGraphRetainUserObject},
    {"cuGraphReleaseUserObject", (void *)cuGraphReleaseUserObject},
    {"cuOccupancyMaxActiveBlocksPerMultiprocessor",
     (void *)cuOccupancyMaxActiveBlocksPerMultiprocessor},
    {"cuOccupancyMaxActiveBlocksPerMultiprocessorWithFlags",
     (void *)cuOccupancyMaxActiveBlocksPerMultiprocessorWithFlags},
    {"cuOccupancyAvailableDynamicSMemPerBlock",
     (void *)cuOccupancyAvailableDynamicSMemPerBlock},
    {"cuOccupancyMaxPotentialClusterSize",
     (void *)cuOccupancyMaxPotentialClusterSize},
    {"cuOccupancyMaxActiveClusters", (void *)cuOccupancyMaxActiveClusters},
    {"cuTexRefSetArray", (void *)cuTexRefSetArray},
    {"cuTexRefSetMipmappedArray", (void *)cuTexRefSetMipmappedArray},
    {"cuTexRefSetAddress_v2", (void *)cuTexRefSetAddress_v2},
    {"cuTexRefSetAddress2D_v3", (void *)cuTexRefSetAddress2D_v3},
    {"cuTexRefSetFormat", (void *)cuTexRefSetFormat},
    {"cuTexRefSetAddressMode", (void *)cuTexRefSetAddressMode},
    {"cuTexRefSetFilterMode", (void *)cuTexRefSetFilterMode},
    {"cuTexRefSetMipmapFilterMode", (void *)cuTexRefSetMipmapFilterMode},
    {"cuTexRefSetMipmapLevelBias", (void *)cuTexRefSetMipmapLevelBias},
    {"cuTexRefSetMipmapLevelClamp", (void *)cuTexRefSetMipmapLevelClamp},
    {"cuTexRefSetMaxAnisotropy", (void *)cuTexRefSetMaxAnisotropy},
    {"cuTexRefSetBorderColor", (void *)cuTexRefSetBorderColor},
    {"cuTexRefSetFlags", (void *)cuTexRefSetFlags},
    {"cuTexRefGetAddress_v2", (void *)cuTexRefGetAddress_v2},
    {"cuTexRefGetArray", (void *)cuTexRefGetArray},
    {"cuTexRefGetMipmappedArray", (void *)cuTexRefGetMipmappedArray},
    {"cuTexRefGetAddressMode", (void *)cuTexRefGetAddressMode},
    {"cuTexRefGetFilterMode", (void *)cuTexRefGetFilterMode},
    {"cuTexRefGetFormat", (void *)cuTexRefGetFormat},
    {"cuTexRefGetMipmapFilterMode", (void *)cuTexRefGetMipmapFilterMode},
    {"cuTexRefGetMipmapLevelBias", (void *)cuTexRefGetMipmapLevelBias},
    {"cuTexRefGetMipmapLevelClamp", (void *)cuTexRefGetMipmapLevelClamp},
    {"cuTexRefGetMaxAnisotropy", (void *)cuTexRefGetMaxAnisotropy},
    {"cuTexRefGetBorderColor", (void *)cuTexRefGetBorderColor},
    {"cuTexRefGetFlags", (void *)cuTexRefGetFlags},
    {"cuTexRefCreate", (void *)cuTexRefCreate},
    {"cuTexRefDestroy", (void *)cuTexRefDestroy},
    {"cuSurfRefSetArray", (void *)cuSurfRefSetArray},
    {"cuSurfRefGetArray", (void *)cuSurfRefGetArray},
    {"cuTexObjectCreate", (void *)cuTexObjectCreate},
    {"cuTexObjectDestroy", (void *)cuTexObjectDestroy},
    {"cuTexObjectGetResourceDesc", (void *)cuTexObjectGetResourceDesc},
    {"cuTexObjectGetTextureDesc", (void *)cuTexObjectGetTextureDesc},
    {"cuTexObjectGetResourceViewDesc", (void *)cuTexObjectGetResourceViewDesc},
    {"cuSurfObjectCreate", (void *)cuSurfObjectCreate},
    {"cuSurfObjectDestroy", (void *)cuSurfObjectDestroy},
    {"cuSurfObjectGetResourceDesc", (void *)cuSurfObjectGetResourceDesc},
    {"cuDeviceCanAccessPeer", (void *)cuDeviceCanAccessPeer},
    {"cuCtxEnablePeerAccess", (void *)cuCtxEnablePeerAccess},
    {"cuCtxDisablePeerAccess", (void *)cuCtxDisablePeerAccess},
    {"cuDeviceGetP2PAttribute", (void *)cuDeviceGetP2PAttribute},
    {"cuGraphicsUnregisterResource", (void *)cuGraphicsUnregisterResource},
    {"cuGraphicsSubResourceGetMappedArray",
     (void *)cuGraphicsSubResourceGetMappedArray},
    {"cuGraphicsResourceGetMappedMipmappedArray",
     (void *)cuGraphicsResourceGetMappedMipmappedArray},
    {"cuGraphicsResourceGetMappedPointer_v2",
     (void *)cuGraphicsResourceGetMappedPointer_v2},
    {"cuGraphicsResourceSetMapFlags_v2",
     (void *)cuGraphicsResourceSetMapFlags_v2},
    {"cuGraphicsMapResources", (void *)cuGraphicsMapResources},
    {"cuGraphicsUnmapResources", (void *)cuGraphicsUnmapResources},
    {"cudaDeviceReset", (void *)cudaDeviceReset},
    {"cudaDeviceSynchronize", (void *)cudaDeviceSynchronize},
    {"cudaDeviceSetLimit", (void *)cudaDeviceSetLimit},
    {"cudaDeviceGetLimit", (void *)cudaDeviceGetLimit},
    {"cudaDeviceGetTexture1DLinearMaxWidth",
     (void *)cudaDeviceGetTexture1DLinearMaxWidth},
    {"cudaDeviceGetCacheConfig", (void *)cudaDeviceGetCacheConfig},
    {"cudaDeviceGetStreamPriorityRange",
     (void *)cudaDeviceGetStreamPriorityRange},
    {"cudaDeviceSetCacheConfig", (void *)cudaDeviceSetCacheConfig},
    {"cudaDeviceGetSharedMemConfig", (void *)cudaDeviceGetSharedMemConfig},
    {"cudaDeviceSetSharedMemConfig", (void *)cudaDeviceSetSharedMemConfig},
    {"cudaDeviceGetByPCIBusId", (void *)cudaDeviceGetByPCIBusId},
    {"cudaDeviceGetPCIBusId", (void *)cudaDeviceGetPCIBusId},
    {"cudaIpcGetEventHandle", (void *)cudaIpcGetEventHandle},
    {"cudaIpcOpenEventHandle", (void *)cudaIpcOpenEventHandle},
    {"cudaIpcOpenMemHandle", (void *)cudaIpcOpenMemHandle},
    {"cudaDeviceFlushGPUDirectRDMAWrites",
     (void *)cudaDeviceFlushGPUDirectRDMAWrites},
    {"cudaThreadExit", (void *)cudaThreadExit},
    {"cudaThreadSynchronize", (void *)cudaThreadSynchronize},
    {"cudaThreadSetLimit", (void *)cudaThreadSetLimit},
    {"cudaThreadGetLimit", (void *)cudaThreadGetLimit},
    {"cudaThreadGetCacheConfig", (void *)cudaThreadGetCacheConfig},
    {"cudaThreadSetCacheConfig", (void *)cudaThreadSetCacheConfig},
    {"cudaGetLastError", (void *)cudaGetLastError},
    {"cudaPeekAtLastError", (void *)cudaPeekAtLastError},
    {"cudaGetDeviceCount", (void *)cudaGetDeviceCount},
    {"cudaGetDeviceProperties_v2", (void *)cudaGetDeviceProperties_v2},
    {"cudaDeviceGetAttribute", (void *)cudaDeviceGetAttribute},
    {"cudaDeviceGetDefaultMemPool", (void *)cudaDeviceGetDefaultMemPool},
    {"cudaDeviceSetMemPool", (void *)cudaDeviceSetMemPool},
    {"cudaDeviceGetMemPool", (void *)cudaDeviceGetMemPool},
    {"cudaDeviceGetP2PAttribute", (void *)cudaDeviceGetP2PAttribute},
    {"cudaChooseDevice", (void *)cudaChooseDevice},
    {"cudaInitDevice", (void *)cudaInitDevice},
    {"cudaSetDevice", (void *)cudaSetDevice},
    {"cudaGetDevice", (void *)cudaGetDevice},
    {"cudaSetValidDevices", (void *)cudaSetValidDevices},
    {"cudaSetDeviceFlags", (void *)cudaSetDeviceFlags},
    {"cudaGetDeviceFlags", (void *)cudaGetDeviceFlags},
    {"cudaStreamCreate", (void *)cudaStreamCreate},
    {"cudaStreamCreateWithFlags", (void *)cudaStreamCreateWithFlags},
    {"cudaStreamCreateWithPriority", (void *)cudaStreamCreateWithPriority},
    {"cudaStreamGetPriority", (void *)cudaStreamGetPriority},
    {"cudaStreamGetFlags", (void *)cudaStreamGetFlags},
    {"cudaStreamGetId", (void *)cudaStreamGetId},
    {"cudaCtxResetPersistingL2Cache", (void *)cudaCtxResetPersistingL2Cache},
    {"cudaStreamCopyAttributes", (void *)cudaStreamCopyAttributes},
    {"cudaStreamGetAttribute", (void *)cudaStreamGetAttribute},
    {"cudaStreamSetAttribute", (void *)cudaStreamSetAttribute},
    {"cudaStreamDestroy", (void *)cudaStreamDestroy},
    {"cudaStreamWaitEvent", (void *)cudaStreamWaitEvent},
    {"cudaStreamSynchronize", (void *)cudaStreamSynchronize},
    {"cudaStreamQuery", (void *)cudaStreamQuery},
    {"cudaStreamBeginCapture", (void *)cudaStreamBeginCapture},
    {"cudaThreadExchangeStreamCaptureMode",
     (void *)cudaThreadExchangeStreamCaptureMode},
    {"cudaStreamEndCapture", (void *)cudaStreamEndCapture},
    {"cudaStreamIsCapturing", (void *)cudaStreamIsCapturing},
    {"cudaStreamGetCaptureInfo_v2", (void *)cudaStreamGetCaptureInfo_v2},
    {"cudaStreamUpdateCaptureDependencies",
     (void *)cudaStreamUpdateCaptureDependencies},
    {"cudaEventCreate", (void *)cudaEventCreate},
    {"cudaEventCreateWithFlags", (void *)cudaEventCreateWithFlags},
    {"cudaEventRecord", (void *)cudaEventRecord},
    {"cudaEventRecordWithFlags", (void *)cudaEventRecordWithFlags},
    {"cudaEventQuery", (void *)cudaEventQuery},
    {"cudaEventSynchronize", (void *)cudaEventSynchronize},
    {"cudaEventDestroy", (void *)cudaEventDestroy},
    {"cudaEventElapsedTime", (void *)cudaEventElapsedTime},
    {"cudaExternalMemoryGetMappedBuffer",
     (void *)cudaExternalMemoryGetMappedBuffer},
    {"cudaExternalMemoryGetMappedMipmappedArray",
     (void *)cudaExternalMemoryGetMappedMipmappedArray},
    {"cudaDestroyExternalMemory", (void *)cudaDestroyExternalMemory},
    {"cudaImportExternalSemaphore", (void *)cudaImportExternalSemaphore},
    {"cudaSignalExternalSemaphoresAsync_v2",
     (void *)cudaSignalExternalSemaphoresAsync_v2},
    {"cudaWaitExternalSemaphoresAsync_v2",
     (void *)cudaWaitExternalSemaphoresAsync_v2},
    {"cudaDestroyExternalSemaphore", (void *)cudaDestroyExternalSemaphore},
    {"cudaLaunchKernelExC", (void *)cudaLaunchKernelExC},
    {"cudaLaunchCooperativeKernel", (void *)cudaLaunchCooperativeKernel},
    {"cudaLaunchCooperativeKernelMultiDevice",
     (void *)cudaLaunchCooperativeKernelMultiDevice},
    {"cudaFuncSetCacheConfig", (void *)cudaFuncSetCacheConfig},
    {"cudaFuncSetSharedMemConfig", (void *)cudaFuncSetSharedMemConfig},
    {"cudaFuncGetAttributes", (void *)cudaFuncGetAttributes},
    {"cudaFuncSetAttribute", (void *)cudaFuncSetAttribute},
    {"cudaSetDoubleForDevice", (void *)cudaSetDoubleForDevice},
    {"cudaSetDoubleForHost", (void *)cudaSetDoubleForHost},
    {"cudaOccupancyMaxActiveBlocksPerMultiprocessor",
     (void *)cudaOccupancyMaxActiveBlocksPerMultiprocessor},
    {"cudaOccupancyAvailableDynamicSMemPerBlock",
     (void *)cudaOccupancyAvailableDynamicSMemPerBlock},
    {"cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags",
     (void *)cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags},
    {"cudaOccupancyMaxPotentialClusterSize",
     (void *)cudaOccupancyMaxPotentialClusterSize},
    {"cudaOccupancyMaxActiveClusters", (void *)cudaOccupancyMaxActiveClusters},
    {"cudaMalloc", (void *)cudaMalloc},
    {"cudaMallocPitch", (void *)cudaMallocPitch},
    {"cudaMallocArray", (void *)cudaMallocArray},
    {"cudaFreeHost", (void *)cudaFreeHost},
    {"cudaFreeArray", (void *)cudaFreeArray},
    {"cudaFreeMipmappedArray", (void *)cudaFreeMipmappedArray},
    {"cudaHostAlloc", (void *)cudaHostAlloc},
    {"cudaMalloc3D", (void *)cudaMalloc3D},
    {"cudaMalloc3DArray", (void *)cudaMalloc3DArray},
    {"cudaMallocMipmappedArray", (void *)cudaMallocMipmappedArray},
    {"cudaGetMipmappedArrayLevel", (void *)cudaGetMipmappedArrayLevel},
    {"cudaMemcpy3D", (void *)cudaMemcpy3D},
    {"cudaMemcpy3DPeer", (void *)cudaMemcpy3DPeer},
    {"cudaMemcpy3DAsync", (void *)cudaMemcpy3DAsync},
    {"cudaMemcpy3DPeerAsync", (void *)cudaMemcpy3DPeerAsync},
    {"cudaMemGetInfo", (void *)cudaMemGetInfo},
    {"cudaArrayGetInfo", (void *)cudaArrayGetInfo},
    {"cudaArrayGetPlane", (void *)cudaArrayGetPlane},
    {"cudaArrayGetMemoryRequirements", (void *)cudaArrayGetMemoryRequirements},
    {"cudaMipmappedArrayGetMemoryRequirements",
     (void *)cudaMipmappedArrayGetMemoryRequirements},
    {"cudaArrayGetSparseProperties", (void *)cudaArrayGetSparseProperties},
    {"cudaMipmappedArrayGetSparseProperties",
     (void *)cudaMipmappedArrayGetSparseProperties},
    {"cudaMemcpy2DToArray", (void *)cudaMemcpy2DToArray},
    {"cudaMemcpy2DArrayToArray", (void *)cudaMemcpy2DArrayToArray},
    {"cudaMemcpyToSymbol", (void *)cudaMemcpyToSymbol},
    {"cudaMemcpy2DToArrayAsync", (void *)cudaMemcpy2DToArrayAsync},
    {"cudaMemcpyToSymbolAsync", (void *)cudaMemcpyToSymbolAsync},
    {"cudaMemset", (void *)cudaMemset},
    {"cudaMemset2D", (void *)cudaMemset2D},
    {"cudaMemset3D", (void *)cudaMemset3D},
    {"cudaMemsetAsync", (void *)cudaMemsetAsync},
    {"cudaMemset2DAsync", (void *)cudaMemset2DAsync},
    {"cudaMemset3DAsync", (void *)cudaMemset3DAsync},
    {"cudaGetSymbolAddress", (void *)cudaGetSymbolAddress},
    {"cudaGetSymbolSize", (void *)cudaGetSymbolSize},
    {"cudaMemPrefetchAsync", (void *)cudaMemPrefetchAsync},
    {"cudaMemAdvise", (void *)cudaMemAdvise},
    {"cudaMemRangeGetAttributes", (void *)cudaMemRangeGetAttributes},
    {"cudaMemcpyToArray", (void *)cudaMemcpyToArray},
    {"cudaMemcpyArrayToArray", (void *)cudaMemcpyArrayToArray},
    {"cudaMemcpyToArrayAsync", (void *)cudaMemcpyToArrayAsync},
    {"cudaMallocAsync", (void *)cudaMallocAsync},
    {"cudaMemPoolTrimTo", (void *)cudaMemPoolTrimTo},
    {"cudaMemPoolSetAccess", (void *)cudaMemPoolSetAccess},
    {"cudaMemPoolGetAccess", (void *)cudaMemPoolGetAccess},
    {"cudaMemPoolCreate", (void *)cudaMemPoolCreate},
    {"cudaMemPoolDestroy", (void *)cudaMemPoolDestroy},
    {"cudaMallocFromPoolAsync", (void *)cudaMallocFromPoolAsync},
    {"cudaMemPoolImportPointer", (void *)cudaMemPoolImportPointer},
    {"cudaPointerGetAttributes", (void *)cudaPointerGetAttributes},
    {"cudaDeviceCanAccessPeer", (void *)cudaDeviceCanAccessPeer},
    {"cudaDeviceEnablePeerAccess", (void *)cudaDeviceEnablePeerAccess},
    {"cudaDeviceDisablePeerAccess", (void *)cudaDeviceDisablePeerAccess},
    {"cudaGraphicsUnregisterResource", (void *)cudaGraphicsUnregisterResource},
    {"cudaGraphicsResourceSetMapFlags",
     (void *)cudaGraphicsResourceSetMapFlags},
    {"cudaGraphicsMapResources", (void *)cudaGraphicsMapResources},
    {"cudaGraphicsUnmapResources", (void *)cudaGraphicsUnmapResources},
    {"cudaGraphicsResourceGetMappedPointer",
     (void *)cudaGraphicsResourceGetMappedPointer},
    {"cudaGraphicsSubResourceGetMappedArray",
     (void *)cudaGraphicsSubResourceGetMappedArray},
    {"cudaGraphicsResourceGetMappedMipmappedArray",
     (void *)cudaGraphicsResourceGetMappedMipmappedArray},
    {"cudaGetChannelDesc", (void *)cudaGetChannelDesc},
    {"cudaCreateTextureObject", (void *)cudaCreateTextureObject},
    {"cudaDestroyTextureObject", (void *)cudaDestroyTextureObject},
    {"cudaGetTextureObjectResourceDesc",
     (void *)cudaGetTextureObjectResourceDesc},
    {"cudaGetTextureObjectTextureDesc",
     (void *)cudaGetTextureObjectTextureDesc},
    {"cudaGetTextureObjectResourceViewDesc",
     (void *)cudaGetTextureObjectResourceViewDesc},
    {"cudaCreateSurfaceObject", (void *)cudaCreateSurfaceObject},
    {"cudaDestroySurfaceObject", (void *)cudaDestroySurfaceObject},
    {"cudaGetSurfaceObjectResourceDesc",
     (void *)cudaGetSurfaceObjectResourceDesc},
    {"cudaDriverGetVersion", (void *)cudaDriverGetVersion},
    {"cudaRuntimeGetVersion", (void *)cudaRuntimeGetVersion},
    {"cudaGraphCreate", (void *)cudaGraphCreate},
    {"cudaGraphKernelNodeGetParams", (void *)cudaGraphKernelNodeGetParams},
    {"cudaGraphKernelNodeSetParams", (void *)cudaGraphKernelNodeSetParams},
    {"cudaGraphKernelNodeCopyAttributes",
     (void *)cudaGraphKernelNodeCopyAttributes},
    {"cudaGraphKernelNodeGetAttribute",
     (void *)cudaGraphKernelNodeGetAttribute},
    {"cudaGraphKernelNodeSetAttribute",
     (void *)cudaGraphKernelNodeSetAttribute},
    {"cudaGraphAddMemcpyNodeToSymbol", (void *)cudaGraphAddMemcpyNodeToSymbol},
    {"cudaGraphMemcpyNodeGetParams", (void *)cudaGraphMemcpyNodeGetParams},
    {"cudaGraphMemcpyNodeSetParams", (void *)cudaGraphMemcpyNodeSetParams},
    {"cudaGraphMemcpyNodeSetParamsToSymbol",
     (void *)cudaGraphMemcpyNodeSetParamsToSymbol},
    {"cudaGraphAddMemsetNode", (void *)cudaGraphAddMemsetNode},
    {"cudaGraphMemsetNodeGetParams", (void *)cudaGraphMemsetNodeGetParams},
    {"cudaGraphMemsetNodeSetParams", (void *)cudaGraphMemsetNodeSetParams},
    {"cudaGraphHostNodeGetParams", (void *)cudaGraphHostNodeGetParams},
    {"cudaGraphHostNodeSetParams", (void *)cudaGraphHostNodeSetParams},
    {"cudaGraphAddChildGraphNode", (void *)cudaGraphAddChildGraphNode},
    {"cudaGraphChildGraphNodeGetGraph",
     (void *)cudaGraphChildGraphNodeGetGraph},
    {"cudaGraphAddEmptyNode", (void *)cudaGraphAddEmptyNode},
    {"cudaGraphAddEventRecordNode", (void *)cudaGraphAddEventRecordNode},
    {"cudaGraphEventRecordNodeGetEvent",
     (void *)cudaGraphEventRecordNodeGetEvent},
    {"cudaGraphEventRecordNodeSetEvent",
     (void *)cudaGraphEventRecordNodeSetEvent},
    {"cudaGraphAddEventWaitNode", (void *)cudaGraphAddEventWaitNode},
    {"cudaGraphEventWaitNodeGetEvent", (void *)cudaGraphEventWaitNodeGetEvent},
    {"cudaGraphEventWaitNodeSetEvent", (void *)cudaGraphEventWaitNodeSetEvent},
    {"cudaGraphAddExternalSemaphoresSignalNode",
     (void *)cudaGraphAddExternalSemaphoresSignalNode},
    {"cudaGraphExternalSemaphoresSignalNodeGetParams",
     (void *)cudaGraphExternalSemaphoresSignalNodeGetParams},
    {"cudaGraphExternalSemaphoresSignalNodeSetParams",
     (void *)cudaGraphExternalSemaphoresSignalNodeSetParams},
    {"cudaGraphAddExternalSemaphoresWaitNode",
     (void *)cudaGraphAddExternalSemaphoresWaitNode},
    {"cudaGraphExternalSemaphoresWaitNodeGetParams",
     (void *)cudaGraphExternalSemaphoresWaitNodeGetParams},
    {"cudaGraphExternalSemaphoresWaitNodeSetParams",
     (void *)cudaGraphExternalSemaphoresWaitNodeSetParams},
    {"cudaGraphMemAllocNodeGetParams", (void *)cudaGraphMemAllocNodeGetParams},
    {"cudaDeviceGraphMemTrim", (void *)cudaDeviceGraphMemTrim},
    {"cudaGraphClone", (void *)cudaGraphClone},
    {"cudaGraphNodeFindInClone", (void *)cudaGraphNodeFindInClone},
    {"cudaGraphNodeGetType", (void *)cudaGraphNodeGetType},
    {"cudaGraphGetRootNodes", (void *)cudaGraphGetRootNodes},
    {"cudaGraphGetEdges", (void *)cudaGraphGetEdges},
    {"cudaGraphNodeGetDependencies", (void *)cudaGraphNodeGetDependencies},
    {"cudaGraphNodeGetDependentNodes", (void *)cudaGraphNodeGetDependentNodes},
    {"cudaGraphAddDependencies", (void *)cudaGraphAddDependencies},
    {"cudaGraphRemoveDependencies", (void *)cudaGraphRemoveDependencies},
    {"cudaGraphDestroyNode", (void *)cudaGraphDestroyNode},
    {"cudaGraphInstantiate", (void *)cudaGraphInstantiate},
    {"cudaGraphInstantiateWithFlags", (void *)cudaGraphInstantiateWithFlags},
    {"cudaGraphInstantiateWithParams", (void *)cudaGraphInstantiateWithParams},
    {"cudaGraphExecGetFlags", (void *)cudaGraphExecGetFlags},
    {"cudaGraphExecKernelNodeSetParams",
     (void *)cudaGraphExecKernelNodeSetParams},
    {"cudaGraphExecMemcpyNodeSetParams",
     (void *)cudaGraphExecMemcpyNodeSetParams},
    {"cudaGraphExecMemcpyNodeSetParamsToSymbol",
     (void *)cudaGraphExecMemcpyNodeSetParamsToSymbol},
    {"cudaGraphExecMemsetNodeSetParams",
     (void *)cudaGraphExecMemsetNodeSetParams},
    {"cudaGraphExecHostNodeSetParams", (void *)cudaGraphExecHostNodeSetParams},
    {"cudaGraphExecChildGraphNodeSetParams",
     (void *)cudaGraphExecChildGraphNodeSetParams},
    {"cudaGraphExecEventRecordNodeSetEvent",
     (void *)cudaGraphExecEventRecordNodeSetEvent},
    {"cudaGraphExecEventWaitNodeSetEvent",
     (void *)cudaGraphExecEventWaitNodeSetEvent},
    {"cudaGraphExecExternalSemaphoresSignalNodeSetParams",
     (void *)cudaGraphExecExternalSemaphoresSignalNodeSetParams},
    {"cudaGraphExecExternalSemaphoresWaitNodeSetParams",
     (void *)cudaGraphExecExternalSemaphoresWaitNodeSetParams},
    {"cudaGraphNodeSetEnabled", (void *)cudaGraphNodeSetEnabled},
    {"cudaGraphNodeGetEnabled", (void *)cudaGraphNodeGetEnabled},
    {"cudaGraphExecUpdate", (void *)cudaGraphExecUpdate},
    {"cudaGraphUpload", (void *)cudaGraphUpload},
    {"cudaGraphLaunch", (void *)cudaGraphLaunch},
    {"cudaGraphExecDestroy", (void *)cudaGraphExecDestroy},
    {"cudaGraphDebugDotPrint", (void *)cudaGraphDebugDotPrint},
    {"cudaUserObjectRetain", (void *)cudaUserObjectRetain},
    {"cudaUserObjectRelease", (void *)cudaUserObjectRelease},
    {"cudaGraphRetainUserObject", (void *)cudaGraphRetainUserObject},
    {"cudaGraphReleaseUserObject", (void *)cudaGraphReleaseUserObject},
    {"cudaGetDriverEntryPoint", (void *)cudaGetDriverEntryPoint},
    {"cudaGetExportTable", (void *)cudaGetExportTable},
    {"cudaGetFuncBySymbol", (void *)cudaGetFuncBySymbol},
    {"cublasCreate_v2", (void *)cublasCreate_v2},
    {"cublasDestroy_v2", (void *)cublasDestroy_v2},
    {"cublasGetVersion_v2", (void *)cublasGetVersion_v2},
    {"cublasGetProperty", (void *)cublasGetProperty},
    {"cublasSetStream_v2", (void *)cublasSetStream_v2},
    {"cublasGetStream_v2", (void *)cublasGetStream_v2},
    {"cublasGetPointerMode_v2", (void *)cublasGetPointerMode_v2},
    {"cublasSetPointerMode_v2", (void *)cublasSetPointerMode_v2},
    {"cublasGetAtomicsMode", (void *)cublasGetAtomicsMode},
    {"cublasSetAtomicsMode", (void *)cublasSetAtomicsMode},
    {"cublasGetMathMode", (void *)cublasGetMathMode},
    {"cublasSetMathMode", (void *)cublasSetMathMode},
    {"cublasGetSmCountTarget", (void *)cublasGetSmCountTarget},
    {"cublasSetSmCountTarget", (void *)cublasSetSmCountTarget},
    {"cublasLoggerConfigure", (void *)cublasLoggerConfigure},
    {"cublasSetLoggerCallback", (void *)cublasSetLoggerCallback},
    {"cublasGetLoggerCallback", (void *)cublasGetLoggerCallback},
    {"cublasSnrm2_v2", (void *)cublasSnrm2_v2},
    {"cublasSnrm2_v2_64", (void *)cublasSnrm2_v2_64},
    {"cublasDnrm2_v2", (void *)cublasDnrm2_v2},
    {"cublasDnrm2_v2_64", (void *)cublasDnrm2_v2_64},
    {"cublasScnrm2_v2", (void *)cublasScnrm2_v2},
    {"cublasScnrm2_v2_64", (void *)cublasScnrm2_v2_64},
    {"cublasDznrm2_v2", (void *)cublasDznrm2_v2},
    {"cublasDznrm2_v2_64", (void *)cublasDznrm2_v2_64},
    {"cublasSdot_v2", (void *)cublasSdot_v2},
    {"cublasSdot_v2_64", (void *)cublasSdot_v2_64},
    {"cublasDdot_v2", (void *)cublasDdot_v2},
    {"cublasDdot_v2_64", (void *)cublasDdot_v2_64},
    {"cublasCdotu_v2", (void *)cublasCdotu_v2},
    {"cublasCdotu_v2_64", (void *)cublasCdotu_v2_64},
    {"cublasCdotc_v2", (void *)cublasCdotc_v2},
    {"cublasCdotc_v2_64", (void *)cublasCdotc_v2_64},
    {"cublasZdotu_v2", (void *)cublasZdotu_v2},
    {"cublasZdotu_v2_64", (void *)cublasZdotu_v2_64},
    {"cublasZdotc_v2", (void *)cublasZdotc_v2},
    {"cublasZdotc_v2_64", (void *)cublasZdotc_v2_64},
    {"cublasSscal_v2", (void *)cublasSscal_v2},
    {"cublasSscal_v2_64", (void *)cublasSscal_v2_64},
    {"cublasDscal_v2", (void *)cublasDscal_v2},
    {"cublasDscal_v2_64", (void *)cublasDscal_v2_64},
    {"cublasCscal_v2", (void *)cublasCscal_v2},
    {"cublasCscal_v2_64", (void *)cublasCscal_v2_64},
    {"cublasCsscal_v2", (void *)cublasCsscal_v2},
    {"cublasCsscal_v2_64", (void *)cublasCsscal_v2_64},
    {"cublasZscal_v2", (void *)cublasZscal_v2},
    {"cublasZscal_v2_64", (void *)cublasZscal_v2_64},
    {"cublasZdscal_v2", (void *)cublasZdscal_v2},
    {"cublasZdscal_v2_64", (void *)cublasZdscal_v2_64},
    {"cublasSaxpy_v2", (void *)cublasSaxpy_v2},
    {"cublasSaxpy_v2_64", (void *)cublasSaxpy_v2_64},
    {"cublasDaxpy_v2", (void *)cublasDaxpy_v2},
    {"cublasDaxpy_v2_64", (void *)cublasDaxpy_v2_64},
    {"cublasCaxpy_v2", (void *)cublasCaxpy_v2},
    {"cublasCaxpy_v2_64", (void *)cublasCaxpy_v2_64},
    {"cublasZaxpy_v2", (void *)cublasZaxpy_v2},
    {"cublasZaxpy_v2_64", (void *)cublasZaxpy_v2_64},
    {"cublasScopy_v2", (void *)cublasScopy_v2},
    {"cublasScopy_v2_64", (void *)cublasScopy_v2_64},
    {"cublasDcopy_v2", (void *)cublasDcopy_v2},
    {"cublasDcopy_v2_64", (void *)cublasDcopy_v2_64},
    {"cublasCcopy_v2", (void *)cublasCcopy_v2},
    {"cublasCcopy_v2_64", (void *)cublasCcopy_v2_64},
    {"cublasZcopy_v2", (void *)cublasZcopy_v2},
    {"cublasZcopy_v2_64", (void *)cublasZcopy_v2_64},
    {"cublasSswap_v2", (void *)cublasSswap_v2},
    {"cublasSswap_v2_64", (void *)cublasSswap_v2_64},
    {"cublasDswap_v2", (void *)cublasDswap_v2},
    {"cublasDswap_v2_64", (void *)cublasDswap_v2_64},
    {"cublasCswap_v2", (void *)cublasCswap_v2},
    {"cublasCswap_v2_64", (void *)cublasCswap_v2_64},
    {"cublasZswap_v2", (void *)cublasZswap_v2},
    {"cublasZswap_v2_64", (void *)cublasZswap_v2_64},
    {"cublasIsamax_v2", (void *)cublasIsamax_v2},
    {"cublasIsamax_v2_64", (void *)cublasIsamax_v2_64},
    {"cublasIdamax_v2", (void *)cublasIdamax_v2},
    {"cublasIdamax_v2_64", (void *)cublasIdamax_v2_64},
    {"cublasIcamax_v2", (void *)cublasIcamax_v2},
    {"cublasIcamax_v2_64", (void *)cublasIcamax_v2_64},
    {"cublasIzamax_v2", (void *)cublasIzamax_v2},
    {"cublasIzamax_v2_64", (void *)cublasIzamax_v2_64},
    {"cublasIamaxEx", (void *)cublasIamaxEx},
    {"cublasIamaxEx_64", (void *)cublasIamaxEx_64},
    {"cublasIsamin_v2", (void *)cublasIsamin_v2},
    {"cublasIsamin_v2_64", (void *)cublasIsamin_v2_64},
    {"cublasIdamin_v2", (void *)cublasIdamin_v2},
    {"cublasIdamin_v2_64", (void *)cublasIdamin_v2_64},
    {"cublasIcamin_v2", (void *)cublasIcamin_v2},
    {"cublasIcamin_v2_64", (void *)cublasIcamin_v2_64},
    {"cublasIzamin_v2", (void *)cublasIzamin_v2},
    {"cublasIzamin_v2_64", (void *)cublasIzamin_v2_64},
    {"cublasIaminEx", (void *)cublasIaminEx},
    {"cublasIaminEx_64", (void *)cublasIaminEx_64},
    {"cublasSasum_v2", (void *)cublasSasum_v2},
    {"cublasSasum_v2_64", (void *)cublasSasum_v2_64},
    {"cublasDasum_v2", (void *)cublasDasum_v2},
    {"cublasDasum_v2_64", (void *)cublasDasum_v2_64},
    {"cublasScasum_v2", (void *)cublasScasum_v2},
    {"cublasScasum_v2_64", (void *)cublasScasum_v2_64},
    {"cublasDzasum_v2", (void *)cublasDzasum_v2},
    {"cublasDzasum_v2_64", (void *)cublasDzasum_v2_64},
    {"cublasSrot_v2", (void *)cublasSrot_v2},
    {"cublasSrot_v2_64", (void *)cublasSrot_v2_64},
    {"cublasDrot_v2", (void *)cublasDrot_v2},
    {"cublasDrot_v2_64", (void *)cublasDrot_v2_64},
    {"cublasCrot_v2", (void *)cublasCrot_v2},
    {"cublasCrot_v2_64", (void *)cublasCrot_v2_64},
    {"cublasCsrot_v2", (void *)cublasCsrot_v2},
    {"cublasCsrot_v2_64", (void *)cublasCsrot_v2_64},
    {"cublasZrot_v2", (void *)cublasZrot_v2},
    {"cublasZrot_v2_64", (void *)cublasZrot_v2_64},
    {"cublasZdrot_v2", (void *)cublasZdrot_v2},
    {"cublasZdrot_v2_64", (void *)cublasZdrot_v2_64},
    {"cublasSrotg_v2", (void *)cublasSrotg_v2},
    {"cublasDrotg_v2", (void *)cublasDrotg_v2},
    {"cublasCrotg_v2", (void *)cublasCrotg_v2},
    {"cublasZrotg_v2", (void *)cublasZrotg_v2},
    {"cublasSrotm_v2", (void *)cublasSrotm_v2},
    {"cublasSrotm_v2_64", (void *)cublasSrotm_v2_64},
    {"cublasDrotm_v2", (void *)cublasDrotm_v2},
    {"cublasDrotm_v2_64", (void *)cublasDrotm_v2_64},
    {"cublasSrotmg_v2", (void *)cublasSrotmg_v2},
    {"cublasDrotmg_v2", (void *)cublasDrotmg_v2},
    {"cublasSgemv_v2", (void *)cublasSgemv_v2},
    {"cublasSgemv_v2_64", (void *)cublasSgemv_v2_64},
    {"cublasDgemv_v2", (void *)cublasDgemv_v2},
    {"cublasDgemv_v2_64", (void *)cublasDgemv_v2_64},
    {"cublasCgemv_v2", (void *)cublasCgemv_v2},
    {"cublasCgemv_v2_64", (void *)cublasCgemv_v2_64},
    {"cublasZgemv_v2", (void *)cublasZgemv_v2},
    {"cublasZgemv_v2_64", (void *)cublasZgemv_v2_64},
    {"cublasSgbmv_v2", (void *)cublasSgbmv_v2},
    {"cublasSgbmv_v2_64", (void *)cublasSgbmv_v2_64},
    {"cublasDgbmv_v2", (void *)cublasDgbmv_v2},
    {"cublasDgbmv_v2_64", (void *)cublasDgbmv_v2_64},
    {"cublasCgbmv_v2", (void *)cublasCgbmv_v2},
    {"cublasCgbmv_v2_64", (void *)cublasCgbmv_v2_64},
    {"cublasZgbmv_v2", (void *)cublasZgbmv_v2},
    {"cublasZgbmv_v2_64", (void *)cublasZgbmv_v2_64},
    {"cublasStrmv_v2", (void *)cublasStrmv_v2},
    {"cublasStrmv_v2_64", (void *)cublasStrmv_v2_64},
    {"cublasDtrmv_v2", (void *)cublasDtrmv_v2},
    {"cublasDtrmv_v2_64", (void *)cublasDtrmv_v2_64},
    {"cublasCtrmv_v2", (void *)cublasCtrmv_v2},
    {"cublasCtrmv_v2_64", (void *)cublasCtrmv_v2_64},
    {"cublasZtrmv_v2", (void *)cublasZtrmv_v2},
    {"cublasZtrmv_v2_64", (void *)cublasZtrmv_v2_64},
    {"cublasStbmv_v2", (void *)cublasStbmv_v2},
    {"cublasStbmv_v2_64", (void *)cublasStbmv_v2_64},
    {"cublasDtbmv_v2", (void *)cublasDtbmv_v2},
    {"cublasDtbmv_v2_64", (void *)cublasDtbmv_v2_64},
    {"cublasCtbmv_v2", (void *)cublasCtbmv_v2},
    {"cublasCtbmv_v2_64", (void *)cublasCtbmv_v2_64},
    {"cublasZtbmv_v2", (void *)cublasZtbmv_v2},
    {"cublasZtbmv_v2_64", (void *)cublasZtbmv_v2_64},
    {"cublasStpmv_v2", (void *)cublasStpmv_v2},
    {"cublasStpmv_v2_64", (void *)cublasStpmv_v2_64},
    {"cublasDtpmv_v2", (void *)cublasDtpmv_v2},
    {"cublasDtpmv_v2_64", (void *)cublasDtpmv_v2_64},
    {"cublasCtpmv_v2", (void *)cublasCtpmv_v2},
    {"cublasCtpmv_v2_64", (void *)cublasCtpmv_v2_64},
    {"cublasZtpmv_v2", (void *)cublasZtpmv_v2},
    {"cublasZtpmv_v2_64", (void *)cublasZtpmv_v2_64},
    {"cublasStrsv_v2", (void *)cublasStrsv_v2},
    {"cublasStrsv_v2_64", (void *)cublasStrsv_v2_64},
    {"cublasDtrsv_v2", (void *)cublasDtrsv_v2},
    {"cublasDtrsv_v2_64", (void *)cublasDtrsv_v2_64},
    {"cublasCtrsv_v2", (void *)cublasCtrsv_v2},
    {"cublasCtrsv_v2_64", (void *)cublasCtrsv_v2_64},
    {"cublasZtrsv_v2", (void *)cublasZtrsv_v2},
    {"cublasZtrsv_v2_64", (void *)cublasZtrsv_v2_64},
    {"cublasStpsv_v2", (void *)cublasStpsv_v2},
    {"cublasStpsv_v2_64", (void *)cublasStpsv_v2_64},
    {"cublasDtpsv_v2", (void *)cublasDtpsv_v2},
    {"cublasDtpsv_v2_64", (void *)cublasDtpsv_v2_64},
    {"cublasCtpsv_v2", (void *)cublasCtpsv_v2},
    {"cublasCtpsv_v2_64", (void *)cublasCtpsv_v2_64},
    {"cublasZtpsv_v2", (void *)cublasZtpsv_v2},
    {"cublasZtpsv_v2_64", (void *)cublasZtpsv_v2_64},
    {"cublasStbsv_v2", (void *)cublasStbsv_v2},
    {"cublasStbsv_v2_64", (void *)cublasStbsv_v2_64},
    {"cublasDtbsv_v2", (void *)cublasDtbsv_v2},
    {"cublasDtbsv_v2_64", (void *)cublasDtbsv_v2_64},
    {"cublasCtbsv_v2", (void *)cublasCtbsv_v2},
    {"cublasCtbsv_v2_64", (void *)cublasCtbsv_v2_64},
    {"cublasZtbsv_v2", (void *)cublasZtbsv_v2},
    {"cublasZtbsv_v2_64", (void *)cublasZtbsv_v2_64},
    {"cublasSsymv_v2", (void *)cublasSsymv_v2},
    {"cublasSsymv_v2_64", (void *)cublasSsymv_v2_64},
    {"cublasDsymv_v2", (void *)cublasDsymv_v2},
    {"cublasDsymv_v2_64", (void *)cublasDsymv_v2_64},
    {"cublasCsymv_v2", (void *)cublasCsymv_v2},
    {"cublasCsymv_v2_64", (void *)cublasCsymv_v2_64},
    {"cublasZsymv_v2", (void *)cublasZsymv_v2},
    {"cublasZsymv_v2_64", (void *)cublasZsymv_v2_64},
    {"cublasChemv_v2", (void *)cublasChemv_v2},
    {"cublasChemv_v2_64", (void *)cublasChemv_v2_64},
    {"cublasZhemv_v2", (void *)cublasZhemv_v2},
    {"cublasZhemv_v2_64", (void *)cublasZhemv_v2_64},
    {"cublasSsbmv_v2", (void *)cublasSsbmv_v2},
    {"cublasSsbmv_v2_64", (void *)cublasSsbmv_v2_64},
    {"cublasDsbmv_v2", (void *)cublasDsbmv_v2},
    {"cublasDsbmv_v2_64", (void *)cublasDsbmv_v2_64},
    {"cublasChbmv_v2", (void *)cublasChbmv_v2},
    {"cublasChbmv_v2_64", (void *)cublasChbmv_v2_64},
    {"cublasZhbmv_v2", (void *)cublasZhbmv_v2},
    {"cublasZhbmv_v2_64", (void *)cublasZhbmv_v2_64},
    {"cublasSspmv_v2", (void *)cublasSspmv_v2},
    {"cublasSspmv_v2_64", (void *)cublasSspmv_v2_64},
    {"cublasDspmv_v2", (void *)cublasDspmv_v2},
    {"cublasDspmv_v2_64", (void *)cublasDspmv_v2_64},
    {"cublasChpmv_v2", (void *)cublasChpmv_v2},
    {"cublasChpmv_v2_64", (void *)cublasChpmv_v2_64},
    {"cublasZhpmv_v2", (void *)cublasZhpmv_v2},
    {"cublasZhpmv_v2_64", (void *)cublasZhpmv_v2_64},
    {"cublasSger_v2", (void *)cublasSger_v2},
    {"cublasSger_v2_64", (void *)cublasSger_v2_64},
    {"cublasDger_v2", (void *)cublasDger_v2},
    {"cublasDger_v2_64", (void *)cublasDger_v2_64},
    {"cublasCgeru_v2", (void *)cublasCgeru_v2},
    {"cublasCgeru_v2_64", (void *)cublasCgeru_v2_64},
    {"cublasCgerc_v2", (void *)cublasCgerc_v2},
    {"cublasCgerc_v2_64", (void *)cublasCgerc_v2_64},
    {"cublasZgeru_v2", (void *)cublasZgeru_v2},
    {"cublasZgeru_v2_64", (void *)cublasZgeru_v2_64},
    {"cublasZgerc_v2", (void *)cublasZgerc_v2},
    {"cublasZgerc_v2_64", (void *)cublasZgerc_v2_64},
    {"cublasSsyr_v2", (void *)cublasSsyr_v2},
    {"cublasSsyr_v2_64", (void *)cublasSsyr_v2_64},
    {"cublasDsyr_v2", (void *)cublasDsyr_v2},
    {"cublasDsyr_v2_64", (void *)cublasDsyr_v2_64},
    {"cublasCsyr_v2", (void *)cublasCsyr_v2},
    {"cublasCsyr_v2_64", (void *)cublasCsyr_v2_64},
    {"cublasZsyr_v2", (void *)cublasZsyr_v2},
    {"cublasZsyr_v2_64", (void *)cublasZsyr_v2_64},
    {"cublasCher_v2", (void *)cublasCher_v2},
    {"cublasCher_v2_64", (void *)cublasCher_v2_64},
    {"cublasZher_v2", (void *)cublasZher_v2},
    {"cublasZher_v2_64", (void *)cublasZher_v2_64},
    {"cublasSspr_v2", (void *)cublasSspr_v2},
    {"cublasSspr_v2_64", (void *)cublasSspr_v2_64},
    {"cublasDspr_v2", (void *)cublasDspr_v2},
    {"cublasDspr_v2_64", (void *)cublasDspr_v2_64},
    {"cublasChpr_v2", (void *)cublasChpr_v2},
    {"cublasChpr_v2_64", (void *)cublasChpr_v2_64},
    {"cublasZhpr_v2", (void *)cublasZhpr_v2},
    {"cublasZhpr_v2_64", (void *)cublasZhpr_v2_64},
    {"cublasSsyr2_v2", (void *)cublasSsyr2_v2},
    {"cublasSsyr2_v2_64", (void *)cublasSsyr2_v2_64},
    {"cublasDsyr2_v2", (void *)cublasDsyr2_v2},
    {"cublasDsyr2_v2_64", (void *)cublasDsyr2_v2_64},
    {"cublasCsyr2_v2", (void *)cublasCsyr2_v2},
    {"cublasCsyr2_v2_64", (void *)cublasCsyr2_v2_64},
    {"cublasZsyr2_v2", (void *)cublasZsyr2_v2},
    {"cublasZsyr2_v2_64", (void *)cublasZsyr2_v2_64},
    {"cublasCher2_v2", (void *)cublasCher2_v2},
    {"cublasCher2_v2_64", (void *)cublasCher2_v2_64},
    {"cublasZher2_v2", (void *)cublasZher2_v2},
    {"cublasZher2_v2_64", (void *)cublasZher2_v2_64},
    {"cublasSspr2_v2", (void *)cublasSspr2_v2},
    {"cublasSspr2_v2_64", (void *)cublasSspr2_v2_64},
    {"cublasDspr2_v2", (void *)cublasDspr2_v2},
    {"cublasDspr2_v2_64", (void *)cublasDspr2_v2_64},
    {"cublasChpr2_v2", (void *)cublasChpr2_v2},
    {"cublasChpr2_v2_64", (void *)cublasChpr2_v2_64},
    {"cublasZhpr2_v2", (void *)cublasZhpr2_v2},
    {"cublasZhpr2_v2_64", (void *)cublasZhpr2_v2_64},
    {"cublasSgemvStridedBatched", (void *)cublasSgemvStridedBatched},
    {"cublasSgemvStridedBatched_64", (void *)cublasSgemvStridedBatched_64},
    {"cublasDgemvStridedBatched", (void *)cublasDgemvStridedBatched},
    {"cublasDgemvStridedBatched_64", (void *)cublasDgemvStridedBatched_64},
    {"cublasCgemvStridedBatched", (void *)cublasCgemvStridedBatched},
    {"cublasCgemvStridedBatched_64", (void *)cublasCgemvStridedBatched_64},
    {"cublasZgemvStridedBatched", (void *)cublasZgemvStridedBatched},
    {"cublasZgemvStridedBatched_64", (void *)cublasZgemvStridedBatched_64},
    {"cublasHSHgemvStridedBatched", (void *)cublasHSHgemvStridedBatched},
    {"cublasHSHgemvStridedBatched_64", (void *)cublasHSHgemvStridedBatched_64},
    {"cublasHSSgemvStridedBatched", (void *)cublasHSSgemvStridedBatched},
    {"cublasHSSgemvStridedBatched_64", (void *)cublasHSSgemvStridedBatched_64},
    {"cublasTSTgemvStridedBatched", (void *)cublasTSTgemvStridedBatched},
    {"cublasTSTgemvStridedBatched_64", (void *)cublasTSTgemvStridedBatched_64},
    {"cublasTSSgemvStridedBatched", (void *)cublasTSSgemvStridedBatched},
    {"cublasTSSgemvStridedBatched_64", (void *)cublasTSSgemvStridedBatched_64},
    {"cublasSgemm_v2", (void *)cublasSgemm_v2},
    {"cublasSgemm_v2_64", (void *)cublasSgemm_v2_64},
    {"cublasDgemm_v2", (void *)cublasDgemm_v2},
    {"cublasDgemm_v2_64", (void *)cublasDgemm_v2_64},
    {"cublasCgemm_v2", (void *)cublasCgemm_v2},
    {"cublasCgemm_v2_64", (void *)cublasCgemm_v2_64},
    {"cublasCgemm3m", (void *)cublasCgemm3m},
    {"cublasCgemm3m_64", (void *)cublasCgemm3m_64},
    {"cublasZgemm_v2", (void *)cublasZgemm_v2},
    {"cublasZgemm_v2_64", (void *)cublasZgemm_v2_64},
    {"cublasZgemm3m", (void *)cublasZgemm3m},
    {"cublasZgemm3m_64", (void *)cublasZgemm3m_64},
    {"cublasHgemm", (void *)cublasHgemm},
    {"cublasHgemm_64", (void *)cublasHgemm_64},
    {"cublasSsyrk_v2", (void *)cublasSsyrk_v2},
    {"cublasSsyrk_v2_64", (void *)cublasSsyrk_v2_64},
    {"cublasDsyrk_v2", (void *)cublasDsyrk_v2},
    {"cublasDsyrk_v2_64", (void *)cublasDsyrk_v2_64},
    {"cublasCsyrk_v2", (void *)cublasCsyrk_v2},
    {"cublasCsyrk_v2_64", (void *)cublasCsyrk_v2_64},
    {"cublasZsyrk_v2", (void *)cublasZsyrk_v2},
    {"cublasZsyrk_v2_64", (void *)cublasZsyrk_v2_64},
    {"cublasCherk_v2", (void *)cublasCherk_v2},
    {"cublasCherk_v2_64", (void *)cublasCherk_v2_64},
    {"cublasZherk_v2", (void *)cublasZherk_v2},
    {"cublasZherk_v2_64", (void *)cublasZherk_v2_64},
    {"cublasSsyr2k_v2", (void *)cublasSsyr2k_v2},
    {"cublasSsyr2k_v2_64", (void *)cublasSsyr2k_v2_64},
    {"cublasDsyr2k_v2", (void *)cublasDsyr2k_v2},
    {"cublasDsyr2k_v2_64", (void *)cublasDsyr2k_v2_64},
    {"cublasCsyr2k_v2", (void *)cublasCsyr2k_v2},
    {"cublasCsyr2k_v2_64", (void *)cublasCsyr2k_v2_64},
    {"cublasZsyr2k_v2", (void *)cublasZsyr2k_v2},
    {"cublasZsyr2k_v2_64", (void *)cublasZsyr2k_v2_64},
    {"cublasCher2k_v2", (void *)cublasCher2k_v2},
    {"cublasCher2k_v2_64", (void *)cublasCher2k_v2_64},
    {"cublasZher2k_v2", (void *)cublasZher2k_v2},
    {"cublasZher2k_v2_64", (void *)cublasZher2k_v2_64},
    {"cublasSsyrkx", (void *)cublasSsyrkx},
    {"cublasSsyrkx_64", (void *)cublasSsyrkx_64},
    {"cublasDsyrkx", (void *)cublasDsyrkx},
    {"cublasDsyrkx_64", (void *)cublasDsyrkx_64},
    {"cublasCsyrkx", (void *)cublasCsyrkx},
    {"cublasCsyrkx_64", (void *)cublasCsyrkx_64},
    {"cublasZsyrkx", (void *)cublasZsyrkx},
    {"cublasZsyrkx_64", (void *)cublasZsyrkx_64},
    {"cublasCherkx", (void *)cublasCherkx},
    {"cublasCherkx_64", (void *)cublasCherkx_64},
    {"cublasZherkx", (void *)cublasZherkx},
    {"cublasZherkx_64", (void *)cublasZherkx_64},
    {"cublasSsymm_v2", (void *)cublasSsymm_v2},
    {"cublasSsymm_v2_64", (void *)cublasSsymm_v2_64},
    {"cublasDsymm_v2", (void *)cublasDsymm_v2},
    {"cublasDsymm_v2_64", (void *)cublasDsymm_v2_64},
    {"cublasCsymm_v2", (void *)cublasCsymm_v2},
    {"cublasCsymm_v2_64", (void *)cublasCsymm_v2_64},
    {"cublasZsymm_v2", (void *)cublasZsymm_v2},
    {"cublasZsymm_v2_64", (void *)cublasZsymm_v2_64},
    {"cublasChemm_v2", (void *)cublasChemm_v2},
    {"cublasChemm_v2_64", (void *)cublasChemm_v2_64},
    {"cublasZhemm_v2", (void *)cublasZhemm_v2},
    {"cublasZhemm_v2_64", (void *)cublasZhemm_v2_64},
    {"cublasStrsm_v2", (void *)cublasStrsm_v2},
    {"cublasStrsm_v2_64", (void *)cublasStrsm_v2_64},
    {"cublasDtrsm_v2", (void *)cublasDtrsm_v2},
    {"cublasDtrsm_v2_64", (void *)cublasDtrsm_v2_64},
    {"cublasCtrsm_v2", (void *)cublasCtrsm_v2},
    {"cublasCtrsm_v2_64", (void *)cublasCtrsm_v2_64},
    {"cublasZtrsm_v2", (void *)cublasZtrsm_v2},
    {"cublasZtrsm_v2_64", (void *)cublasZtrsm_v2_64},
    {"cublasStrmm_v2", (void *)cublasStrmm_v2},
    {"cublasStrmm_v2_64", (void *)cublasStrmm_v2_64},
    {"cublasDtrmm_v2", (void *)cublasDtrmm_v2},
    {"cublasDtrmm_v2_64", (void *)cublasDtrmm_v2_64},
    {"cublasCtrmm_v2", (void *)cublasCtrmm_v2},
    {"cublasCtrmm_v2_64", (void *)cublasCtrmm_v2_64},
    {"cublasZtrmm_v2", (void *)cublasZtrmm_v2},
    {"cublasZtrmm_v2_64", (void *)cublasZtrmm_v2_64},
    {"cublasHgemmStridedBatched", (void *)cublasHgemmStridedBatched},
    {"cublasHgemmStridedBatched_64", (void *)cublasHgemmStridedBatched_64},
    {"cublasSgemmStridedBatched", (void *)cublasSgemmStridedBatched},
    {"cublasSgemmStridedBatched_64", (void *)cublasSgemmStridedBatched_64},
    {"cublasDgemmStridedBatched", (void *)cublasDgemmStridedBatched},
    {"cublasDgemmStridedBatched_64", (void *)cublasDgemmStridedBatched_64},
    {"cublasCgemmStridedBatched", (void *)cublasCgemmStridedBatched},
    {"cublasCgemmStridedBatched_64", (void *)cublasCgemmStridedBatched_64},
    {"cublasCgemm3mStridedBatched", (void *)cublasCgemm3mStridedBatched},
    {"cublasCgemm3mStridedBatched_64", (void *)cublasCgemm3mStridedBatched_64},
    {"cublasZgemmStridedBatched", (void *)cublasZgemmStridedBatched},
    {"cublasZgemmStridedBatched_64", (void *)cublasZgemmStridedBatched_64},
    {"cublasSgeam", (void *)cublasSgeam},
    {"cublasSgeam_64", (void *)cublasSgeam_64},
    {"cublasDgeam", (void *)cublasDgeam},
    {"cublasDgeam_64", (void *)cublasDgeam_64},
    {"cublasCgeam", (void *)cublasCgeam},
    {"cublasCgeam_64", (void *)cublasCgeam_64},
    {"cublasZgeam", (void *)cublasZgeam},
    {"cublasZgeam_64", (void *)cublasZgeam_64},
    {"cublasSdgmm", (void *)cublasSdgmm},
    {"cublasSdgmm_64", (void *)cublasSdgmm_64},
    {"cublasDdgmm", (void *)cublasDdgmm},
    {"cublasDdgmm_64", (void *)cublasDdgmm_64},
    {"cublasCdgmm", (void *)cublasCdgmm},
    {"cublasCdgmm_64", (void *)cublasCdgmm_64},
    {"cublasZdgmm", (void *)cublasZdgmm},
    {"cublasZdgmm_64", (void *)cublasZdgmm_64},
    {"cublasStpttr", (void *)cublasStpttr},
    {"cublasDtpttr", (void *)cublasDtpttr},
    {"cublasCtpttr", (void *)cublasCtpttr},
    {"cublasZtpttr", (void *)cublasZtpttr},
    {"cublasStrttp", (void *)cublasStrttp},
    {"cublasDtrttp", (void *)cublasDtrttp},
    {"cublasCtrttp", (void *)cublasCtrttp},
    {"cublasZtrttp", (void *)cublasZtrttp},
    {"cublasUint8gemmBias", (void *)cublasUint8gemmBias},
    {"cudnnGetProperty", (void *)cudnnGetProperty},
    {"cudnnCreate", (void *)cudnnCreate},
    {"cudnnDestroy", (void *)cudnnDestroy},
    {"cudnnSetStream", (void *)cudnnSetStream},
    {"cudnnGetStream", (void *)cudnnGetStream},
    {"cudnnGetCallback", (void *)cudnnGetCallback},
    {"cudnnGraphVersionCheck", (void *)cudnnGraphVersionCheck},
    {"cudnnBackendCreateDescriptor", (void *)cudnnBackendCreateDescriptor},
    {"cudnnBackendDestroyDescriptor", (void *)cudnnBackendDestroyDescriptor},
    {"cudnnBackendInitialize", (void *)cudnnBackendInitialize},
    {"cudnnBackendFinalize", (void *)cudnnBackendFinalize},
    {"cudnnBackendSetAttribute", (void *)cudnnBackendSetAttribute},
    {"cudnnBackendExecute", (void *)cudnnBackendExecute},
    {"cudnnBackendPopulateCudaGraph", (void *)cudnnBackendPopulateCudaGraph},
    {"cudnnBackendUpdateCudaGraph", (void *)cudnnBackendUpdateCudaGraph},
    {"cudnnCreateTensorDescriptor", (void *)cudnnCreateTensorDescriptor},
    {"cudnnSetTensor4dDescriptor", (void *)cudnnSetTensor4dDescriptor},
    {"cudnnSetTensor4dDescriptorEx", (void *)cudnnSetTensor4dDescriptorEx},
    {"cudnnGetTensor4dDescriptor", (void *)cudnnGetTensor4dDescriptor},
    {"cudnnGetTensorSizeInBytes", (void *)cudnnGetTensorSizeInBytes},
    {"cudnnDestroyTensorDescriptor", (void *)cudnnDestroyTensorDescriptor},
    {"cudnnInitTransformDest", (void *)cudnnInitTransformDest},
    {"cudnnCreateTensorTransformDescriptor",
     (void *)cudnnCreateTensorTransformDescriptor},
    {"cudnnDestroyTensorTransformDescriptor",
     (void *)cudnnDestroyTensorTransformDescriptor},
    {"cudnnCreateOpTensorDescriptor", (void *)cudnnCreateOpTensorDescriptor},
    {"cudnnSetOpTensorDescriptor", (void *)cudnnSetOpTensorDescriptor},
    {"cudnnGetOpTensorDescriptor", (void *)cudnnGetOpTensorDescriptor},
    {"cudnnDestroyOpTensorDescriptor", (void *)cudnnDestroyOpTensorDescriptor},
    {"cudnnCreateReduceTensorDescriptor",
     (void *)cudnnCreateReduceTensorDescriptor},
    {"cudnnSetReduceTensorDescriptor", (void *)cudnnSetReduceTensorDescriptor},
    {"cudnnGetReduceTensorDescriptor", (void *)cudnnGetReduceTensorDescriptor},
    {"cudnnDestroyReduceTensorDescriptor",
     (void *)cudnnDestroyReduceTensorDescriptor},
    {"cudnnGetReductionIndicesSize", (void *)cudnnGetReductionIndicesSize},
    {"cudnnGetReductionWorkspaceSize", (void *)cudnnGetReductionWorkspaceSize},
    {"cudnnCreateFilterDescriptor", (void *)cudnnCreateFilterDescriptor},
    {"cudnnSetFilter4dDescriptor", (void *)cudnnSetFilter4dDescriptor},
    {"cudnnGetFilter4dDescriptor", (void *)cudnnGetFilter4dDescriptor},
    {"cudnnGetFilterSizeInBytes", (void *)cudnnGetFilterSizeInBytes},
    {"cudnnDestroyFilterDescriptor", (void *)cudnnDestroyFilterDescriptor},
    {"cudnnCreatePoolingDescriptor", (void *)cudnnCreatePoolingDescriptor},
    {"cudnnSetPooling2dDescriptor", (void *)cudnnSetPooling2dDescriptor},
    {"cudnnGetPooling2dDescriptor", (void *)cudnnGetPooling2dDescriptor},
    {"cudnnGetPooling2dForwardOutputDim",
     (void *)cudnnGetPooling2dForwardOutputDim},
    {"cudnnDestroyPoolingDescriptor", (void *)cudnnDestroyPoolingDescriptor},
    {"cudnnCreateActivationDescriptor",
     (void *)cudnnCreateActivationDescriptor},
    {"cudnnSetActivationDescriptor", (void *)cudnnSetActivationDescriptor},
    {"cudnnGetActivationDescriptor", (void *)cudnnGetActivationDescriptor},
    {"cudnnSetActivationDescriptorSwishBeta",
     (void *)cudnnSetActivationDescriptorSwishBeta},
    {"cudnnGetActivationDescriptorSwishBeta",
     (void *)cudnnGetActivationDescriptorSwishBeta},
    {"cudnnDestroyActivationDescriptor",
     (void *)cudnnDestroyActivationDescriptor},
    {"cudnnActivationForward", (void *)cudnnActivationForward},
    {"cudnnCreateLRNDescriptor", (void *)cudnnCreateLRNDescriptor},
    {"cudnnSetLRNDescriptor", (void *)cudnnSetLRNDescriptor},
    {"cudnnGetLRNDescriptor", (void *)cudnnGetLRNDescriptor},
    {"cudnnDestroyLRNDescriptor", (void *)cudnnDestroyLRNDescriptor},
    {"cudnnDeriveBNTensorDescriptor", (void *)cudnnDeriveBNTensorDescriptor},
    {"cudnnDeriveNormTensorDescriptor",
     (void *)cudnnDeriveNormTensorDescriptor},
    {"cudnnCreateSpatialTransformerDescriptor",
     (void *)cudnnCreateSpatialTransformerDescriptor},
    {"cudnnDestroySpatialTransformerDescriptor",
     (void *)cudnnDestroySpatialTransformerDescriptor},
    {"cudnnCreateDropoutDescriptor", (void *)cudnnCreateDropoutDescriptor},
    {"cudnnDestroyDropoutDescriptor", (void *)cudnnDestroyDropoutDescriptor},
    {"cudnnDropoutGetStatesSize", (void *)cudnnDropoutGetStatesSize},
    {"cudnnDropoutGetReserveSpaceSize",
     (void *)cudnnDropoutGetReserveSpaceSize},
    {"cudnnGetDropoutDescriptor", (void *)cudnnGetDropoutDescriptor},
    {"cudnnOpsVersionCheck", (void *)cudnnOpsVersionCheck},
    {"cudnnGetBatchNormalizationForwardTrainingExWorkspaceSize",
     (void *)cudnnGetBatchNormalizationForwardTrainingExWorkspaceSize},
    {"cudnnGetBatchNormalizationBackwardExWorkspaceSize",
     (void *)cudnnGetBatchNormalizationBackwardExWorkspaceSize},
    {"cudnnGetBatchNormalizationTrainingExReserveSpaceSize",
     (void *)cudnnGetBatchNormalizationTrainingExReserveSpaceSize},
    {"cudnnGetNormalizationForwardTrainingWorkspaceSize",
     (void *)cudnnGetNormalizationForwardTrainingWorkspaceSize},
    {"cudnnGetNormalizationBackwardWorkspaceSize",
     (void *)cudnnGetNormalizationBackwardWorkspaceSize},
    {"cudnnGetNormalizationTrainingReserveSpaceSize",
     (void *)cudnnGetNormalizationTrainingReserveSpaceSize},
    {"cuMemcpy_ptds", (void *)cuMemcpy},
    {"cuMemcpyAsync_ptsz", (void *)cuMemcpyAsync},
    {"cuMemcpyPeer_ptds", (void *)cuMemcpyPeer},
    {"cuMemcpyPeerAsync_ptsz", (void *)cuMemcpyPeerAsync},
    {"cuMemPrefetchAsync_ptsz", (void *)cuMemPrefetchAsync},
    {"cuMemsetD8Async_ptsz", (void *)cuMemsetD8Async},
    {"cuMemsetD16Async_ptsz", (void *)cuMemsetD16Async},
    {"cuMemsetD32Async_ptsz", (void *)cuMemsetD32Async},
    {"cuMemsetD2D8Async_ptsz", (void *)cuMemsetD2D8Async},
    {"cuMemsetD2D16Async_ptsz", (void *)cuMemsetD2D16Async},
    {"cuMemsetD2D32Async_ptsz", (void *)cuMemsetD2D32Async},
    {"cuStreamGetPriority_ptsz", (void *)cuStreamGetPriority},
    {"cuStreamGetId_ptsz", (void *)cuStreamGetId},
    {"cuStreamGetFlags_ptsz", (void *)cuStreamGetFlags},
    {"cuStreamGetCtx_ptsz", (void *)cuStreamGetCtx},
    {"cuStreamWaitEvent_ptsz", (void *)cuStreamWaitEvent},
    {"cuStreamEndCapture_ptsz", (void *)cuStreamEndCapture},
    {"cuStreamIsCapturing_ptsz", (void *)cuStreamIsCapturing},
    {"cuStreamUpdateCaptureDependencies_ptsz",
     (void *)cuStreamUpdateCaptureDependencies},
    {"cuStreamAttachMemAsync_ptsz", (void *)cuStreamAttachMemAsync},
    {"cuStreamQuery_ptsz", (void *)cuStreamQuery},
    {"cuStreamSynchronize_ptsz", (void *)cuStreamSynchronize},
    {"cuEventRecord_ptsz", (void *)cuEventRecord},
    {"cuEventRecordWithFlags_ptsz", (void *)cuEventRecordWithFlags},
    {"cuLaunchKernel_ptsz", (void *)cuLaunchKernel},
    {"cuGraphicsMapResources_ptsz", (void *)cuGraphicsMapResources},
    {"cuGraphicsUnmapResources_ptsz", (void *)cuGraphicsUnmapResources},
    {"cuLaunchCooperativeKernel_ptsz", (void *)cuLaunchCooperativeKernel},
    {"cuSignalExternalSemaphoresAsync_ptsz",
     (void *)cuSignalExternalSemaphoresAsync},
    {"cuWaitExternalSemaphoresAsync_ptsz",
     (void *)cuWaitExternalSemaphoresAsync},
    {"cuGraphInstantiateWithParams_ptsz", (void *)cuGraphInstantiateWithParams},
    {"cuGraphUpload_ptsz", (void *)cuGraphUpload},
    {"cuGraphLaunch_ptsz", (void *)cuGraphLaunch},
    {"cuStreamCopyAttributes_ptsz", (void *)cuStreamCopyAttributes},
    {"cuStreamGetAttribute_ptsz", (void *)cuStreamGetAttribute},
    {"cuStreamSetAttribute_ptsz", (void *)cuStreamSetAttribute},
    {"cuMemMapArrayAsync_ptsz", (void *)cuMemMapArrayAsync},
    {"cuMemFreeAsync_ptsz", (void *)cuMemFreeAsync},
    {"cuMemAllocAsync_ptsz", (void *)cuMemAllocAsync},
    {"cuMemAllocFromPoolAsync_ptsz", (void *)cuMemAllocFromPoolAsync},
    {"cudaFree", (void *)cudaFree},
    {"cudaMemcpy", (void *)cudaMemcpy},
    {"cudaMallocHost", (void *)cudaMallocHost},
    {"cudaMemcpyAsync", (void *)cudaMemcpyAsync},
    {"cudaLaunchKernel", (void *)cudaLaunchKernel},
    {"cudaMallocManaged", (void *)cudaMallocManaged},
    {"cudaGraphGetNodes", (void *)cudaGraphGetNodes},
    {"cudaGraphDestroy", (void *)cudaGraphDestroy},
    {"cudaGraphAddKernelNode", (void *)cudaGraphAddKernelNode},
    {"cudaGraphAddMemcpyNode", (void *)cudaGraphAddMemcpyNode},
    {"cudaGraphAddHostNode", (void *)cudaGraphAddHostNode},
    {"cudaGraphAddMemFreeNode", (void *)cudaGraphAddMemFreeNode},
    {"cudaGraphAddMemAllocNode", (void *)cudaGraphAddMemAllocNode},
    {"cudaDeviceGetGraphMemAttribute", (void *)cudaDeviceGetGraphMemAttribute},
};

void *get_function_pointer(const char *name) {
  auto it = functionMap.find(name);
  if (it == functionMap.end())
    return nullptr;
  return it->second;
}
